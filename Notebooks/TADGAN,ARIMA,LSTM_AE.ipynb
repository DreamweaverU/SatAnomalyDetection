{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Pm4UFLkDI4-",
        "outputId": "472e1d2d-1d28-4459-da5a-593f1b0c92c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting orion-ml\n",
            "  Downloading orion_ml-0.2.0-py2.py3-none-any.whl (110 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 40 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 51 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 61 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 71 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 81 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 92 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 102 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 110 kB 24.8 MB/s \n",
            "\u001b[?25hCollecting azure-cognitiveservices-anomalydetector<0.4,>=0.3\n",
            "  Downloading azure_cognitiveservices_anomalydetector-0.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting xlsxwriter>=1.3.6<1.4\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 53.5 MB/s \n",
            "\u001b[?25hCollecting mlprimitives<0.3,>=0.2.2\n",
            "  Downloading mlprimitives-0.2.5-py2.py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting mongoengine<0.25,>=0.20.0\n",
            "  Downloading mongoengine-0.23.1-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting pymongo<4,>=3.7.2\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate<0.9,>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from orion-ml) (0.8.9)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 68.8 MB/s \n",
            "\u001b[?25hCollecting baytune<0.3,>=0.2.3\n",
            "  Downloading baytune-0.2.5-py2.py3-none-any.whl (28 kB)\n",
            "Collecting mlblocks<0.4,>=0.3.0\n",
            "  Downloading mlblocks-0.3.4-py2.py3-none-any.whl (26 kB)\n",
            "Collecting scikit-learn<0.21,>=0.20.1\n",
            "  Downloading scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba<0.52,>=0.48 in /usr/local/lib/python3.7/dist-packages (from orion-ml) (0.51.2)\n",
            "Collecting pyts<0.11,>=0.9\n",
            "  Downloading pyts-0.10.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 55.5 MB/s \n",
            "\u001b[?25hCollecting numpy<1.17,>=1.15.4\n",
            "  Downloading numpy-1.16.6-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 278 kB/s \n",
            "\u001b[?25hCollecting pandas<0.25,>=0.23.4\n",
            "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 53.6 MB/s \n",
            "\u001b[?25hCollecting Keras<2.4,>=2.1.6\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 61.0 MB/s \n",
            "\u001b[?25hCollecting s3fs<0.5,>=0.2.2\n",
            "  Downloading s3fs-0.4.2-py3-none-any.whl (19 kB)\n",
            "Collecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting msrest>=0.5.0\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from baytune<0.3,>=0.2.3->orion-ml) (1.4.1)\n",
            "Requirement already satisfied: six>=1.0 in /usr/local/lib/python3.7/dist-packages (from baytune<0.3,>=0.2.3->orion-ml) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras<2.4,>=2.1.6->orion-ml) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras<2.4,>=2.1.6->orion-ml) (3.13)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from mlprimitives<0.3,>=0.2.2->orion-ml) (57.4.0)\n",
            "Requirement already satisfied: opencv-python<5,>=3.4.0.12 in /usr/local/lib/python3.7/dist-packages (from mlprimitives<0.3,>=0.2.2->orion-ml) (4.1.2.30)\n",
            "Requirement already satisfied: statsmodels<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from mlprimitives<0.3,>=0.2.2->orion-ml) (0.10.2)\n",
            "Collecting nltk<4,>=3.3\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 44.7 MB/s \n",
            "\u001b[?25hCollecting iso639<0.2,>=0.1.4\n",
            "  Downloading iso639-0.1.4.tar.gz (11 kB)\n",
            "Collecting scikit-image!=0.14.3,<0.15,>=0.13.1\n",
            "  Downloading scikit_image-0.14.5-cp37-cp37m-manylinux1_x86_64.whl (25.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from mlprimitives<0.3,>=0.2.2->orion-ml) (2.6.3)\n",
            "Collecting langdetect<2,>=1.0.7\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost<1,>=0.72.1 in /usr/local/lib/python3.7/dist-packages (from mlprimitives<0.3,>=0.2.2->orion-ml) (0.90)\n",
            "Collecting tensorflow<2,>=1.11.0\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.6 kB/s \n",
            "\u001b[?25hCollecting featuretools<0.12,>=0.6.1\n",
            "  Downloading featuretools-0.11.0-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting python-louvain<0.14,>=0.10\n",
            "  Downloading python-louvain-0.13.tar.gz (18 kB)\n",
            "Collecting lightfm<2,>=1.15\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.4 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (5.2.1)\n",
            "Requirement already satisfied: cloudpickle>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.3.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (0.16.0)\n",
            "Requirement already satisfied: click>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.32.0 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (4.62.3)\n",
            "Requirement already satisfied: psutil>=5.4.8 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (5.4.8)\n",
            "Requirement already satisfied: dask>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (2.12.0)\n",
            "Requirement already satisfied: distributed>=1.24.2 in /usr/local/lib/python3.7/dist-packages (from featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.25.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (2.0.0)\n",
            "Requirement already satisfied: tblib in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.7.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.0.3)\n",
            "Requirement already satisfied: tornado>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (5.1.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (2.4.0)\n",
            "Requirement already satisfied: toolz>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (0.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm<2,>=1.15->mlprimitives<0.3,>=0.2.2->orion-ml) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (2021.10.8)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 557 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (1.3.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.3->mlprimitives<0.3,>=0.2.2->orion-ml) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<0.52,>=0.48->orion-ml) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas<0.25,>=0.23.4->orion-ml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas<0.25,>=0.23.4->orion-ml) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm<2,>=1.15->mlprimitives<0.3,>=0.2.2->orion-ml) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm<2,>=1.15->mlprimitives<0.3,>=0.2.2->orion-ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm<2,>=1.15->mlprimitives<0.3,>=0.2.2->orion-ml) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (3.1.1)\n",
            "Collecting botocore>=1.12.91\n",
            "  Downloading botocore-1.23.39-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 35.1 MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (7.1.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image!=0.14.3,<0.15,>=0.13.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.3.2)\n",
            "Collecting PyWavelets>=0.4.0\n",
            "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels<1,>=0.9.0->mlprimitives<0.3,>=0.2.2->orion-ml) (0.5.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (1.13.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (1.43.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (0.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.11.0->mlprimitives<0.3,>=0.2.2->orion-ml) (3.7.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=1.24.2->featuretools<0.12,>=0.6.1->mlprimitives<0.3,>=0.2.2->orion-ml) (1.0.1)\n",
            "Building wheels for collected packages: iso639, langdetect, lightfm, python-louvain, gast\n",
            "  Building wheel for iso639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso639: filename=iso639-0.1.4-py3-none-any.whl size=11191 sha256=749099f23fc21e0d1edc24ab45e7947fa7e2f2ad7911700eb4f7e5919702bcb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/0c/79/0f1e37567fba2eed11c6323b06c07480ad0881d2735fa1c98c\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=9aed7c52afaf1a95fdd3e02fb8f4a69d8aa62e6499846f72f4235501afed49ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705348 sha256=7f17dfdd7bdd43badab4c8f330f25dd7566ab865be6e13b4cca2da838da19a5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "  Building wheel for python-louvain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-louvain: filename=python_louvain-0.13-py3-none-any.whl size=9238 sha256=77efcfbc165a739219eb0c93beda75726322e6db57de27abe6b5c02e55678b45\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/6b/3b/87539deabac63a68ec34be2867308907d0544e11ba4d4e728d\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=fdaa27ca92a144c14cbdd6090deb63c343c361c9bd5644d73b54a0fef10168b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built iso639 langdetect lightfm python-louvain gast\n",
            "Installing collected packages: urllib3, numpy, jmespath, h5py, fsspec, botocore, tensorflow-estimator, tensorboard, scikit-learn, s3fs, regex, PyWavelets, pandas, keras-applications, isodate, gast, tensorflow, scikit-image, python-louvain, pymongo, nltk, msrest, mlblocks, lightfm, langdetect, Keras, iso639, featuretools, docutils, azure-common, xlsxwriter, pyts, mongoengine, mlprimitives, baytune, azure-cognitiveservices-anomalydetector, orion-ml\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.2.0\n",
            "    Uninstalling PyWavelets-1.2.0:\n",
            "      Successfully uninstalled PyWavelets-1.2.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: python-louvain\n",
            "    Found existing installation: python-louvain 0.15\n",
            "    Uninstalling python-louvain-0.15:\n",
            "      Successfully uninstalled python-louvain-0.15\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.1\n",
            "    Uninstalling pymongo-4.0.1:\n",
            "      Successfully uninstalled pymongo-4.0.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.16.6 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Keras-2.3.1 PyWavelets-1.1.1 azure-cognitiveservices-anomalydetector-0.3.0 azure-common-1.1.27 baytune-0.2.5 botocore-1.23.39 docutils-0.15.2 featuretools-0.11.0 fsspec-2022.1.0 gast-0.2.2 h5py-2.10.0 iso639-0.1.4 isodate-0.6.1 jmespath-0.10.0 keras-applications-1.0.8 langdetect-1.0.9 lightfm-1.16 mlblocks-0.3.4 mlprimitives-0.2.5 mongoengine-0.23.1 msrest-0.6.21 nltk-3.6.7 numpy-1.16.6 orion-ml-0.2.0 pandas-0.24.2 pymongo-3.12.3 python-louvain-0.13 pyts-0.10.0 regex-2022.1.18 s3fs-0.4.2 scikit-image-0.14.5 scikit-learn-0.20.4 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1 urllib3-1.25.11 xlsxwriter-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install orion-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CqLiIWhDoeX",
        "outputId": "2e1ce1b5-0987-448f-95ab-eeff33ec0a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        }
      ],
      "source": [
        "from orion.data import load_signal\n",
        "\n",
        "SIGNALS = [\n",
        "    'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11', 'D-12', 'B-1', 'G-6', 'G-7', 'P-7',\n",
        "    'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3', 'M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8'\n",
        "]\n",
        "SMAP=[  'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11', 'D-12', 'B-1', 'G-6', 'G-7', 'P-7',\n",
        "    'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3']\n",
        "\n",
        "MSL=['M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8']\n",
        "\n",
        "append_train='-train'\n",
        "append_test='-test'\n",
        "append_new='-new'\n",
        "training = [sub+append_train for sub in SMAP]\n",
        "print(len(training))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ2L50kPp2t3"
      },
      "outputs": [],
      "source": [
        "from orion import Orion\n",
        "from orion.analysis import analyze\n",
        "\n",
        "\n",
        "orion = Orion(pipeline='tadgan')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBh9k9u5sNbd"
      },
      "outputs": [],
      "source": [
        "from orion.data import load_anomalies\n",
        "from orion.data import load_signal\n",
        "import logging\n",
        "import warnings\n",
        "import statistics\n",
        "from orion.evaluation import contextual_accuracy, contextual_f1_score,contextual_recall,contextual_precision\n",
        "from orion.analysis import analyze\n",
        "pipeline = 'tadgan'\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "logging.getLogger().setLevel(level=logging.ERROR)\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmdTV_w0o74E",
        "outputId": "15a068f7-d32c-44ea-981a-fa2a9611b83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/35, [Dx loss: [-0.2538772  -3.7114468   0.78104913  0.26765206]] [Dz loss: [ 2.1411576 -0.2680082  1.6556734  0.0753492]] [G loss: [ 0.5346668 -0.8190495 -1.4182805  0.2771997]]\n",
            "Epoch: 2/35, [Dx loss: [-1.8602304  -5.7896748   3.6184075   0.03110369]] [Dz loss: [ 3.0962498  -0.40694708  2.4489105   0.1054287 ]] [G loss: [ 4.335228  -3.2541068  4.358397   0.3230937]]\n",
            "Epoch: 3/35, [Dx loss: [-2.435181   -2.9320147   0.0769545   0.04198792]] [Dz loss: [-22.405424    -0.32249328 -23.364687     0.12817517]] [G loss: [33.374653    0.04791032 30.52427     0.2802475 ]]\n",
            "Epoch: 4/35, [Dx loss: [-2.1716955  -5.6662436   3.1826024   0.03119456]] [Dz loss: [ 8.262297   -0.09239884  4.5272064   0.3827488 ]] [G loss: [-4.4380684  -3.2603312  -3.3070402   0.21293028]]\n",
            "Epoch: 5/35, [Dx loss: [-2.4454231  -5.0919657   2.3018572   0.03446848]] [Dz loss: [40.891624    0.3259682  39.14995     0.14157137]] [G loss: [-28.593508    -2.1550193  -28.979734     0.25412464]]\n",
            "Epoch: 6/35, [Dx loss: [-1.7146447  -3.8004875   1.8076289   0.02782139]] [Dz loss: [-93.99017      0.86452997 -96.19945      0.1344733 ]] [G loss: [127.43927    -1.7775804 127.22064     0.1996218]]\n",
            "Epoch: 7/35, [Dx loss: [-1.9923813  -3.670199    1.3952467   0.02825708]] [Dz loss: [-153.8129       1.596357  -168.67485      1.3265594]] [G loss: [200.2801      -1.3604552  199.45946      0.21810913]]\n",
            "Epoch: 8/35, [Dx loss: [-1.8059933  -1.1759286  -0.8674281   0.02373637]] [Dz loss: [5.022107   1.8698359  1.6728146  0.14794573]] [G loss: [ 1.9176133   1.0022038  -1.3411114   0.22565207]]\n",
            "Epoch: 9/35, [Dx loss: [-1.5752957  -3.7621608   1.9977894   0.01890753]] [Dz loss: [9.356271   1.6883056  5.848486   0.18194786]] [G loss: [-5.7063923  -2.033793   -5.5435143   0.18709159]]\n",
            "Epoch: 10/35, [Dx loss: [-1.2878778  -3.9241157   2.5166821   0.01195559]] [Dz loss: [-5.7936335   1.6180019  -9.264102    0.18524675]] [G loss: [12.797492   -2.5420692  13.604041    0.17355198]]\n",
            "Epoch: 11/35, [Dx loss: [-1.0468476  -0.71326977 -0.45271558  0.01191374]] [Dz loss: [-16.317421     1.6772623  -18.851822     0.08571359]] [G loss: [24.483812   0.9202368 21.680008   0.1883566]]\n",
            "Epoch: 12/35, [Dx loss: [-1.0775682  -0.79346114 -0.38872522  0.01046182]] [Dz loss: [-5.4234858   1.7570149  -8.427969    0.12474693]] [G loss: [10.893026   -0.10044837  8.752323    0.22411516]]\n",
            "Epoch: 13/35, [Dx loss: [-1.4210608  -7.527547    5.968958    0.01375275]] [Dz loss: [ 2.7985342   1.7237377  -1.9297107   0.30045077]] [G loss: [-2.2638948  -6.14432     2.001137    0.18792877]]\n",
            "Epoch: 14/35, [Dx loss: [-1.2662742  -8.748114    7.323283    0.01585548]] [Dz loss: [ 0.80325687  1.6414133  -1.9226221   0.10844658]] [G loss: [-3.5316734  -7.329015    2.0002599   0.17970815]]\n",
            "Epoch: 15/35, [Dx loss: [-0.9409709  -2.5990987   1.519417    0.01387107]] [Dz loss: [-0.01014211  1.5580149  -2.662269    0.10941122]] [G loss: [ 3.964694   -0.7228755   2.8807988   0.18067706]]\n",
            "Epoch: 16/35, [Dx loss: [-1.0572035   0.35800254 -1.5266497   0.01114436]] [Dz loss: [ 0.2300754   1.5350978  -2.6989446   0.13939224]] [G loss: [5.7368894  1.212563   2.7680144  0.17563121]]\n",
            "Epoch: 17/35, [Dx loss: [-0.9986676  -4.860066    3.7509491   0.01104497]] [Dz loss: [ 0.75611484  1.4789283  -2.1295042   0.14066906]] [G loss: [ 0.59547657 -3.6742554   2.3038855   0.19658469]]\n",
            "Epoch: 18/35, [Dx loss: [-1.0109926  -0.18459195 -0.97463006  0.01482296]] [Dz loss: [ 1.2749283   1.437355   -1.5014935   0.13390669]] [G loss: [4.8212643  1.1608253  1.605238   0.20552011]]\n",
            "Epoch: 19/35, [Dx loss: [-1.249538   -2.6837046   1.3046138   0.01295529]] [Dz loss: [ 2.189128    1.4259589  -0.9343133   0.16974829]] [G loss: [ 1.4886742  -1.5750724   0.9901763   0.20735702]]\n",
            "Epoch: 20/35, [Dx loss: [-0.9052056  -1.8967874   0.8775954   0.01139864]] [Dz loss: [ 2.5245872   1.3176792  -0.4422257   0.16491337]] [G loss: [ 2.562813   -0.11730605  0.43508068  0.22450384]]\n",
            "Epoch: 21/35, [Dx loss: [-1.0233339   4.896481   -6.049015    0.01291995]] [Dz loss: [ 2.7956681   1.2980138  -0.08502295  0.15826769]] [G loss: [8.245939   6.195503   0.13857953 0.19118571]]\n",
            "Epoch: 22/35, [Dx loss: [-1.0873467   0.69991624 -1.9572866   0.01700237]] [Dz loss: [3.103097   1.296622   0.15581036 0.16506645]] [G loss: [ 3.3190978   1.4897379  -0.07215735  0.1901517 ]]\n",
            "Epoch: 23/35, [Dx loss: [-0.88575923 -1.5130458   0.509538    0.01177486]] [Dz loss: [ 2.6342595   1.3555592  -0.15412599  0.14328259]] [G loss: [ 1.876926   -0.31228715  0.29795778  0.18912552]]\n",
            "Epoch: 24/35, [Dx loss: [-0.9234784  -0.82077485 -0.20137039  0.00986668]] [Dz loss: [ 1.3694917   1.4913161  -1.3456703   0.12238453]] [G loss: [3.2509851  0.04203579 1.4319167  0.17770329]]\n",
            "Epoch: 25/35, [Dx loss: [-0.9520774  -1.1899202   0.11875008  0.01190925]] [Dz loss: [ 0.23747835  1.605862   -2.588237    0.12198534]] [G loss: [4.5387855  0.04911762 2.7681692  0.17214985]]\n",
            "Epoch: 26/35, [Dx loss: [-0.88053215 -0.7551854  -0.22960392  0.01042571]] [Dz loss: [ 0.48374134  1.6488187  -2.2905583   0.11254807]] [G loss: [4.2242002  0.09194689 2.2792923  0.18529604]]\n",
            "Epoch: 27/35, [Dx loss: [-1.0110455  -3.5050857   2.375564    0.01184769]] [Dz loss: [ 1.2827288   1.6945947  -1.4215437   0.10096775]] [G loss: [ 0.8181867  -2.4453092   1.4259553   0.18375404]]\n",
            "Epoch: 28/35, [Dx loss: [-0.8889472  -2.2567086   1.2508068   0.01169547]] [Dz loss: [ 1.7717775   1.6693512  -0.8197352   0.09221611]] [G loss: [ 1.5386727  -1.140731    0.8440224   0.18353814]]\n",
            "Epoch: 29/35, [Dx loss: [-0.8963517  -3.809012    2.7842727   0.01283872]] [Dz loss: [ 1.7835872   1.5819706  -0.6508015   0.08524184]] [G loss: [-0.36145872 -2.7108433   0.6641131   0.16852714]]\n",
            "Epoch: 30/35, [Dx loss: [-0.8691207   0.15095136 -1.1255434   0.01054712]] [Dz loss: [ 1.8474114   1.5503302  -0.5951373   0.08922187]] [G loss: [3.4999132  1.3474228  0.6190604  0.15334299]]\n",
            "Epoch: 31/35, [Dx loss: [-0.88943255 -2.9452956   1.9396471   0.01162159]] [Dz loss: [ 1.8703343   1.5390246  -0.53766495  0.08689748]] [G loss: [-0.381895   -2.3157759   0.55124676  0.13826339]]\n",
            "Epoch: 32/35, [Dx loss: [-0.82939565 -3.4818947   2.526611    0.01258873]] [Dz loss: [ 1.95556     1.514774   -0.38921854  0.08300044]] [G loss: [-0.3169456  -2.03119     0.37326846  0.13409758]]\n",
            "Epoch: 33/35, [Dx loss: [-0.7558917  0.8706749 -1.7283003  0.0101734]] [Dz loss: [ 1.9621537   1.4782383  -0.3178584   0.08017735]] [G loss: [3.4184036  1.8306775  0.33619076 0.12515351]]\n",
            "Epoch: 34/35, [Dx loss: [-0.8779777  -1.5835066   0.58157885  0.012395  ]] [Dz loss: [ 2.0636346   1.4714639  -0.24500306  0.08371741]] [G loss: [ 0.5108431  -0.91449654  0.2518927   0.1173447 ]]\n",
            "Epoch: 35/35, [Dx loss: [-0.77285284 -4.1049843   3.2282665   0.01038651]] [Dz loss: [ 1.9948412   1.4166315  -0.23358269  0.08117922]] [G loss: [-1.6426253  -2.9277773   0.19615495  0.1088997 ]]\n",
            "precision 0.0 Signal P-1\n",
            "recall 0.0 Signal P-1\n",
            "Accuracy 0.8520695761907251 Signal P-1\n",
            "F1 nan Signal P-1\n",
            "Epoch: 1/35, [Dx loss: [-3.8239465  -7.2757516   0.6981867   0.27536178]] [Dz loss: [2.5726876  0.26696077 1.5213716  0.07843552]] [G loss: [ 4.7308073 -0.6463514 -1.262616   0.6639774]]\n",
            "Epoch: 2/35, [Dx loss: [-5.6380625  -7.56186     0.9378451   0.09859543]] [Dz loss: [-1.6847973   0.19352809 -2.8400397   0.09617144]] [G loss: [10.419357   -0.34808648  5.6517305   0.51157135]]\n",
            "Epoch: 3/35, [Dx loss: [-5.6770277  -5.7697315  -0.8582958   0.09509992]] [Dz loss: [ 0.67439646  0.21428648 -1.716473    0.21765831]] [G loss: [7.8884234  0.58954793 2.5211704  0.47777048]]\n",
            "Epoch: 4/35, [Dx loss: [-5.74811    -9.131765    2.469375    0.09142809]] [Dz loss: [2.1154747  0.1413154  0.4917428  0.14824167]] [G loss: [ 1.7965422  -2.6413264   0.11901513  0.43188533]]\n",
            "Epoch: 5/35, [Dx loss: [-5.882503   -9.159167    2.352133    0.09245298]] [Dz loss: [6.514247   0.15304872 5.1155252  0.12456741]] [G loss: [-0.34894985 -2.27464    -2.3886266   0.4314317 ]]\n",
            "Epoch: 6/35, [Dx loss: [-6.025907   -9.044855    2.0669076   0.09520406]] [Dz loss: [-40.6641       0.8101491  -44.77661      0.33023626]] [G loss: [65.697105   -2.1305127  63.42755     0.44000643]]\n",
            "Epoch: 7/35, [Dx loss: [-6.0696573  -9.023161    2.0277746   0.09257308]] [Dz loss: [-3.3967648   1.4960637  -7.982817    0.30899885]] [G loss: [11.44522   -1.8950716  8.550919   0.4789372]]\n",
            "Epoch: 8/35, [Dx loss: [-6.2636476  -8.530934    1.3537502   0.09135373]] [Dz loss: [-1.0719426  1.6874863 -4.0779533  0.1318525]] [G loss: [ 7.223673   -1.4403174   4.387126    0.42768645]]\n",
            "Epoch: 9/35, [Dx loss: [-6.4151764  -9.284685    1.9159374   0.09535693]] [Dz loss: [-1.5163656   1.7795864  -4.3740926   0.10781398]] [G loss: [ 6.942015  -1.868818   4.628617   0.4182216]]\n",
            "Epoch: 10/35, [Dx loss: [-6.4872217  -9.069512    1.6391947   0.09430955]] [Dz loss: [ 1.4460055   1.6572273  -1.6789529   0.14677304]] [G loss: [ 4.33346    -1.6358354   1.7486407   0.42206544]]\n",
            "Epoch: 11/35, [Dx loss: [-6.516037   -8.918147    1.4564556   0.09456553]] [Dz loss: [ 2.2919      1.5998051  -0.73367316  0.14257678]] [G loss: [ 3.5549648  -1.4243791   0.78613293  0.4193211 ]]\n",
            "Epoch: 12/35, [Dx loss: [-6.4188566  -8.793726    1.4468278   0.09280405]] [Dz loss: [ 1.877827    1.5038072  -0.7315156   0.11055356]] [G loss: [ 3.579391   -1.4419283   0.805583    0.42157364]]\n",
            "Epoch: 13/35, [Dx loss: [-6.279028   -8.770201    1.5997766   0.08913965]] [Dz loss: [ 2.2621436   1.4080664  -0.31204277  0.11661204]] [G loss: [ 3.036028   -1.5935676   0.33899173  0.42906037]]\n",
            "Epoch: 14/35, [Dx loss: [-5.974349  -8.5695     1.7394698  0.085568 ]] [Dz loss: [ 2.1586711   1.3135685  -0.25676006  0.11018629]] [G loss: [ 2.942174   -1.6980262   0.26752868  0.43726712]]\n",
            "Epoch: 15/35, [Dx loss: [-5.7685237  -8.296886    1.703924    0.08244381]] [Dz loss: [ 2.0199184   1.2320807  -0.1689652   0.09568025]] [G loss: [ 2.8890352  -1.6697327   0.16958523  0.43891826]]\n",
            "Epoch: 16/35, [Dx loss: [-5.5681562  -8.293676    1.9294713   0.07960495]] [Dz loss: [ 2.033583    1.1599319  -0.11373904  0.09873901]] [G loss: [ 2.4140725  -1.9337842   0.11380677  0.42340505]]\n",
            "Epoch: 17/35, [Dx loss: [-5.4519095  -8.006775    1.791379    0.07634869]] [Dz loss: [ 1.9762936   1.073792   -0.06121097  0.09637128]] [G loss: [ 2.4248533  -1.7849797   0.05790016  0.4151933 ]]\n",
            "Epoch: 18/35, [Dx loss: [-5.2816234  -7.6994658   1.6923468   0.07254957]] [Dz loss: [ 1.8854206   0.9799552  -0.03369396  0.09391592]] [G loss: [ 2.4753726  -1.670105    0.03554452  0.4109933 ]]\n",
            "Epoch: 19/35, [Dx loss: [-5.12721    -7.823265    1.9757586   0.07202972]] [Dz loss: [1.943577   0.88816565 0.0370992  0.1018312 ]] [G loss: [ 2.188783   -1.9271601  -0.02130116  0.41372442]]\n",
            "Epoch: 20/35, [Dx loss: [-5.0297766  -7.2672806   1.5599083   0.06775948]] [Dz loss: [2.0249102 0.8205694 0.202319  0.1002022]] [G loss: [ 2.474411   -1.4866531  -0.2108876   0.41719514]]\n",
            "Epoch: 21/35, [Dx loss: [-4.8961577  -6.5451555   1.0069916   0.06420068]] [Dz loss: [2.1861644  0.7404685  0.3409495  0.11047466]] [G loss: [ 2.8324203  -0.9921477  -0.3485575   0.41731256]]\n",
            "Epoch: 22/35, [Dx loss: [-4.7440686  -6.7756515   1.4011174   0.06304669]] [Dz loss: [2.2266853  0.7021991  0.42921215 0.10952745]] [G loss: [ 2.3264208  -1.4243321  -0.4293465   0.41800997]]\n",
            "Epoch: 23/35, [Dx loss: [-4.5556126  -7.2637568   2.1235566   0.05845883]] [Dz loss: [2.2005012  0.6780628  0.4164959  0.11059425]] [G loss: [ 1.6878555  -2.0861874  -0.42862356  0.42026666]]\n",
            "Epoch: 24/35, [Dx loss: [-4.2854085  -6.940074    2.1006217   0.05540429]] [Dz loss: [2.1455147  0.63266766 0.43127474 0.10815722]] [G loss: [ 1.7136647  -2.08316    -0.44068772  0.42375124]]\n",
            "Epoch: 25/35, [Dx loss: [-4.076847   -6.9946604   2.4012315   0.05165816]] [Dz loss: [2.0916133  0.5869113  0.41828504 0.10864166]] [G loss: [ 1.3987513  -2.4579785  -0.3886782   0.42454082]]\n",
            "Epoch: 26/35, [Dx loss: [-3.5411143  -7.0161743   3.0589423   0.04161178]] [Dz loss: [2.0655024  0.5734261  0.33990663 0.11521695]] [G loss: [ 1.3047419  -2.7580612  -0.31981727  0.43826205]]\n",
            "Epoch: 27/35, [Dx loss: [-3.468455   -5.4819818   1.5656179   0.04479073]] [Dz loss: [2.0999885  0.5451473  0.30454168 0.12502989]] [G loss: [ 2.3240762  -1.6563401  -0.30809113  0.42885074]]\n",
            "Epoch: 28/35, [Dx loss: [-3.075633   -8.739367    5.3008738   0.03628594]] [Dz loss: [2.0873322  0.5052575  0.31909835 0.12629762]] [G loss: [-1.3834753  -5.338765   -0.2821028   0.42373922]]\n",
            "Epoch: 29/35, [Dx loss: [-3.1200264  -7.5383286   4.020096    0.03982063]] [Dz loss: [2.0838723  0.5052749  0.25716475 0.13214323]] [G loss: [-0.12203014 -3.8508244  -0.2656237   0.39944178]]\n",
            "Epoch: 30/35, [Dx loss: [-3.2074866  -6.6418715   3.0403197   0.03940667]] [Dz loss: [2.0165646  0.47149596 0.21134213 0.13337268]] [G loss: [ 0.6469802  -3.0770993  -0.19343229  0.39175117]]\n",
            "Epoch: 31/35, [Dx loss: [-3.0601752  -6.2072477   2.779333    0.03677404]] [Dz loss: [1.9201504  0.44480482 0.0734157  0.14019297]] [G loss: [ 1.0376751  -2.6837711  -0.07092886  0.37923753]]\n",
            "Epoch: 32/35, [Dx loss: [-3.0297937  -5.8596964   2.4650655   0.03648367]] [Dz loss: [1.8972601  0.42648825 0.04087723 0.14298944]] [G loss: [ 1.3348886  -2.3904057  -0.02489819  0.37501922]]\n",
            "Epoch: 33/35, [Dx loss: [-3.020139   -5.2978067   1.9126024   0.03650657]] [Dz loss: [2.0683823  0.34818107 0.16822162 0.15519795]] [G loss: [ 1.6590993  -1.8613614  -0.16618311  0.36866438]]\n",
            "Epoch: 34/35, [Dx loss: [-2.9769566  -4.3743496   1.0579633   0.03394298]] [Dz loss: [2.068285   0.24401256 0.33844778 0.1485825 ]] [G loss: [ 2.3525856  -0.9790916  -0.33015454  0.36618316]]\n",
            "Epoch: 35/35, [Dx loss: [-2.7658315  -3.8992324   0.82364357  0.03097569]] [Dz loss: [1.9842956  0.1492941  0.5396999  0.12953015]] [G loss: [ 2.456595   -0.74716425 -0.5372084   0.37409675]]\n",
            "precision 0.3894472876199108 Signal S-1\n",
            "recall 0.3467563233535998 Signal S-1\n",
            "Accuracy 0.9270122719923197 Signal S-1\n",
            "F1 0.36686402397983126 Signal S-1\n",
            "Epoch: 1/35, [Dx loss: [-4.239175   -8.814784    1.311938    0.32636714]] [Dz loss: [ 2.8356102 -0.3685575  2.270801   0.0933367]] [G loss: [ 4.920859   -1.320387   -1.8908885   0.81321347]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.075776  -10.676699    4.7280216   0.0872899]] [Dz loss: [-0.9583786  -0.15284072 -1.5293823   0.07238445]] [G loss: [10.139338  -4.578331   6.952138   0.7765531]]\n",
            "Epoch: 3/35, [Dx loss: [-4.4876947 -8.131057   2.5130641  0.1130297]] [Dz loss: [-2.9088695  -0.04165474 -3.8754964   0.10082811]] [G loss: [10.928491   -2.2670143   5.5481443   0.76473606]]\n",
            "Epoch: 4/35, [Dx loss: [-4.314995  -9.966812   4.665223   0.0986593]] [Dz loss: [ 9.890899   -0.02098869  9.001094    0.09107932]] [G loss: [-4.2739534 -4.7893524 -7.5048704  0.8020269]]\n",
            "Epoch: 5/35, [Dx loss: [ -4.9371696  -11.579644     5.6111765    0.10312998]] [Dz loss: [-21.519678     0.51596564 -22.767748     0.07321084]] [G loss: [43.605698   -4.976895   40.49755     0.80850434]]\n",
            "Epoch: 6/35, [Dx loss: [-3.8182855  -9.487829    4.9522843   0.07172598]] [Dz loss: [-75.32194      1.1914079  -81.04192      0.45285726]] [G loss: [97.39853    -5.075782   93.88235     0.85919684]]\n",
            "Epoch: 7/35, [Dx loss: [-2.5556064  -9.759504    6.720276    0.04836223]] [Dz loss: [12.111693   1.4390061  9.072649   0.1600038]] [G loss: [-3.6801877 -6.6771116 -5.080835   0.8077759]]\n",
            "Epoch: 8/35, [Dx loss: [-2.176348   -9.344374    6.9004006   0.02676258]] [Dz loss: [-1.4930842   1.4112821  -4.0052366   0.11008707]] [G loss: [16.773657  -6.9072156 15.484311   0.819656 ]]\n",
            "Epoch: 9/35, [Dx loss: [-1.8901441  -9.217165    6.871769    0.04552521]] [Dz loss: [-19.678816    1.6759214 -23.606628    0.225189 ]] [G loss: [28.71946    -6.674386   26.988367    0.84054804]]\n",
            "Epoch: 10/35, [Dx loss: [-1.9526575  -7.538462    5.131938    0.04538668]] [Dz loss: [-4.260309    1.775054   -7.484207    0.14488448]] [G loss: [11.588665   -4.5140424   8.004977    0.80977297]]\n",
            "Epoch: 11/35, [Dx loss: [-1.0655448 -7.6851816  6.372017   0.0247619]] [Dz loss: [-1.9260162   1.7532291  -5.0634937   0.13842463]] [G loss: [ 6.7214713 -6.6343036  5.145865   0.8209909]]\n",
            "Epoch: 12/35, [Dx loss: [ -1.585207   -13.39636     11.648198     0.01629556]] [Dz loss: [ 1.9068048   1.7112129  -1.7474581   0.19430493]] [G loss: [ -2.983149  -12.891909    1.7767591   0.8132001]]\n",
            "Epoch: 13/35, [Dx loss: [ -1.6933619  -17.397015    15.3209095    0.03827413]] [Dz loss: [-0.84655684  1.6330926  -3.8167343   0.13370845]] [G loss: [ -1.7825685  -14.248568     4.435209     0.80307895]]\n",
            "Epoch: 14/35, [Dx loss: [ -0.7923435  -12.749567    11.723799     0.02334239]] [Dz loss: [-3.3580105   1.6393092  -6.0768595   0.10795397]] [G loss: [  4.114504   -11.079035     6.875632     0.83179075]]\n",
            "Epoch: 15/35, [Dx loss: [-1.6093878  -5.598402    3.8275247   0.01614893]] [Dz loss: [-4.2254257   1.6858574  -6.9753366   0.10640534]] [G loss: [11.835922  -4.389326   7.7641287  0.846112 ]]\n",
            "Epoch: 16/35, [Dx loss: [ -1.9224972  -12.748346    10.374924     0.04509261]] [Dz loss: [ 1.2412934   1.7198598  -1.6537644   0.11751975]] [G loss: [ -0.26858747 -10.227677     1.9072813    0.80518085]]\n",
            "Epoch: 17/35, [Dx loss: [ -1.6368368  -14.571465    12.606352     0.03282713]] [Dz loss: [-3.0798295   1.7789997  -5.903218    0.10443888]] [G loss: [  2.5012932 -12.636242    7.0843925   0.8053143]]\n",
            "Epoch: 18/35, [Dx loss: [ -1.1393331  -17.290453    15.793716     0.03574033]] [Dz loss: [ -7.2025976    1.8657919  -10.581971     0.15135813]] [G loss: [  3.729751   -15.82067     11.008511     0.85419106]]\n",
            "Epoch: 19/35, [Dx loss: [ -1.9980571  -17.055477    14.850665     0.02067544]] [Dz loss: [-1.1855873   1.9553177  -4.2952223   0.11543174]] [G loss: [ -2.3162718 -14.768852    4.2469053   0.8205674]]\n",
            "Epoch: 20/35, [Dx loss: [ -0.87022513 -10.518277     9.392181     0.02558711]] [Dz loss: [ 0.7754053   1.8470936  -2.255666    0.11839779]] [G loss: [ 2.1926913 -8.541956   2.4790256  0.8255621]]\n",
            "Epoch: 21/35, [Dx loss: [-1.4844922   0.05369522 -1.8394024   0.0301215 ]] [Dz loss: [ 0.16288885  1.8254158  -2.7456162   0.10830893]] [G loss: [13.369488    2.3685448   3.0696363   0.79313064]]\n",
            "Epoch: 22/35, [Dx loss: [-0.9560506  -0.91714096 -0.23732515  0.01984155]] [Dz loss: [-1.3543146   1.8148139  -4.163608    0.09944794]] [G loss: [13.228922    0.20425296  4.41952     0.86051476]]\n",
            "Epoch: 23/35, [Dx loss: [ -0.90539324 -13.626045    12.537451     0.01831986]] [Dz loss: [-2.8976502   1.884507   -6.3170614   0.15349038]] [G loss: [  1.2678437 -13.85725     6.8165298   0.8308565]]\n",
            "Epoch: 24/35, [Dx loss: [-8.9244062e-01 -1.7905212e+01  1.6865891e+01  1.4688322e-02]] [Dz loss: [-3.0680518   1.9540821  -6.4674597   0.14453271]] [G loss: [ -1.3622773 -16.452038    6.8113575   0.8278403]]\n",
            "Epoch: 25/35, [Dx loss: [-1.011886   -5.8802004   4.58698     0.02813335]] [Dz loss: [-0.7182656   2.011332   -3.9959831   0.12663856]] [G loss: [ 7.3373966 -3.5295115  4.0358553  0.6831053]]\n",
            "Epoch: 26/35, [Dx loss: [-0.8869815  -1.7871828   0.74957144  0.01506301]] [Dz loss: [ 0.6361743   2.0243037  -2.3945522   0.10064224]] [G loss: [ 7.3932047  -0.9374056   2.4659169   0.58646935]]\n",
            "Epoch: 27/35, [Dx loss: [ -0.7823128 -13.30678    12.361       0.0163467]] [Dz loss: [ 1.4047556   1.9401478  -1.4132311   0.08778386]] [G loss: [ -7.873157   -13.268317     1.3927064    0.40024543]]\n",
            "Epoch: 28/35, [Dx loss: [-8.8381565e-01 -1.5231786e+01  1.4202257e+01  1.4571267e-02]] [Dz loss: [ 1.667503    1.8614416  -1.0971651   0.09032266]] [G loss: [-10.291998   -14.150177     1.0767254    0.27814534]]\n",
            "Epoch: 29/35, [Dx loss: [ -0.7174357  -11.26898     10.349983     0.02015606]] [Dz loss: [ 2.002094    1.7832896  -0.7784024   0.09972075]] [G loss: [-6.803372   -9.700721    0.78237987  0.2114968 ]]\n",
            "Epoch: 30/35, [Dx loss: [-0.8788389  -2.6481187   1.5206313   0.02486482]] [Dz loss: [ 2.2175975   1.7137394  -0.5485015   0.10523598]] [G loss: [ 0.9451326 -1.5143329  0.5825514  0.1876914]]\n",
            "Epoch: 31/35, [Dx loss: [-0.80529916 -9.601614    8.524266    0.02720488]] [Dz loss: [ 2.4088082   1.6283967  -0.36057773  0.11409891]] [G loss: [-7.410811   -9.345488    0.37237608  0.15623012]]\n",
            "Epoch: 32/35, [Dx loss: [ -0.90030974 -12.957982    11.867674     0.01899976]] [Dz loss: [ 2.481058    1.5283291  -0.22394475  0.11766733]] [G loss: [-10.011647   -11.634727     0.23054172   0.13925384]]\n",
            "Epoch: 33/35, [Dx loss: [-0.7920619  -8.458792    7.429869    0.02368623]] [Dz loss: [ 2.4536664   1.4696324  -0.1350608   0.11190941]] [G loss: [-5.372075   -6.855574    0.12991598  0.13535835]]\n",
            "Epoch: 34/35, [Dx loss: [-0.7941152  -1.22739     0.20719619  0.02260785]] [Dz loss: [ 2.5316322   1.3870121  -0.09155359  0.12361739]] [G loss: [1.3934243  0.09149384 0.08065245 0.12212779]]\n",
            "Epoch: 35/35, [Dx loss: [-0.65698755 -4.793456    3.9037266   0.02327415]] [Dz loss: [ 2.5916371   1.3812428  -0.07254128  0.12829356]] [G loss: [-4.0151873  -5.1383696   0.06864309  0.10545392]]\n",
            "precision 0.10427828371523432 Signal E-1\n",
            "recall 0.07707526769959236 Signal E-1\n",
            "Accuracy 0.9058132652617386 Signal E-1\n",
            "F1 0.08863655075848308 Signal E-1\n",
            "Epoch: 1/35, [Dx loss: [-1.6513903  -4.6376567   0.596295    0.23899707]] [Dz loss: [ 1.7696056  -0.91548604  1.9465189   0.07385729]] [G loss: [ 1.8249683  -0.59144145 -1.7088279   0.41252375]]\n",
            "Epoch: 2/35, [Dx loss: [-2.149239  -6.1308346  3.6133294  0.0368266]] [Dz loss: [ 1.4176081 -1.2685487  1.1311744  0.1554982]] [G loss: [ 7.359488   -3.4165366   6.131915    0.46441096]]\n",
            "Epoch: 3/35, [Dx loss: [-2.5728004  -6.28345     3.1786785   0.05319719]] [Dz loss: [-25.438616    -1.704475   -25.17136      0.14372161]] [G loss: [31.812769   -2.75557    29.59045     0.49778855]]\n",
            "Epoch: 4/35, [Dx loss: [-2.265255   -7.4647117   4.7144628   0.04849943]] [Dz loss: [ 5.955832   -1.912967    1.3859099   0.64828897]] [G loss: [-0.94330484 -4.8541784  -0.5633888   0.44742626]]\n",
            "Epoch: 5/35, [Dx loss: [-3.2344654  -8.737761    5.102738    0.04005565]] [Dz loss: [20.62669    -1.296235   17.411732    0.45111942]] [G loss: [-15.758671   -5.0698485 -14.027822    0.3338999]]\n",
            "Epoch: 6/35, [Dx loss: [-2.558592   -9.048386    6.2261972   0.02635958]] [Dz loss: [29.172253   -0.45738345 26.933346    0.26962942]] [G loss: [-3.7109897  -6.161717   -0.8017943   0.32525215]]\n",
            "Epoch: 7/35, [Dx loss: [-1.4624094 -6.1708913  4.3997393  0.0308744]] [Dz loss: [-45.936775     0.3948806  -47.937603     0.16059583]] [G loss: [69.78162    -3.9933589  70.152466    0.36225253]]\n",
            "Epoch: 8/35, [Dx loss: [-1.639981   -5.545023    3.5833092   0.03217328]] [Dz loss: [-2.8615766   0.783054   -5.0762477   0.14316157]] [G loss: [ 7.921613   -3.4221776   7.225478    0.41183132]]\n",
            "Epoch: 9/35, [Dx loss: [-0.93690264 -7.186423    6.039729    0.02097913]] [Dz loss: [10.40939     1.0137633   8.52579     0.08698363]] [G loss: [-4.297358   -6.1609116  -1.4856343   0.33491886]]\n",
            "Epoch: 10/35, [Dx loss: [-0.85811186 -7.4301696   6.3728456   0.01992102]] [Dz loss: [-14.882032     1.2586079  -16.918402     0.07777602]] [G loss: [26.280298   -6.3159447  29.439167    0.31570747]]\n",
            "Epoch: 11/35, [Dx loss: [-0.7031614  -5.8474245   4.9730744   0.01711885]] [Dz loss: [-71.16283      1.4650601  -76.38905      0.37611574]] [G loss: [87.54271    -4.687667   89.00795     0.32224226]]\n",
            "Epoch: 12/35, [Dx loss: [ -1.5797986  -12.267134    10.443252     0.02440855]] [Dz loss: [ 0.0730967   1.6886206  -2.9259832   0.13104592]] [G loss: [ -3.3931684  -11.237171     3.5742078    0.42697945]]\n",
            "Epoch: 13/35, [Dx loss: [-1.8482084  -9.752279    7.680827    0.02232462]] [Dz loss: [ 2.0820327   1.6522305  -0.86030686  0.12901096]] [G loss: [-2.0725107  -6.8211555   1.613806    0.31348392]]\n",
            "Epoch: 14/35, [Dx loss: [-0.40501744  3.1213968  -3.7347882   0.02083741]] [Dz loss: [-3.3707314   1.6975145  -6.254205    0.11859598]] [G loss: [14.66441    4.730335   6.7215705  0.3212505]]\n",
            "Epoch: 15/35, [Dx loss: [-1.4528219  -2.505712    0.7421483   0.03107417]] [Dz loss: [-2.9775348  1.6646328 -5.491181   0.0849013]] [G loss: [ 7.6050634  -1.5631152   5.854147    0.33140314]]\n",
            "Epoch: 16/35, [Dx loss: [ -0.53100777 -12.132053    11.375065     0.02259815]] [Dz loss: [-1.4896065   1.6665169  -4.4137096   0.12575868]] [G loss: [ -3.1690571 -11.42291     4.6664968   0.3587356]]\n",
            "Epoch: 17/35, [Dx loss: [-0.43405303 -9.543586    9.000348    0.01091846]] [Dz loss: [ 0.78652304  1.6188253  -2.2068532   0.13745509]] [G loss: [-3.51259    -9.0427265   2.2552996   0.32748365]]\n",
            "Epoch: 18/35, [Dx loss: [-0.47999555 -5.372799    4.751217    0.01415862]] [Dz loss: [ 1.4876922   1.6387434  -1.4638022   0.13127504]] [G loss: [ 1.1782708  -3.6920788   1.4296755   0.34406736]]\n",
            "Epoch: 19/35, [Dx loss: [-1.2619647   2.1097875  -3.589831    0.02180788]] [Dz loss: [ 1.6397358   1.6063383  -1.3284152   0.13618128]] [G loss: [9.147877   4.290064   1.3086362  0.35491762]]\n",
            "Epoch: 20/35, [Dx loss: [ -0.814929  16.97033  -18.027767   0.024251]] [Dz loss: [ 1.5838977   1.5278895  -1.1816951   0.12377034]] [G loss: [23.264608  18.51558    1.2268331  0.3522195]]\n",
            "Epoch: 21/35, [Dx loss: [ -0.79579    11.992498  -12.990407    0.0202118]] [Dz loss: [ 1.308833    1.4771088  -1.1521385   0.09838624]] [G loss: [17.045826   12.735708    1.2030445   0.31070724]]\n",
            "Epoch: 22/35, [Dx loss: [ -1.1520317  11.795103  -13.143086    0.0195951]] [Dz loss: [ 1.5485935   1.4414035  -0.9396676   0.10468572]] [G loss: [17.74872    13.513725    0.946477    0.32885158]]\n",
            "Epoch: 23/35, [Dx loss: [-1.1203380e+00  1.5781122e+01 -1.7048115e+01  1.4665405e-02]] [Dz loss: [ 1.7301992   1.3978255  -0.6647769   0.09971511]] [G loss: [21.394802   17.540504    0.6746565   0.31796408]]\n",
            "Epoch: 24/35, [Dx loss: [-8.1677401e-01  1.9770029e+01 -2.0772863e+01  1.8605750e-02]] [Dz loss: [ 1.7908394   1.3662016  -0.5926305   0.10172684]] [G loss: [24.40205    21.01727     0.6066249   0.27781567]]\n",
            "Epoch: 25/35, [Dx loss: [-8.6988449e-01  2.1439648e+01 -2.2457193e+01  1.4766298e-02]] [Dz loss: [ 2.0553212   1.3483782  -0.38374525  0.10906886]] [G loss: [25.27535    22.522728    0.40309423  0.23495275]]\n",
            "Epoch: 26/35, [Dx loss: [-6.6118389e-01  2.1165821e+01 -2.1983423e+01  1.5641559e-02]] [Dz loss: [ 2.131396    1.3073776  -0.22362319  0.10476415]] [G loss: [23.927132   21.954405    0.25438     0.17183459]]\n",
            "Epoch: 27/35, [Dx loss: [-7.67940223e-01  1.87987251e+01 -1.97032986e+01  1.36631625e-02]] [Dz loss: [ 2.1154456   1.2777729  -0.09342626  0.09310992]] [G loss: [20.932798   19.658407    0.09540467  0.1178987 ]]\n",
            "Epoch: 28/35, [Dx loss: [-7.62120366e-01  2.10210247e+01 -2.19169731e+01  1.33826155e-02]] [Dz loss: [ 2.088223    1.2797238  -0.01451974  0.08230197]] [G loss: [2.3084063e+01 2.2093332e+01 1.5468122e-02 9.7525991e-02]]\n",
            "Epoch: 29/35, [Dx loss: [-6.9199109e-01  1.8959164e+01 -1.9789589e+01  1.3843732e-02]] [Dz loss: [2.166844   1.318584   0.02304576 0.08252141]] [G loss: [ 2.0410896e+01  1.9479177e+01 -5.7130838e-03  9.3743272e-02]]\n",
            "Epoch: 30/35, [Dx loss: [-7.98348606e-01  1.31138535e+01 -1.40331745e+01  1.20971221e-02]] [Dz loss: [2.0846     1.2472032  0.04474127 0.07926558]] [G loss: [14.902866   14.136073   -0.02393445  0.07907262]]\n",
            "Epoch: 31/35, [Dx loss: [-8.5226500e-01  1.5378065e+01 -1.6389805e+01  1.5947552e-02]] [Dz loss: [2.159406   1.2572633  0.05992102 0.08422214]] [G loss: [17.13923    16.455902   -0.05747687  0.07408038]]\n",
            "Epoch: 32/35, [Dx loss: [ -0.8316701   14.171969   -15.163702     0.01600607]] [Dz loss: [2.0982525  1.2219503  0.04149622 0.0834806 ]] [G loss: [15.574919   14.959702   -0.02994352  0.06451602]]\n",
            "Epoch: 33/35, [Dx loss: [ -0.78011686  11.036107   -11.9556055    0.01393808]] [Dz loss: [2.0529513  1.1870612  0.03922285 0.0826667 ]] [G loss: [12.560249   11.961526   -0.03998833  0.06387111]]\n",
            "Epoch: 34/35, [Dx loss: [-7.93052137e-01  1.47053013e+01 -1.56414385e+01  1.43087730e-02]] [Dz loss: [2.1114612  1.2122238  0.03249577 0.08667419]] [G loss: [16.3592     15.757778   -0.02858553  0.06300084]]\n",
            "Epoch: 35/35, [Dx loss: [ -0.7493346   12.311588   -13.212352     0.01514255]] [Dz loss: [2.0633562  1.1549283  0.00807695 0.09003506]] [G loss: [ 1.3749284e+01  1.3190446e+01 -4.0720031e-03  5.6290906e-02]]\n",
            "precision 0.9356223431798032 Signal E-2\n",
            "recall 0.1560487368418855 Signal E-2\n",
            "Accuracy 0.8600398600745863 Signal E-2\n",
            "F1 0.2674847533954141 Signal E-2\n",
            "Epoch: 1/35, [Dx loss: [ 0.33410984 -2.3420413   0.6054057   0.20707452]] [Dz loss: [2.0133796  0.09235679 0.8243502  0.10966724]] [G loss: [ 0.14255458 -0.58300835 -0.8337902   0.15593532]]\n",
            "Epoch: 2/35, [Dx loss: [-0.07650274 -3.6872559   3.456948    0.01538047]] [Dz loss: [8.015463   0.13157395 6.6947145  0.11891735]] [G loss: [-3.1022067 -3.378359  -2.5521665  0.2828319]]\n",
            "Epoch: 3/35, [Dx loss: [ -0.9676485  -10.96121      9.437494     0.05560694]] [Dz loss: [-50.844505     0.50619864 -52.125935     0.07752245]] [G loss: [61.9225     -9.36053    68.000824    0.32822073]]\n",
            "Epoch: 4/35, [Dx loss: [  0.5565972  -11.187335    11.521316     0.02226149]] [Dz loss: [-15.062906    0.9317013 -18.86362     0.2869013]] [G loss: [ 10.79599    -11.703762    20.043455     0.24562961]]\n",
            "Epoch: 5/35, [Dx loss: [-1.8596146  -6.387925    4.1100903   0.04182207]] [Dz loss: [ 0.95177287  1.1437724  -3.606784    0.34147847]] [G loss: [ 1.786894   -3.2380571   3.3246307   0.17003207]]\n",
            "Epoch: 6/35, [Dx loss: [-2.4500458  -8.028777    5.2819343   0.02967975]] [Dz loss: [ 2.2731178   1.1537597  -0.1548155   0.12741742]] [G loss: [-3.893926   -5.4910307   0.17857218  0.1418532 ]]\n",
            "Epoch: 7/35, [Dx loss: [-0.4038759  -7.396978    6.780614    0.02124884]] [Dz loss: [2.8352916  1.1246959  0.61645234 0.10941429]] [G loss: [-5.6445565  -6.3629055  -0.5872963   0.13056454]]\n",
            "Epoch: 8/35, [Dx loss: [ -0.6318626   11.809289   -12.735119     0.02939693]] [Dz loss: [2.274753   1.1901263  0.03870797 0.10459182]] [G loss: [16.097355   14.236713    0.15296857  0.17076714]]\n",
            "Epoch: 9/35, [Dx loss: [ -0.06945478  10.794065   -11.081482     0.02179613]] [Dz loss: [ 1.9318914   1.1988739  -0.43002018  0.11630376]] [G loss: [11.67367    10.260822    0.5272612   0.08855854]]\n",
            "Epoch: 10/35, [Dx loss: [-2.0427566  -3.0495598   0.7562455   0.02505577]] [Dz loss: [ 1.908262    1.1782271  -0.55180293  0.12818381]] [G loss: [ 0.35560513 -1.09106     0.7748469   0.06718183]]\n",
            "Epoch: 11/35, [Dx loss: [-1.3426384  -5.33058     3.839114    0.01488266]] [Dz loss: [ 0.9544939   1.0852437  -1.2917738   0.11610238]] [G loss: [-2.110076   -4.102891    1.3804637   0.06123513]]\n",
            "Epoch: 12/35, [Dx loss: [ 0.02689509 -1.462219    1.387724    0.01013906]] [Dz loss: [ 0.56737673  0.9771056  -1.5128207   0.11030912]] [G loss: [ 1.7408836  -0.6257812   1.6708895   0.06957754]]\n",
            "Epoch: 13/35, [Dx loss: [ -0.48309606  14.238027   -15.033496     0.03123709]] [Dz loss: [ 1.6430571   0.84401655 -0.594877    0.13939178]] [G loss: [17.516735   16.045776    0.6479954   0.08229657]]\n",
            "Epoch: 14/35, [Dx loss: [ -0.43383017  12.025991   -12.61268      0.01528588]] [Dz loss: [2.43434    0.8045176  0.13157123 0.14982508]] [G loss: [12.318333   11.917869   -0.12039721  0.05208627]]\n",
            "Epoch: 15/35, [Dx loss: [ 0.34067404  4.9133425  -4.683329    0.01106613]] [Dz loss: [2.6421602  0.7457854  0.5332012  0.13631734]] [G loss: [ 4.2481294   4.205805   -0.5169759   0.05593003]]\n",
            "Epoch: 16/35, [Dx loss: [-1.0516679  -2.8602226   1.6350925   0.01734618]] [Dz loss: [2.582581   0.68596613 0.7331761  0.11634384]] [G loss: [-2.088091   -1.9708767  -0.7024599   0.05852457]]\n",
            "Epoch: 17/35, [Dx loss: [-1.1608846 -3.8346112  2.5500681  0.0123658]] [Dz loss: [2.3749788  0.7810641  0.4889218  0.11049938]] [G loss: [-2.1592338  -2.3701177  -0.3672334   0.05781173]]\n",
            "Epoch: 18/35, [Dx loss: [-0.21857409  0.5790549  -0.8728881   0.0075259 ]] [Dz loss: [ 1.5763396   0.84773695 -0.34612378  0.10747262]] [G loss: [2.2962282  1.1364496  0.4998919  0.06598864]]\n",
            "Epoch: 19/35, [Dx loss: [ 0.70817953  7.186805   -6.621928    0.0143304 ]] [Dz loss: [ 1.1627386   0.96339256 -0.75630605  0.09556523]] [G loss: [9.499262   8.118793   0.8130854  0.05673837]]\n",
            "Epoch: 20/35, [Dx loss: [-1.1016595e+00  2.2713398e+01 -2.4035366e+01  2.2030752e-02]] [Dz loss: [ 1.8573122   1.0510644  -0.28906015  0.10953076]] [G loss: [24.900124   24.131147    0.27343     0.04955453]]\n",
            "Epoch: 21/35, [Dx loss: [-5.4742736e-01  1.5984116e+01 -1.6642559e+01  1.1101229e-02]] [Dz loss: [ 2.3881433   0.9996728  -0.09145838  0.14799294]] [G loss: [16.890907   16.4198      0.0951428   0.03759655]]\n",
            "Epoch: 22/35, [Dx loss: [ 7.9879177e-01  1.5444727e+01 -1.4738419e+01  9.2484942e-03]] [Dz loss: [2.6010737  0.9238804  0.02191774 0.16552758]] [G loss: [ 1.5207644e+01  1.4734984e+01 -1.0767878e-02  4.8342813e-02]]\n",
            "Epoch: 23/35, [Dx loss: [  0.1641927   14.969508   -14.966629     0.01613123]] [Dz loss: [2.7562618  0.85833967 0.09998146 0.17979404]] [G loss: [15.023804   14.589714   -0.09001435  0.05241033]]\n",
            "Epoch: 24/35, [Dx loss: [ -1.5596863   8.409235  -10.17385     0.0204928]] [Dz loss: [2.8562872  0.7600286  0.2014869  0.18947707]] [G loss: [10.501815   10.251066   -0.2133721   0.04641216]]\n",
            "Epoch: 25/35, [Dx loss: [-1.0501478   8.636117   -9.845819    0.01595556]] [Dz loss: [2.813105   0.72239125 0.26070473 0.1830009 ]] [G loss: [ 9.911852    9.759668   -0.25931984  0.04115038]]\n",
            "Epoch: 26/35, [Dx loss: [-0.05491931  8.561594   -8.721744    0.01052288]] [Dz loss: [2.6920705  0.672329   0.25951272 0.17602292]] [G loss: [ 9.004647    8.800225   -0.24571022  0.04501315]]\n",
            "Epoch: 27/35, [Dx loss: [ 0.39189947  9.97803    -9.718882    0.01327505]] [Dz loss: [2.7840595  0.6172206  0.24690792 0.19199312]] [G loss: [ 9.67734     9.363273   -0.26221913  0.05762854]]\n",
            "Epoch: 28/35, [Dx loss: [-1.0545031   6.8716736  -8.125432    0.01992539]] [Dz loss: [2.662166   0.6134102  0.23379692 0.18149592]] [G loss: [ 9.151704    8.866555   -0.2309809   0.05161301]]\n",
            "Epoch: 29/35, [Dx loss: [ -0.37775442  10.69215    -11.205255     0.01353513]] [Dz loss: [2.6070023  0.51366353 0.36458942 0.17287494]] [G loss: [11.197826   11.228071   -0.38017294  0.03499271]]\n",
            "Epoch: 30/35, [Dx loss: [ 3.2612976e-01  1.2914358e+01 -1.2711968e+01  1.2374285e-02]] [Dz loss: [2.4535909  0.4626282  0.36053288 0.16304296]] [G loss: [13.290911   13.237675   -0.37379113  0.04270271]]\n",
            "Epoch: 31/35, [Dx loss: [-9.0113181e-01  2.0203615e+01 -2.1280384e+01  1.7563406e-02]] [Dz loss: [2.446981   0.44646364 0.3903344  0.16101828]] [G loss: [21.500498   21.424753   -0.3792415   0.04549849]]\n",
            "Epoch: 32/35, [Dx loss: [-7.2325766e-01  1.6262760e+01 -1.7109259e+01  1.2324200e-02]] [Dz loss: [2.467584  0.4120245 0.498307  0.1557252]] [G loss: [16.606525   16.722649   -0.5216128   0.04054878]]\n",
            "Epoch: 33/35, [Dx loss: [-1.6964695e-01  1.5754196e+01 -1.6053600e+01  1.2975921e-02]] [Dz loss: [2.4581969  0.3816411  0.63955575 0.14370003]] [G loss: [16.339334  16.601131  -0.6358956  0.0374099]]\n",
            "Epoch: 34/35, [Dx loss: [ 1.02442935e-01  2.03112431e+01 -2.03983879e+01  1.89586040e-02]] [Dz loss: [2.4112506  0.39061147 0.725067   0.1295572 ]] [G loss: [20.134142   20.398329   -0.68827593  0.04240883]]\n",
            "Epoch: 35/35, [Dx loss: [ -0.4158074   16.293144   -16.956604     0.02476557]] [Dz loss: [2.3429368  0.4437502  0.637714   0.12614721]] [G loss: [16.580292   16.738077   -0.5936894   0.04359062]]\n",
            "precision 1.0 Signal E-3\n",
            "recall 0.036425916752774366 Signal E-3\n",
            "Accuracy 0.6273778012582504 Signal E-3\n",
            "F1 0.07029140465128544 Signal E-3\n",
            "Epoch: 1/35, [Dx loss: [-0.9641733  -3.9183643   0.5992493   0.23549426]] [Dz loss: [ 2.350331   -0.70905733  2.2484152   0.08109728]] [G loss: [ 0.62289363 -0.59291923 -2.0203316   0.32361442]]\n",
            "Epoch: 2/35, [Dx loss: [-2.4175484  -7.265039    4.186465    0.06610266]] [Dz loss: [ 2.9867692  -0.711856    2.469603    0.12290212]] [G loss: [ 3.236845   -4.263733    4.1276016   0.33729765]]\n",
            "Epoch: 3/35, [Dx loss: [-1.5080019  -9.950959    8.138385    0.03045706]] [Dz loss: [-15.525246    -1.0733904  -15.719198     0.12673475]] [G loss: [15.039055   -8.88655    21.033413    0.28921905]]\n",
            "Epoch: 4/35, [Dx loss: [ -2.1982083  -12.951994    10.32862      0.04251663]] [Dz loss: [12.694574  -1.3117284  8.63756    0.5368741]] [G loss: [-14.19711     -9.463522    -7.094084     0.23604953]]\n",
            "Epoch: 5/35, [Dx loss: [ -1.8835933  -10.698045     8.521212     0.02932378]] [Dz loss: [40.239834   -0.5929602  37.430695    0.34020978]] [G loss: [-27.628311    -8.3988085  -21.84297      0.26134697]]\n",
            "Epoch: 6/35, [Dx loss: [-1.8943536  -9.250097    6.9880233   0.03677213]] [Dz loss: [-85.00975      0.38456827 -88.175095     0.27807564]] [G loss: [109.11322     -6.9741316  113.81965      0.22677073]]\n",
            "Epoch: 7/35, [Dx loss: [ -1.8319407  -12.922638    10.678082     0.04126136]] [Dz loss: [-23.609173     1.24667    -27.12002      0.22641763]] [G loss: [ 20.873995   -10.685123    29.499681     0.20594358]]\n",
            "Epoch: 8/35, [Dx loss: [-1.8051145 -9.501596   7.4066877  0.0289795]] [Dz loss: [ 3.116604    1.4959376  -1.0429515   0.26636183]] [G loss: [-1.908405   -6.9341483   2.8727825   0.21529615]]\n",
            "Epoch: 9/35, [Dx loss: [-1.6891747  -6.781311    4.7827597   0.03093757]] [Dz loss: [-3.8363671   1.534149   -7.528657    0.21581392]] [G loss: [ 6.0225353  -4.8383512   8.669845    0.21910417]]\n",
            "Epoch: 10/35, [Dx loss: [-1.0663247  -9.057748    7.808963    0.01824584]] [Dz loss: [-3.1080399   1.5600137  -6.0719037   0.14038517]] [G loss: [ 1.5452356  -8.101404    7.032047    0.26145926]]\n",
            "Epoch: 11/35, [Dx loss: [ -1.2142265  -15.288803    13.844667     0.02299109]] [Dz loss: [-1.3067588   1.5373127  -4.3758316   0.15317604]] [G loss: [ -6.3710246  -13.830034     4.942341     0.25166708]]\n",
            "Epoch: 12/35, [Dx loss: [-1.0364404 -8.209528   6.98998    0.0183106]] [Dz loss: [-0.8229081   1.4861968  -3.5774198   0.12683152]] [G loss: [-0.5771229 -6.629384   3.912717   0.2139544]]\n",
            "Epoch: 13/35, [Dx loss: [-1.1226661  -6.5703316   5.243966    0.02036993]] [Dz loss: [-0.35846898  1.5247322  -2.9111524   0.10279508]] [G loss: [ 0.36799467 -5.0557795   3.209518    0.22142567]]\n",
            "Epoch: 14/35, [Dx loss: [-1.0790368  -4.373469    3.0877945   0.02066378]] [Dz loss: [ 0.6840192   1.5691664  -1.942803    0.10576557]] [G loss: [ 1.5409441  -2.8255534   2.1654923   0.22010054]]\n",
            "Epoch: 15/35, [Dx loss: [-0.84558946 -6.235038    5.1744127   0.02150351]] [Dz loss: [ 1.5965364   1.6058178  -0.9397017   0.09304199]] [G loss: [-2.2252996  -5.4107194   0.99130595  0.2194114 ]]\n",
            "Epoch: 16/35, [Dx loss: [-1.1914755  -8.604361    7.129172    0.02837158]] [Dz loss: [ 1.4461395   1.6305208  -1.2131988   0.10288171]] [G loss: [-3.0806532  -6.6752143   1.3465543   0.22480068]]\n",
            "Epoch: 17/35, [Dx loss: [-0.31914863 -2.321043    1.829722    0.01721719]] [Dz loss: [ 0.5623801   1.6429096  -1.9362589   0.08557295]] [G loss: [ 3.132442   -1.0252807   1.9558134   0.22019094]]\n",
            "Epoch: 18/35, [Dx loss: [-0.70845723  1.9777533  -2.854735    0.01685244]] [Dz loss: [ 1.0612234   1.6523101  -1.4785217   0.08874352]] [G loss: [6.704123   2.98961    1.616899   0.20976144]]\n",
            "Epoch: 19/35, [Dx loss: [-1.0283507   1.9277003  -3.1684825   0.02124319]] [Dz loss: [ 1.434477    1.7036717  -1.1520903   0.08828954]] [G loss: [6.7429414  3.410808   1.2252676  0.21068655]]\n",
            "Epoch: 20/35, [Dx loss: [-1.1773959   1.9673399  -3.3449674   0.02002313]] [Dz loss: [ 1.4892352   1.6750215  -1.0166061   0.08308201]] [G loss: [5.928481   3.036639   1.0808989  0.18109435]]\n",
            "Epoch: 21/35, [Dx loss: [-0.03247916 -4.899582    4.703448    0.01636549]] [Dz loss: [ 1.7283748   1.6574482  -0.7411979   0.08121243]] [G loss: [-2.9213343  -5.4469213   0.74952316  0.17760636]]\n",
            "Epoch: 22/35, [Dx loss: [-0.67710423 -9.229278    8.366289    0.01858854]] [Dz loss: [ 1.9993109   1.5934745  -0.43869346  0.08445302]] [G loss: [-6.345112   -8.065152    0.46936548  0.12506738]]\n",
            "Epoch: 23/35, [Dx loss: [ -0.467203  -10.335889    9.75539     0.0113293]] [Dz loss: [ 1.9950145   1.5643446  -0.38961506  0.08202849]] [G loss: [-8.121935   -9.608456    0.4071508   0.10793695]]\n",
            "Epoch: 24/35, [Dx loss: [-0.7110935  -5.597991    4.794047    0.00928513]] [Dz loss: [ 1.9449127   1.4964273  -0.34454197  0.07930274]] [G loss: [-3.3727303  -4.554828    0.34179464  0.08403036]]\n",
            "Epoch: 25/35, [Dx loss: [-0.5305674  -4.0542517   3.4150639   0.01086204]] [Dz loss: [ 2.035093    1.4472163  -0.21818297  0.08060599]] [G loss: [-2.2589862  -3.2819543   0.2256218   0.07973465]]\n",
            "Epoch: 26/35, [Dx loss: [-0.4994979  -4.586625    3.9826083   0.01045181]] [Dz loss: [ 2.0072248   1.3774266  -0.15249774  0.07822957]] [G loss: [-3.3129668  -4.2455707   0.15422009  0.07783835]]\n",
            "Epoch: 27/35, [Dx loss: [-0.66215754 -6.749011    5.981794    0.0105058 ]] [Dz loss: [ 2.0329497   1.3926613  -0.13541302  0.07757014]] [G loss: [-5.437092   -6.220332    0.1374979   0.06457431]]\n",
            "Epoch: 28/35, [Dx loss: [-0.56451035 -6.4484396   5.7732224   0.01107079]] [Dz loss: [ 2.1056771   1.3624054  -0.06254875  0.08058203]] [G loss: [-4.8493896  -5.4966593   0.06469376  0.05825759]]\n",
            "Epoch: 29/35, [Dx loss: [-0.6550214  -5.5989027   4.850238    0.00936431]] [Dz loss: [ 2.0669436   1.3283899  -0.03986408  0.07784181]] [G loss: [-4.3151636  -4.9996567   0.03739047  0.06471021]]\n",
            "Epoch: 30/35, [Dx loss: [-0.68424827 -7.533152    6.744766    0.01041396]] [Dz loss: [ 2.1283      1.312079   -0.0219021   0.08381227]] [G loss: [-6.2042365  -6.8644967   0.0309921   0.06292681]]\n",
            "Epoch: 31/35, [Dx loss: [-0.45395294 -5.2696276   4.7175145   0.00981612]] [Dz loss: [2.2106183  1.261266   0.00521562 0.09441368]] [G loss: [-3.6524622e+00 -4.2184114e+00 -1.3600430e-03  5.6730915e-02]]\n",
            "Epoch: 32/35, [Dx loss: [-0.5915833  -1.1503534   0.46112627  0.00976438]] [Dz loss: [2.1847847  1.178838   0.02533938 0.09806073]] [G loss: [-0.02454323 -0.56988966 -0.02811334  0.05734598]]\n",
            "Epoch: 33/35, [Dx loss: [-0.57693344 -6.3066077   5.596972    0.01327022]] [Dz loss: [2.1973221  1.165005   0.04113824 0.09911788]] [G loss: [-5.478184   -5.994979   -0.03841158  0.05552061]]\n",
            "Epoch: 34/35, [Dx loss: [-0.56527346 -6.9350386   6.2709417   0.00988241]] [Dz loss: [2.247947   1.1114343  0.04554255 0.10909706]] [G loss: [-5.5834866  -6.0356426  -0.05106218  0.05032178]]\n",
            "Epoch: 35/35, [Dx loss: [-0.6697349   0.37999043 -1.1674821   0.01177568]] [Dz loss: [2.3409104  1.0577681  0.06617053 0.1216972 ]] [G loss: [ 2.1728203   1.7210879  -0.06854253  0.05202749]]\n",
            "precision nan Signal E-4\n",
            "recall 0.0 Signal E-4\n",
            "Accuracy 0.663474195343434 Signal E-4\n",
            "F1 nan Signal E-4\n",
            "Epoch: 1/35, [Dx loss: [-4.5880113  -8.813067    0.82388306  0.34011728]] [Dz loss: [ 3.6354954  -0.63405466  3.2192302   0.10503205]] [G loss: [ 5.6143193  -0.82466936 -2.9226577   0.93616456]]\n",
            "Epoch: 2/35, [Dx loss: [ -6.8088036 -10.219721    1.9300003   0.1480916]] [Dz loss: [15.44628   -0.4884398 15.2443905  0.0690331]] [G loss: [ 1.5474467  -1.0201323  -4.737618    0.73051965]]\n",
            "Epoch: 3/35, [Dx loss: [ -7.126542   -13.201853     4.350905     0.17244038]] [Dz loss: [-30.055878    -0.48962227 -30.451405     0.08851521]] [G loss: [55.69421   -5.2242756 53.629105   0.7289381]]\n",
            "Epoch: 4/35, [Dx loss: [ -7.247248   -16.263903     7.2725053    0.17441504]] [Dz loss: [17.80079    -0.5864056  12.808864    0.55783314]] [G loss: [ 1.0632269 -7.344434   1.591996   0.6815665]]\n",
            "Epoch: 5/35, [Dx loss: [ -4.809568   -12.441115     6.77409      0.08574601]] [Dz loss: [55.57572    -0.46686068 53.273846    0.27687326]] [G loss: [-39.827515    -6.436423   -40.091198     0.67001086]]\n",
            "Epoch: 6/35, [Dx loss: [-2.936577   -8.420515    5.008158    0.04757818]] [Dz loss: [66.35814     0.16886178 65.23413     0.09551396]] [G loss: [-32.424583    -4.391321   -34.651253     0.66179913]]\n",
            "Epoch: 7/35, [Dx loss: [-4.111076   -6.3150215   0.89490986  0.13090359]] [Dz loss: [-265.51498      1.2189063 -271.46753      0.4733573]] [G loss: [331.53815     -0.46379593 325.16965      0.6832302 ]]\n",
            "Epoch: 8/35, [Dx loss: [-4.511842  -6.2713556  0.7695195  0.0989994]] [Dz loss: [-460.806        2.1473427 -478.1036       1.5150311]] [G loss: [552.4701     -1.0167584 546.6255      0.686138 ]]\n",
            "Epoch: 9/35, [Dx loss: [-2.5357633  -6.620333    3.5916042   0.04929657]] [Dz loss: [-460.27554      3.0274434 -514.843        5.154009 ]] [G loss: [575.29926     -3.283864   571.9704       0.66127324]]\n",
            "Epoch: 10/35, [Dx loss: [ -1.9118416  -10.523442     8.433348     0.01782529]] [Dz loss: [-181.9823       3.60667   -211.56828      2.5979323]] [G loss: [230.65646    -9.996061  233.91158     0.6740944]]\n",
            "Epoch: 11/35, [Dx loss: [ -2.4373367  -22.83506     19.933807     0.04639151]] [Dz loss: [-456.53793      4.023959  -485.90137      2.5339503]] [G loss: [562.2114    -19.211199  574.8019      0.6620773]]\n",
            "Epoch: 12/35, [Dx loss: [ -1.5164697  -11.153126     9.415754     0.02209002]] [Dz loss: [-533.52814     4.974328 -673.3556     13.485326]] [G loss: [ 7.3263251e+02 -7.9781113e+00  7.3407416e+02  6.5364826e-01]]\n",
            "Epoch: 13/35, [Dx loss: [ -1.4376198  -10.871533     9.241362     0.01925524]] [Dz loss: [-226.78992     5.745982 -321.64142     8.910552]] [G loss: [341.9192    -11.35203   346.68372     0.6587505]]\n",
            "Epoch: 14/35, [Dx loss: [-1.4519856e+00 -2.5935421e+01  2.4229931e+01  2.5350805e-02]] [Dz loss: [-480.212       6.663479 -606.7211     11.984569]] [G loss: [636.55664    -24.260506   654.2286       0.65886676]]\n",
            "Epoch: 15/35, [Dx loss: [-1.0309055e+00 -2.0329779e+01  1.9136662e+01  1.6220931e-02]] [Dz loss: [-189.63867      7.6314173 -302.81476     10.554468 ]] [G loss: [300.52173    -18.20893    312.2021       0.65286124]]\n",
            "Epoch: 16/35, [Dx loss: [-8.4564435e-01 -1.2674429e+01  1.1737215e+01  9.1572059e-03]] [Dz loss: [-258.03583      7.7837663 -335.31308      6.949346 ]] [G loss: [378.93054    -12.222881   384.53796      0.66154695]]\n",
            "Epoch: 17/35, [Dx loss: [ -0.99072886 -14.110945    12.907866     0.02123465]] [Dz loss: [-494.1845      8.480731 -615.6134     11.294817]] [G loss: [ 6.6669592e+02 -1.2463556e+01  6.7256201e+02  6.5974396e-01]]\n",
            "Epoch: 18/35, [Dx loss: [ -0.85028154 -11.776476    10.696588     0.02296054]] [Dz loss: [-108.27468     8.931889 -260.8785     14.367193]] [G loss: [257.79816   -9.947489 261.13132    0.661435]]\n",
            "Epoch: 19/35, [Dx loss: [ -1.3435905  -14.189837    12.661371     0.01848785]] [Dz loss: [ -27.455633    8.577866 -155.12834    11.909483]] [G loss: [163.61517   -14.343517  171.40987     0.6548836]]\n",
            "Epoch: 20/35, [Dx loss: [ -1.6827335  -18.621515    16.653961     0.02848246]] [Dz loss: [ -83.136475    7.787332 -189.90988     9.898608]] [G loss: [191.97815   -15.592141  200.91583     0.6654471]]\n",
            "Epoch: 21/35, [Dx loss: [ -0.902387   -16.937754    15.842978     0.01923883]] [Dz loss: [ -88.11523      7.734069  -177.27847      8.1429205]] [G loss: [172.95815   -16.210405  182.71582     0.6452718]]\n",
            "Epoch: 22/35, [Dx loss: [-8.3012408e-01 -2.1430206e+01  2.0389166e+01  2.1091336e-02]] [Dz loss: [ -45.80488      7.6122255 -133.06389      7.964679 ]] [G loss: [120.88359   -19.961946  134.10388     0.6741663]]\n",
            "Epoch: 23/35, [Dx loss: [-1.8725249e+00 -2.4519245e+01  2.2471577e+01  1.7514497e-02]] [Dz loss: [ -6.9518304   7.4000382 -69.08621     5.4734344]] [G loss: [ 53.611904 -23.363672  70.05145    0.692413]]\n",
            "Epoch: 24/35, [Dx loss: [-7.3041207e-01 -2.9647791e+01  2.8784796e+01  1.3257610e-02]] [Dz loss: [  2.3665128   7.1883545 -42.361282    3.753944 ]] [G loss: [ 22.075066   -28.025385    43.31157      0.67888767]]\n",
            "Epoch: 25/35, [Dx loss: [ -2.3398135  -24.154911    21.360361     0.04547323]] [Dz loss: [  6.7551055   6.7985907 -41.27922     4.1235743]] [G loss: [ 28.411623  -21.404465   43.23271     0.6583373]]\n",
            "Epoch: 26/35, [Dx loss: [-1.2307874e+00 -2.5039257e+01  2.3584682e+01  2.2379678e-02]] [Dz loss: [ -4.7169557   6.6027083 -48.749615    3.7429955]] [G loss: [ 31.321665  -23.290693   48.052254    0.6560099]]\n",
            "Epoch: 27/35, [Dx loss: [-1.0447080e+00 -1.7422014e+01  1.6222927e+01  1.5437757e-02]] [Dz loss: [ 23.48454    6.40287  -32.44564    4.952731]] [G loss: [ 24.845495   -15.668491    33.57974      0.69342506]]\n",
            "Epoch: 28/35, [Dx loss: [-8.9496166e-01 -1.6539406e+01  1.5544538e+01  9.9906102e-03]] [Dz loss: [ 28.995901    6.187819  -24.705502    4.7513585]] [G loss: [ 16.094673   -15.893802    25.120012     0.68684614]]\n",
            "Epoch: 29/35, [Dx loss: [ -1.0660851 -19.14515    17.833471    0.0245597]] [Dz loss: [ 27.327728    5.9667783 -18.697655    4.0058603]] [G loss: [  8.336179  -17.28997    18.764538    0.6861611]]\n",
            "Epoch: 30/35, [Dx loss: [ -1.0306436  -15.650133    14.311688     0.03077994]] [Dz loss: [ 26.188955   5.628203 -13.40489    3.396564]] [G loss: [  5.37251   -14.824139   13.091476    0.7105171]]\n",
            "Epoch: 31/35, [Dx loss: [-1.1319231e+00 -2.1527225e+01  2.0210300e+01  1.8500229e-02]] [Dz loss: [22.830637   5.4706297 -9.851703   2.7211707]] [G loss: [ -3.571418  -20.175045    9.760213    0.6843413]]\n",
            "Epoch: 32/35, [Dx loss: [-9.1867858e-01 -2.3535557e+01  2.2524803e+01  9.2074126e-03]] [Dz loss: [21.611544   5.21521   -7.198976   2.3595307]] [G loss: [ -8.476627  -22.927053    7.2662697   0.7184158]]\n",
            "Epoch: 33/35, [Dx loss: [ -3.5897725  -23.033415    18.704098     0.07395481]] [Dz loss: [20.52152    5.0263376 -5.6756563  2.1170835]] [G loss: [ -5.4756255  -17.608185     5.5030203    0.66295403]]\n",
            "Epoch: 34/35, [Dx loss: [ -1.368419   -11.429312     9.822271     0.02386199]] [Dz loss: [19.760235   4.742648  -4.2347255  1.9252316]] [G loss: [ 2.1638677  -9.073506    4.068234    0.71691406]]\n",
            "Epoch: 35/35, [Dx loss: [-0.52285475 -2.9853199   2.3398547   0.01226105]] [Dz loss: [16.189518   4.64603   -3.9033985  1.5446885]] [G loss: [ 7.727553   -3.1660085   3.8960304   0.69975305]]\n",
            "precision 0.27536239420209535 Signal E-5\n",
            "recall 0.23750011031537757 Signal E-5\n",
            "Accuracy 0.9464608650311954 Signal E-5\n",
            "F1 0.25503365297189917 Signal E-5\n",
            "Epoch: 1/35, [Dx loss: [-4.053137   -8.9338455   1.3597146   0.35209966]] [Dz loss: [ 3.0295389  -0.44023865  2.746993    0.07227846]] [G loss: [ 4.9421625  -1.4074452  -2.4137726   0.87633806]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.6568108  -10.458624     3.7636318    0.10381812]] [Dz loss: [ 0.3517363  -0.4271389  -1.0123892   0.17912634]] [G loss: [ 9.656351   -3.146891    7.745314    0.50579286]]\n",
            "Epoch: 3/35, [Dx loss: [-4.83146    -5.919547   -0.19067374  0.12787601]] [Dz loss: [-19.792301    -0.62197995 -20.799313     0.16289939]] [G loss: [30.064781   -0.03266692 24.87779     0.52196616]]\n",
            "Epoch: 4/35, [Dx loss: [ -5.494288  -10.883265    4.3399096   0.1049066]] [Dz loss: [14.814458   -0.75061136  8.992968    0.65721023]] [G loss: [-6.271718  -4.355976  -7.031288   0.5115546]]\n",
            "Epoch: 5/35, [Dx loss: [ -5.6557946 -12.841911    6.026174    0.1159942]] [Dz loss: [45.46981    -0.13683702 44.344326    0.12623104]] [G loss: [-26.07253     -6.116851   -25.161375     0.52056956]]\n",
            "Epoch: 6/35, [Dx loss: [ -3.83075    -11.271522     6.6729746    0.07677973]] [Dz loss: [-195.35211      1.0128162 -209.5969       1.3231959]] [G loss: [266.21472    -5.6877728 266.78262     0.5119898]]\n",
            "Epoch: 7/35, [Dx loss: [-5.63164     1.8201911  -8.89381     0.14419802]] [Dz loss: [-57.203136    2.3298726 -81.94999     2.2416985]] [G loss: [116.557205    9.033718  102.24703     0.5276459]]\n",
            "Epoch: 8/35, [Dx loss: [-5.4648104   0.9006877  -7.4421945   0.10766955]] [Dz loss: [-12.333482     2.5465553  -15.975161     0.10951203]] [G loss: [42.167995    7.527253   29.46841     0.51723284]]\n",
            "Epoch: 9/35, [Dx loss: [-5.4308624  -4.5196047  -1.9629968   0.10517398]] [Dz loss: [-11.426453     2.4982529  -15.922793     0.19980884]] [G loss: [25.797085   1.4438925 19.350231   0.5002962]]\n",
            "Epoch: 10/35, [Dx loss: [-5.7943087  -9.943425    3.0191898   0.11299278]] [Dz loss: [-15.016718     2.379085   -19.739632     0.23438291]] [G loss: [24.152262   -3.0343702  22.192247    0.49943858]]\n",
            "Epoch: 11/35, [Dx loss: [-6.1719885  -9.620499    2.3542073   0.10943055]] [Dz loss: [-15.259807     2.4791322  -22.232052     0.44931117]] [G loss: [27.486937   -2.2969112  24.60526     0.51785827]]\n",
            "Epoch: 12/35, [Dx loss: [-6.1177382  -8.97445     1.7128102   0.11439006]] [Dz loss: [ -6.8298745    2.3495908  -11.475149     0.22956845]] [G loss: [15.340123   -1.722454   12.111516    0.49510622]]\n",
            "Epoch: 13/35, [Dx loss: [-5.9398804  -8.622958    1.4646523   0.12184252]] [Dz loss: [-0.6841027   2.3253217  -5.493434    0.24840097]] [G loss: [ 9.6431465 -1.414484   5.878442   0.5179189]]\n",
            "Epoch: 14/35, [Dx loss: [-5.8013067 -8.743067   1.377114   0.1564646]] [Dz loss: [-2.3374794  2.2973783 -8.065983   0.3431125]] [G loss: [11.863807  -1.4075913  8.170891   0.5100507]]\n",
            "Epoch: 15/35, [Dx loss: [-5.506615   -8.323198    1.5103369   0.13062459]] [Dz loss: [ -8.470007     2.3153489  -14.306376     0.35210198]] [G loss: [18.622982  -1.4450341 15.008858   0.5059158]]\n",
            "Epoch: 16/35, [Dx loss: [-5.9376855  -8.650236    1.3010061   0.14115438]] [Dz loss: [-3.8535552   2.373177   -8.814814    0.25880817]] [G loss: [12.978006   -1.328331    9.211855    0.50944823]]\n",
            "Epoch: 17/35, [Dx loss: [-5.868156  -8.466835   1.2582436  0.1340436]] [Dz loss: [ 0.05214161  2.3631706  -3.7921567   0.14811276]] [G loss: [ 7.7269564  -1.2614353   3.9994879   0.49889034]]\n",
            "Epoch: 18/35, [Dx loss: [-5.81024    -8.37615     1.294753    0.12711567]] [Dz loss: [-1.5452344   2.2570655  -5.623921    0.18216212]] [G loss: [ 9.800539  -1.2647461  6.0273566  0.5037928]]\n",
            "Epoch: 19/35, [Dx loss: [-5.8792105  -8.446592    1.2416494   0.13257335]] [Dz loss: [-4.34856     2.2485366  -9.525776    0.29286796]] [G loss: [14.041316 -1.233278 10.144855  0.512974]]\n",
            "Epoch: 20/35, [Dx loss: [-6.0119286  -8.503771    1.2179619   0.12738807]] [Dz loss: [ -5.665227     2.2539651  -11.776304     0.38571134]] [G loss: [16.178045   -1.2022896  12.40463     0.49757037]]\n",
            "Epoch: 21/35, [Dx loss: [-6.0702415 -8.494322   1.156666   0.1267415]] [Dz loss: [ -5.740798    2.2711892 -11.649257    0.363727 ]] [G loss: [16.332674  -1.1386657 12.407422   0.5063919]]\n",
            "Epoch: 22/35, [Dx loss: [-6.142043   -8.463365    1.0520523   0.12692678]] [Dz loss: [-4.1297975   2.256904   -7.8304014   0.14437017]] [G loss: [12.572388  -1.0736922  8.517058   0.512902 ]]\n",
            "Epoch: 23/35, [Dx loss: [-6.099842   -8.293028    1.0418713   0.11513144]] [Dz loss: [-6.1664195   2.2929988  -9.839697    0.13802788]] [G loss: [14.666458  -0.9920966 10.662315   0.4996239]]\n",
            "Epoch: 24/35, [Dx loss: [-6.134631   -8.598124    1.0886351   0.13748577]] [Dz loss: [ 0.27054793  2.2339299  -3.5092132   0.15458313]] [G loss: [ 7.8722324 -1.1317377  3.9398785  0.5064091]]\n",
            "Epoch: 25/35, [Dx loss: [-5.9893193  -8.268966    1.0423313   0.12373147]] [Dz loss: [-0.83887875  2.2402825  -4.3231273   0.12439656]] [G loss: [ 8.89664   -1.0940996  4.8749123  0.5115827]]\n",
            "Epoch: 26/35, [Dx loss: [-5.897839   -8.234117    1.0895021   0.12467744]] [Dz loss: [-2.4384894   2.17508    -5.86028     0.12467112]] [G loss: [10.221037   -1.0429722   6.160173    0.51038367]]\n",
            "Epoch: 27/35, [Dx loss: [-5.6819787  -7.9966063   1.3094326   0.10051952]] [Dz loss: [-2.3541985   2.1543298  -5.790339    0.12818101]] [G loss: [11.07374    -1.1958464   5.776598    0.64929885]]\n",
            "Epoch: 28/35, [Dx loss: [-5.6112595  -8.025936    1.3697733   0.10449034]] [Dz loss: [-17.774082     2.1945732  -22.264637     0.22959784]] [G loss: [27.361635  -1.2492508 23.540438   0.5070447]]\n",
            "Epoch: 29/35, [Dx loss: [-5.3982263  -7.715538    1.2599282   0.10573836]] [Dz loss: [-11.654707     2.3141265  -16.32277      0.23539333]] [G loss: [21.39063    -1.1656798  17.176413    0.53798985]]\n",
            "Epoch: 30/35, [Dx loss: [-4.363591   -7.942195    2.7691226   0.08094806]] [Dz loss: [ -6.3407393    2.4287827  -10.571727     0.18022051]] [G loss: [14.252393  -2.305308  11.0655365  0.5492165]]\n",
            "Epoch: 31/35, [Dx loss: [-5.4203334  -4.0423927  -2.560685    0.11827449]] [Dz loss: [-4.419713    2.3871756  -8.867574    0.20606849]] [G loss: [17.527811   2.9990957  9.412181   0.5116536]]\n",
            "Epoch: 32/35, [Dx loss: [-5.772882   -6.8869553  -0.03905209  0.11531259]] [Dz loss: [-3.5838456   2.3469555  -7.6616364   0.17308351]] [G loss: [13.37298    -0.10292089  8.35782     0.51180816]]\n",
            "Epoch: 33/35, [Dx loss: [-5.907861   -7.665582    0.64028513  0.11174355]] [Dz loss: [-4.3977385   2.2517788  -8.814165    0.21646473]] [G loss: [13.569792  -0.7414551  9.200318   0.5110929]]\n",
            "Epoch: 34/35, [Dx loss: [-5.957475   -7.6970873   0.64959526  0.10900164]] [Dz loss: [-4.968129    2.3257594  -8.675391    0.13815008]] [G loss: [13.544369   -0.52595013  9.022373    0.50479454]]\n",
            "Epoch: 35/35, [Dx loss: [-5.9052234 -7.343066   0.3264207  0.1111422]] [Dz loss: [-1.5329734   2.3341126  -5.223105    0.13560197]] [G loss: [10.317974   -0.37331083  5.6073565   0.50839293]]\n",
            "precision 0.38922172620821516 Signal E-6\n",
            "recall 1.0 Signal E-6\n",
            "Accuracy 0.987709362573804 Signal E-6\n",
            "F1 0.5603450030551552 Signal E-6\n",
            "Epoch: 1/35, [Dx loss: [-3.7008095  -7.102533    0.6655452   0.27361766]] [Dz loss: [ 3.403902   -0.18580112  2.771723    0.08179804]] [G loss: [ 2.5940359 -0.6212291 -2.5040224  0.5719287]]\n",
            "Epoch: 2/35, [Dx loss: [-4.4529886  -7.3150506   2.1229916   0.07390705]] [Dz loss: [5.0278845  0.027389   4.231922   0.07685731]] [G loss: [ 5.020605   -1.6870028   3.2857957   0.34218127]]\n",
            "Epoch: 3/35, [Dx loss: [-4.3806276  -7.0893807   2.06138     0.06473733]] [Dz loss: [-29.024927     0.29963765 -30.23973      0.09151767]] [G loss: [41.439686   -2.334013   40.34303     0.34306675]]\n",
            "Epoch: 4/35, [Dx loss: [ -3.0564604  -10.842675     7.252603     0.05336089]] [Dz loss: [ 1.5222126   0.29415953 -1.3190943   0.2547146 ]] [G loss: [-1.3951162  -7.3522544   2.9093175   0.30478203]]\n",
            "Epoch: 5/35, [Dx loss: [ -3.7027154  -14.2267685    9.900691     0.06233624]] [Dz loss: [41.178368    0.4062933  39.452385    0.13196874]] [G loss: [-40.217773    -9.790478   -33.243015     0.28157178]]\n",
            "Epoch: 6/35, [Dx loss: [ -3.547105  -12.286566    8.180853    0.0558606]] [Dz loss: [-42.860954     0.8075322  -45.041256     0.13727668]] [G loss: [65.46568   -8.225465  71.04544    0.2645707]]\n",
            "Epoch: 7/35, [Dx loss: [ -3.5068004  -11.440924     7.404631     0.05294908]] [Dz loss: [-260.54605      1.5992692 -273.70572      1.1560411]] [G loss: [ 3.0105133e+02 -7.2580180e+00  3.0574951e+02  2.5598320e-01]]\n",
            "Epoch: 8/35, [Dx loss: [ -2.9045813 -10.3146305   7.0167413   0.039331 ]] [Dz loss: [ -89.1696       2.2569954 -103.49609      1.20695  ]] [G loss: [116.60866    -6.9823465 120.99983     0.2591175]]\n",
            "Epoch: 9/35, [Dx loss: [-3.326228   -9.760449    6.030635    0.04035873]] [Dz loss: [24.288818    2.4919415  16.462238    0.53346413]] [G loss: [-1.7567005  -6.0048594   1.6480026   0.26001567]]\n",
            "Epoch: 10/35, [Dx loss: [ -2.8333035 -10.809295    7.5940413   0.0381949]] [Dz loss: [-135.12233       2.6299703  -139.64493       0.18926132]] [G loss: [183.45981     -7.6934485  188.57137      0.25819123]]\n",
            "Epoch: 11/35, [Dx loss: [ -2.6747906  -12.400884     9.362978     0.03631165]] [Dz loss: [-190.21063      3.2802284 -206.20828      1.271739 ]] [G loss: [226.66878    -9.461044  233.51727     0.2612547]]\n",
            "Epoch: 12/35, [Dx loss: [ -2.6713552  -11.138254     8.119313     0.03475863]] [Dz loss: [-216.22714      3.8699887 -236.39749      1.6300371]] [G loss: [ 2.7384683e+02 -7.7341037e+00  2.7901675e+02  2.5641534e-01]]\n",
            "Epoch: 13/35, [Dx loss: [-2.744755   -8.378206    5.3130894   0.03203609]] [Dz loss: [-178.89156      4.5589943 -211.16605      2.7715464]] [G loss: [236.39499     -5.290499   239.10107      0.25844118]]\n",
            "Epoch: 14/35, [Dx loss: [-2.8870516  -9.645283    6.419511    0.03387201]] [Dz loss: [-160.68839      4.846651  -198.34492      3.2809925]] [G loss: [208.53961     -6.4317603  212.38908      0.25822845]]\n",
            "Epoch: 15/35, [Dx loss: [ -2.8338263  -10.410893     7.224562     0.03525051]] [Dz loss: [-112.95955      5.137251  -180.52158      6.2424765]] [G loss: [184.06418    -7.3151097 188.84589     0.2533391]]\n",
            "Epoch: 16/35, [Dx loss: [-2.7909064  -9.487184    6.354724    0.03415522]] [Dz loss: [ -3.285375    5.2408323 -34.629265    2.610306 ]] [G loss: [34.960693   -6.036273   38.21122     0.27857503]]\n",
            "Epoch: 17/35, [Dx loss: [-2.7658842  -8.446064    5.340813    0.03393669]] [Dz loss: [ 2.4599376  4.8607135 -9.462931   0.7062155]] [G loss: [ 9.203824  -5.4725676 12.090719   0.2585672]]\n",
            "Epoch: 18/35, [Dx loss: [-2.8113387  -8.345373    5.2036815   0.03303526]] [Dz loss: [-16.996231    4.7362795 -28.541386    0.6808873]] [G loss: [30.380013   -5.1065607  32.942375    0.25442016]]\n",
            "Epoch: 19/35, [Dx loss: [-2.7552319  -8.327364    5.2066927   0.03654394]] [Dz loss: [ -5.6484737   4.640813  -28.766657    1.8477364]] [G loss: [27.936462   -5.339193   30.738268    0.25373864]]\n",
            "Epoch: 20/35, [Dx loss: [-2.8208432  -8.036712    4.8716116   0.03442574]] [Dz loss: [ 11.39369     4.45929   -19.639496    2.6573892]] [G loss: [18.153366   -4.7501173  20.176378    0.27271038]]\n",
            "Epoch: 21/35, [Dx loss: [-2.8561864  -7.444402    4.2408724   0.03473427]] [Dz loss: [17.478321   4.41852   -9.52995    2.2589748]] [G loss: [ 8.458376   -4.2689548  10.00879     0.27185413]]\n",
            "Epoch: 22/35, [Dx loss: [-2.8824534  -7.158937    3.9565647   0.03199185]] [Dz loss: [15.788172   4.256345  -5.255768   1.6787593]] [G loss: [ 4.1856127  -3.8614283   5.352766    0.26942745]]\n",
            "Epoch: 23/35, [Dx loss: [-2.8783312 -6.4409194  3.2559097  0.0306679]] [Dz loss: [15.148964   4.0354095 -2.8897924  1.4003344]] [G loss: [ 2.3115363  -3.307508    2.9576201   0.26614243]]\n",
            "Epoch: 24/35, [Dx loss: [-2.9113796  -7.0192933   3.7761512   0.03317633]] [Dz loss: [12.466336   3.7428718 -1.5314432  1.025491 ]] [G loss: [ 0.42508313 -3.715515    1.5346168   0.26059812]]\n",
            "Epoch: 25/35, [Dx loss: [-2.8855965  -6.4883766   3.2983558   0.03044235]] [Dz loss: [10.3081     3.5659435 -0.8330318  0.7575188]] [G loss: [ 0.0860211 -3.3343027  0.8212084  0.2599115]]\n",
            "Epoch: 26/35, [Dx loss: [-2.7954638  -6.109314    2.9944222   0.03194282]] [Dz loss: [ 8.66226     3.2766583  -0.5295105   0.59151113]] [G loss: [ 0.21371478 -2.9046354   0.5430911   0.25752595]]\n",
            "Epoch: 27/35, [Dx loss: [-2.7450962  -6.0421753   3.0102706   0.02868085]] [Dz loss: [ 8.008561   3.0169322 -0.4141759  0.5405804]] [G loss: [-0.06793848 -3.049318    0.42653972  0.25548398]]\n",
            "Epoch: 28/35, [Dx loss: [-2.7462034 -6.147808   3.0912375  0.0310366]] [Dz loss: [ 7.2927628   2.8069673  -0.5064038   0.49921995]] [G loss: [-0.08539456 -3.1533172   0.52646405  0.25414586]]\n",
            "Epoch: 29/35, [Dx loss: [-2.7638912  -5.531968    2.4901223   0.02779555]] [Dz loss: [ 6.5751762   2.64308    -0.75066525  0.46827608]] [G loss: [ 0.7804882  -2.4777458   0.7462723   0.25119618]]\n",
            "Epoch: 30/35, [Dx loss: [-2.7390351  -6.134631    3.0924623   0.03031343]] [Dz loss: [ 5.304888    2.490672   -1.2399306   0.40541473]] [G loss: [ 0.91892886 -2.9819589   1.3433284   0.25575596]]\n",
            "Epoch: 31/35, [Dx loss: [-2.74443    -4.5884314   1.5513854   0.02926152]] [Dz loss: [ 4.689945   2.448411  -2.0233505  0.4264885]] [G loss: [ 3.169929  -1.588872   2.2179081  0.2540893]]\n",
            "Epoch: 32/35, [Dx loss: [-2.684884   -5.6560183   2.6879697   0.02831645]] [Dz loss: [ 3.91822    2.415384  -2.559963   0.4062799]] [G loss: [ 2.4949718  -2.65677     2.5773103   0.25744313]]\n",
            "Epoch: 33/35, [Dx loss: [-2.6390076  -4.449195    1.5567609   0.02534273]] [Dz loss: [ 3.4665732   2.4025185  -2.3971455   0.34611997]] [G loss: [ 3.570353  -1.4674705  2.4343023  0.2603521]]\n",
            "Epoch: 34/35, [Dx loss: [-2.6219287 -5.2561994  2.3429856  0.0291286]] [Dz loss: [ 3.7474205   2.3708339  -1.9449279   0.33215147]] [G loss: [ 2.1629598  -2.3794408   1.9559393   0.25864613]]\n",
            "Epoch: 35/35, [Dx loss: [-2.4720922  -4.280744    1.563927    0.02447249]] [Dz loss: [ 3.9255242  2.3563113 -1.3234141  0.2892627]] [G loss: [ 2.4452276  -1.5270214   1.3244466   0.26478025]]\n",
            "precision 0.6974358505612891 Signal E-7\n",
            "recall 0.9714285761526825 Signal E-7\n",
            "Accuracy 0.9848357147314603 Signal E-7\n",
            "F1 0.8119402683927028 Signal E-7\n",
            "Epoch: 1/35, [Dx loss: [-0.85826445 -3.4127793   0.59552914  0.19589859]] [Dz loss: [ 2.1715848  -0.01639709  1.2061754   0.09818062]] [G loss: [ 0.9578973  -0.6473763  -1.1908938   0.27961674]]\n",
            "Epoch: 2/35, [Dx loss: [-1.420695   -5.2131085   3.6348102   0.01576026]] [Dz loss: [-0.38884398  0.10749908 -1.3595291   0.08631859]] [G loss: [ 1.9822752 -3.5729764  2.6173577  0.2937894]]\n",
            "Epoch: 3/35, [Dx loss: [-0.06935536 -8.106037    7.7129188   0.03237631]] [Dz loss: [ 0.33226845  0.26410902 -1.0610331   0.11291925]] [G loss: [-4.1210685 -7.699177   1.2830917  0.2295016]]\n",
            "Epoch: 4/35, [Dx loss: [-0.87161416 -8.341108    7.236777    0.02327185]] [Dz loss: [3.5382588  0.21911497 2.2149596  0.11041842]] [G loss: [-7.4664407  -7.1532054  -1.9070895   0.15938544]]\n",
            "Epoch: 5/35, [Dx loss: [-1.4884127  -8.580995    6.784691    0.03078907]] [Dz loss: [-0.35352427  0.15082678 -2.1158192   0.16114677]] [G loss: [ 1.4976285  -6.380847    5.3238873   0.25545877]]\n",
            "Epoch: 6/35, [Dx loss: [-2.1555026  -8.282244    5.82964     0.02971012]] [Dz loss: [-0.538094   -0.01098818 -2.3089523   0.17818466]] [G loss: [-1.6830431  -6.112071    2.5530741   0.18759537]]\n",
            "Epoch: 7/35, [Dx loss: [-0.59755844 -9.581845    8.831415    0.01528746]] [Dz loss: [3.7488987  0.01168939 2.5811677  0.1156041 ]] [G loss: [-9.431707  -8.43746   -2.251793   0.1257545]]\n",
            "Epoch: 8/35, [Dx loss: [-0.9410125   1.9561888  -3.1383102   0.02411089]] [Dz loss: [-2.6872435   0.58759135 -4.2501364   0.09753006]] [G loss: [11.6556425   3.7850018   5.801465    0.20691743]]\n",
            "Epoch: 9/35, [Dx loss: [-0.21024628 -7.2934046   6.8864045   0.01967524]] [Dz loss: [ 0.43580547  0.8589404  -1.9179636   0.14948289]] [G loss: [-4.2413006  -7.525883    2.1473336   0.11372486]]\n",
            "Epoch: 10/35, [Dx loss: [ -2.0788715 -13.929494   11.599406    0.0251216]] [Dz loss: [2.544861   0.78748906 0.36228794 0.1395084 ]] [G loss: [-11.072159   -11.577863    -0.3263428    0.08320466]]\n",
            "Epoch: 11/35, [Dx loss: [ -1.2136452  -11.894373    10.554503     0.01262243]] [Dz loss: [2.7185724  0.6641255  0.551194   0.15032533]] [G loss: [ -9.7440405  -10.476269    -0.41021386   0.11424415]]\n",
            "Epoch: 12/35, [Dx loss: [-0.11382566 -8.476061    8.202586    0.01596467]] [Dz loss: [2.0644472  0.5142167  0.33770043 0.12125306]] [G loss: [-6.251774   -7.3951583  -0.21272874  0.13561139]]\n",
            "Epoch: 13/35, [Dx loss: [-0.90713227 -3.1305385   2.0879397   0.0135466 ]] [Dz loss: [1.3046709  0.5376855  0.00926054 0.07577249]] [G loss: [-0.38465035 -1.894389    0.2460317   0.12637071]]\n",
            "Epoch: 14/35, [Dx loss: [-0.5164038  -9.0899315   8.347081    0.02264472]] [Dz loss: [-0.23097639  0.7271954  -1.7022024   0.07440312]] [G loss: [-6.7545266  -9.461193    1.9108071   0.07958591]]\n",
            "Epoch: 15/35, [Dx loss: [ -1.6078923  -14.167028    12.389573     0.01695633]] [Dz loss: [ 1.5055258   0.8242874  -0.3711353   0.10523736]] [G loss: [-10.981339   -12.005261     0.40271884   0.06212028]]\n",
            "Epoch: 16/35, [Dx loss: [-3.06278437e-01 -1.18126392e+01  1.14006720e+01  1.05689615e-02]] [Dz loss: [ 0.7885317   0.8381643  -0.8135821   0.07639495]] [G loss: [ -9.41638    -11.195386     0.95819414   0.08208124]]\n",
            "Epoch: 17/35, [Dx loss: [-0.93630916 -4.3267775   3.2173915   0.01730761]] [Dz loss: [ 0.88870335  0.92949617 -0.6985446   0.06577517]] [G loss: [-0.69922715 -2.685789    0.88047194  0.11060899]]\n",
            "Epoch: 18/35, [Dx loss: [-0.7315167  -4.445284    3.5832558   0.01305113]] [Dz loss: [ 1.2958527   0.97203016 -0.3985929   0.07224154]] [G loss: [-2.4080245  -3.6500921   0.39089876  0.08511688]]\n",
            "Epoch: 19/35, [Dx loss: [ -0.94986916 -10.181334     9.047329     0.01841352]] [Dz loss: [ 1.7268598   1.0243099  -0.22363095  0.09261812]] [G loss: [-8.424912   -9.232657    0.2296244   0.05781215]]\n",
            "Epoch: 20/35, [Dx loss: [ -0.9027751  -10.669407     9.656802     0.01098292]] [Dz loss: [ 1.8986461   1.0310891  -0.12641208  0.09939691]] [G loss: [-8.991623   -9.695564    0.15721886  0.0546722 ]]\n",
            "Epoch: 21/35, [Dx loss: [-0.4867936  -4.718068    4.062852    0.01684228]] [Dz loss: [ 1.9190512   0.98669976 -0.06006796  0.0992419 ]] [G loss: [-2.3272314  -2.9942005   0.08011086  0.05868581]]\n",
            "Epoch: 22/35, [Dx loss: [-0.7104638   3.952704   -4.8053846   0.01422174]] [Dz loss: [2.153493   0.8986808  0.00309804 0.12517142]] [G loss: [ 5.258896    4.675488   -0.00686249  0.05902704]]\n",
            "Epoch: 23/35, [Dx loss: [-0.51435626  0.283761   -0.9382509   0.01401336]] [Dz loss: [2.1346843  0.8100026  0.08580096 0.12388809]] [G loss: [ 1.1635699   0.793531   -0.08872405  0.0458763 ]]\n",
            "Epoch: 24/35, [Dx loss: [-0.57977736  0.51997316 -1.23212     0.01323696]] [Dz loss: [1.9302571  0.66067064 0.22093503 0.10486512]] [G loss: [ 2.011228    1.692498   -0.21683511  0.05355652]]\n",
            "Epoch: 25/35, [Dx loss: [-0.6670369   2.198588   -3.0218105   0.01561849]] [Dz loss: [2.0077825  0.5614461  0.45913458 0.09872019]] [G loss: [ 2.7442544   2.722106   -0.45556462  0.04777128]]\n",
            "Epoch: 26/35, [Dx loss: [-0.58081746  0.48745465 -1.2296795   0.01614073]] [Dz loss: [2.2594624  0.5218284  0.86787164 0.08697622]] [G loss: [ 0.48517674  0.74630576 -0.7874519   0.05263229]]\n",
            "Epoch: 27/35, [Dx loss: [-0.6869366  -5.399033    4.575332    0.01367643]] [Dz loss: [ 1.122664    0.59780705 -0.23956783  0.07644248]] [G loss: [-3.7789602  -4.7774796   0.4150151   0.05835041]]\n",
            "Epoch: 28/35, [Dx loss: [-0.7809756  -7.378127    6.4714303   0.01257221]] [Dz loss: [ 1.0961887   0.72536623 -0.61993986  0.09907623]] [G loss: [-4.839851   -6.1534724   0.76686347  0.05467585]]\n",
            "Epoch: 29/35, [Dx loss: [-0.48560205 -2.8563354   2.2277744   0.01429597]] [Dz loss: [2.231046   0.7073873  0.14132239 0.13823366]] [G loss: [-1.5514698  -1.8817918  -0.14533272  0.04756546]]\n",
            "Epoch: 30/35, [Dx loss: [-0.5627166  -3.7459347   3.0798485   0.01033691]] [Dz loss: [2.57801    0.664892   0.37333122 0.15397869]] [G loss: [-3.5046742  -3.627369   -0.34798884  0.04706834]]\n",
            "Epoch: 31/35, [Dx loss: [-0.7236578  -8.491316    7.64001     0.01276488]] [Dz loss: [2.4913058  0.51286256 0.6048279  0.13736154]] [G loss: [-7.620547   -7.569862   -0.5596361   0.05089516]]\n",
            "Epoch: 32/35, [Dx loss: [-0.38959017 -3.9821537   3.4783008   0.0114262 ]] [Dz loss: [1.94433    0.45232505 0.5118366  0.09801684]] [G loss: [-2.830032   -2.8859627  -0.41119358  0.04671238]]\n",
            "Epoch: 33/35, [Dx loss: [-0.89910716 -1.561867    0.54627854  0.01164811]] [Dz loss: [1.7071558  0.42345303 0.11459485 0.11691078]] [G loss: [-0.11758228 -0.5410379  -0.04692471  0.04703804]]\n",
            "Epoch: 34/35, [Dx loss: [-0.38315004 -5.444394    4.9578686   0.01033752]] [Dz loss: [ 1.4712273   0.4397479  -0.01046997  0.10419492]] [G loss: [-5.0864964  -5.63359     0.05674167  0.04903521]]\n",
            "Epoch: 35/35, [Dx loss: [-7.4630940e-01 -1.1305385e+01  1.0469121e+01  8.9954557e-03]] [Dz loss: [1.7717276  0.43928275 0.5143727  0.08180722]] [G loss: [-9.919057   -9.964397   -0.4342619   0.04796021]]\n",
            "precision 1.0 Signal E-8\n",
            "recall 0.30868172348147227 Signal E-8\n",
            "Accuracy 0.9495955925448365 Signal E-8\n",
            "F1 0.47174453183359133 Signal E-8\n",
            "Epoch: 1/35, [Dx loss: [-0.2836396  -3.2932477   0.5747693   0.24348387]] [Dz loss: [ 1.1982247  -0.58504236  0.87886685  0.09044005]] [G loss: [ 1.2023444  -0.64085776 -0.74588513  0.25890872]]\n",
            "Epoch: 2/35, [Dx loss: [-1.2640772  -4.751531    3.3224044   0.01650498]] [Dz loss: [12.005014   -0.65778935 11.462954    0.11998518]] [G loss: [-8.578971   -3.1987977  -8.3818      0.30016264]]\n",
            "Epoch: 3/35, [Dx loss: [ 5.5761932e-04 -2.0377052e+00  1.6605046e+00  3.7775785e-02]] [Dz loss: [-4.2016096  -0.38077718 -4.900957    0.10801248]] [G loss: [21.052488   -0.45288718 15.941883    0.5563492 ]]\n",
            "Epoch: 4/35, [Dx loss: [-1.856582    3.3535495  -5.4933825   0.02832507]] [Dz loss: [-34.658447     0.573754   -36.172253     0.09400564]] [G loss: [57.661133    5.2597857  48.560596    0.38407508]]\n",
            "Epoch: 5/35, [Dx loss: [-1.189604   -9.315851    7.7659254   0.03603204]] [Dz loss: [-92.65384      1.8317757  -99.09411      0.46085006]] [G loss: [104.64718    -8.2694025 110.0611      0.2855482]]\n",
            "Epoch: 6/35, [Dx loss: [ -1.7967186  -10.683466     8.710962     0.01757826]] [Dz loss: [-20.515814     2.6023748  -30.28426      0.71660614]] [G loss: [28.405514  -8.609062  34.345383   0.2669191]]\n",
            "Epoch: 7/35, [Dx loss: [-0.5202753  -5.158791    4.389267    0.02492482]] [Dz loss: [ 0.3379262   2.5025628  -4.2057242   0.20410874]] [G loss: [ 3.605463  -3.1982346  4.247032   0.2556665]]\n",
            "Epoch: 8/35, [Dx loss: [-0.5330046   8.395386   -9.054461    0.01260701]] [Dz loss: [ 3.4523182   2.2391174  -1.0429981   0.22561984]] [G loss: [12.610645    9.374678    1.07092     0.21650478]]\n",
            "Epoch: 9/35, [Dx loss: [-0.8621744  -6.862593    5.6162424   0.03841763]] [Dz loss: [ 3.4887981   1.9845352  -0.18845475  0.16927174]] [G loss: [-5.136854   -6.9257154   0.326259    0.14626022]]\n",
            "Epoch: 10/35, [Dx loss: [ -1.4400243  -12.67043     11.050239     0.01801681]] [Dz loss: [ 3.1246336   1.8698975  -0.4066361   0.16613722]] [G loss: [ -8.863098   -10.764979     0.546801     0.13550802]]\n",
            "Epoch: 11/35, [Dx loss: [ 1.8834068e-01 -9.4626226e+00  9.5571775e+00  9.3783867e-03]] [Dz loss: [ 2.490869    1.735411   -0.660391    0.14158487]] [G loss: [-6.554627   -8.65833     0.77387154  0.13298303]]\n",
            "Epoch: 12/35, [Dx loss: [ -1.2261639   11.694508   -13.080149     0.01594761]] [Dz loss: [ 2.260772    1.6268187  -0.80638564  0.14403391]] [G loss: [16.330042  14.079767   0.8349911  0.1415283]]\n",
            "Epoch: 13/35, [Dx loss: [ 1.2445927e-01  1.1427683e+01 -1.1404793e+01  1.0157128e-02]] [Dz loss: [ 1.7703108   1.6071193  -1.0941112   0.12573029]] [G loss: [13.283138  11.246527   1.1297348  0.0906876]]\n",
            "Epoch: 14/35, [Dx loss: [-0.291259    6.590997   -7.175242    0.02929868]] [Dz loss: [ 1.4999219  1.509388  -1.09848    0.1089014]] [G loss: [9.350162  6.8979387 1.161611  0.1290612]]\n",
            "Epoch: 15/35, [Dx loss: [-1.3866953  -1.214154   -0.32623512  0.01536939]] [Dz loss: [ 2.1573327   1.4733815  -0.5442568   0.12282075]] [G loss: [ 1.0919241  -0.12427211  0.55077827  0.0665418 ]]\n",
            "Epoch: 16/35, [Dx loss: [ 0.20130984 -0.951537    0.99607515  0.01567719]] [Dz loss: [ 2.3186355  1.401062  -0.164      0.1081573]] [G loss: [ 0.66183186 -0.2696761   0.1787031   0.07528049]]\n",
            "Epoch: 17/35, [Dx loss: [-0.80127203  8.464898   -9.579893    0.03137218]] [Dz loss: [2.5096803  1.3168335  0.06010519 0.1132741 ]] [G loss: [10.714349    9.949663   -0.07452819  0.08392132]]\n",
            "Epoch: 18/35, [Dx loss: [ -0.57586515  10.323734   -11.065626     0.01660257]] [Dz loss: [2.526954   1.243612   0.16903837 0.11143033]] [G loss: [11.4241     11.050026   -0.18865314  0.05627269]]\n",
            "Epoch: 19/35, [Dx loss: [ 0.12358407  7.501274   -7.4888825   0.01111934]] [Dz loss: [2.4552953  1.1156127  0.18992312 0.11497595]] [G loss: [ 8.396589    7.8563695  -0.19150138  0.07317214]]\n",
            "Epoch: 20/35, [Dx loss: [-7.4248803e-01  1.6546244e+01 -1.7449377e+01  1.6064400e-02]] [Dz loss: [2.4066203  1.0158894  0.19339964 0.11973312]] [G loss: [17.863081   17.457966   -0.20324014  0.06083571]]\n",
            "Epoch: 21/35, [Dx loss: [-4.9074760e-01  1.1375632e+01 -1.1971182e+01  1.0480536e-02]] [Dz loss: [2.4218795  0.95575106 0.20513192 0.12609966]] [G loss: [12.147053   11.793077   -0.19781184  0.05517868]]\n",
            "Epoch: 22/35, [Dx loss: [ -0.19592494  12.121527   -12.481895     0.01644451]] [Dz loss: [2.4497395  0.9097338  0.25073752 0.12892684]] [G loss: [13.362916   12.983362   -0.24393669  0.06234913]]\n",
            "Epoch: 23/35, [Dx loss: [-4.9287540e-01  2.0367018e+01 -2.1056936e+01  1.9704513e-02]] [Dz loss: [2.590235   0.8463311  0.27614123 0.14677623]] [G loss: [21.857307   21.450483   -0.2670622   0.06738866]]\n",
            "Epoch: 24/35, [Dx loss: [-6.3999057e-01  1.8927671e+01 -1.9693928e+01  1.2626897e-02]] [Dz loss: [2.5530686  0.77424955 0.31988177 0.14589368]] [G loss: [20.102816   19.895615   -0.32320458  0.05304047]]\n",
            "Epoch: 25/35, [Dx loss: [ 5.5613197e-02  2.0843674e+01 -2.0929081e+01  1.4101808e-02]] [Dz loss: [2.5536513  0.7164431  0.3538483  0.14833596]] [G loss: [21.147112   20.914001   -0.36987543  0.06029834]]\n",
            "Epoch: 26/35, [Dx loss: [ -1.0937722   14.552061   -15.831938     0.01861043]] [Dz loss: [2.4441211  0.6565347  0.31310004 0.14744867]] [G loss: [15.77148    15.493657   -0.2980674   0.05758902]]\n",
            "Epoch: 27/35, [Dx loss: [-6.9206101e-01  1.1118983e+01 -1.1926030e+01  1.1498661e-02]] [Dz loss: [2.5215795  0.6502695  0.34739402 0.15239158]] [G loss: [12.071608   11.95109    -0.3389302   0.04594473]]\n",
            "Epoch: 28/35, [Dx loss: [ -0.47528473  11.061958   -11.674002     0.01367597]] [Dz loss: [2.4982677  0.5773266  0.35717568 0.15637659]] [G loss: [11.739506   11.586789   -0.36481073  0.05175269]]\n",
            "Epoch: 29/35, [Dx loss: [-0.1958292   8.488053   -8.913071    0.02291873]] [Dz loss: [2.5302615  0.5614735  0.37787125 0.15909162]] [G loss: [ 8.880971    8.7519     -0.35634613  0.04854172]]\n",
            "Epoch: 30/35, [Dx loss: [-1.1552284  6.2040706 -7.5044813  0.0145183]] [Dz loss: [2.6327531  0.5268649  0.38253492 0.1723353 ]] [G loss: [ 7.6766443   7.5594673  -0.38845295  0.05056304]]\n",
            "Epoch: 31/35, [Dx loss: [-0.03778981  7.803342   -7.9899073   0.01487775]] [Dz loss: [2.6669378  0.46783003 0.38668117 0.18124266]] [G loss: [ 8.528255    8.397946   -0.39676434  0.05270744]]\n",
            "Epoch: 32/35, [Dx loss: [-1.1361035   7.9020796  -9.17457     0.01363886]] [Dz loss: [2.496919   0.41589516 0.40723705 0.16737863]] [G loss: [ 9.073804    8.973904   -0.3954758   0.04953763]]\n",
            "Epoch: 33/35, [Dx loss: [-3.8563189e-01  6.9522223e+00 -7.4118714e+00  7.4018734e-03]] [Dz loss: [2.3608544  0.38480836 0.4429521  0.15330938]] [G loss: [ 7.2887564   7.2678723  -0.44574207  0.04666265]]\n",
            "Epoch: 34/35, [Dx loss: [-0.7766286   4.6581755  -5.6277685   0.01929639]] [Dz loss: [2.441672   0.4163455  0.42517918 0.16001475]] [G loss: [ 5.720155    5.6117435  -0.40178964  0.05102008]]\n",
            "Epoch: 35/35, [Dx loss: [-0.65384704  6.6718154  -7.409365    0.00837021]] [Dz loss: [2.6751184  0.41935158 0.47924644 0.17765199]] [G loss: [ 7.646437    7.672284   -0.46945563  0.04436084]]\n",
            "precision nan Signal E-9\n",
            "recall 0.0 Signal E-9\n",
            "Accuracy 0.9578363996751842 Signal E-9\n",
            "F1 nan Signal E-9\n",
            "Epoch: 1/35, [Dx loss: [-4.5971937  -8.887419    0.8707388   0.34194875]] [Dz loss: [ 2.9692292  -0.5293838   2.6545002   0.08441123]] [G loss: [ 5.5253105 -0.8989519 -2.3332794  0.8757542]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.842987   -11.677394     4.8930826    0.09413231]] [Dz loss: [ 2.5134501  -0.5091496   1.2054279   0.18171737]] [G loss: [ 8.17311    -4.987118    5.4523954   0.77078325]]\n",
            "Epoch: 3/35, [Dx loss: [-3.5813727 -9.904634   5.5379615  0.0785301]] [Dz loss: [-22.26587     -0.76263624 -23.403639     0.19004056]] [G loss: [32.625843  -5.497677  30.161837   0.7961681]]\n",
            "Epoch: 4/35, [Dx loss: [ -5.0779066  -11.6884165    5.5753937    0.10351139]] [Dz loss: [24.855236   -0.83651733 19.978598    0.5713156 ]] [G loss: [-13.55835     -5.480172   -16.260347     0.81821704]]\n",
            "Epoch: 5/35, [Dx loss: [ -6.141961   -10.979255     3.574429     0.12628637]] [Dz loss: [34.72229    -0.3419388  33.96714     0.10970853]] [G loss: [-5.369506  -3.5266733 -9.905717   0.8062887]]\n",
            "Epoch: 6/35, [Dx loss: [-6.496881  -9.577196   1.6055361  0.1474779]] [Dz loss: [-212.44336       0.23167136 -221.06267       0.8387617 ]] [G loss: [272.51538     -1.3405668  265.75272      0.81032324]]\n",
            "Epoch: 7/35, [Dx loss: [-6.4756002  -9.555941    1.6899618   0.13903786]] [Dz loss: [17.44938     1.0660102   8.948313    0.74350584]] [G loss: [ 8.271965   -1.672068    1.6746523   0.82693815]]\n",
            "Epoch: 8/35, [Dx loss: [-6.285546   -9.350968    1.7348664   0.13305576]] [Dz loss: [6.049554   1.6810741  3.3909314  0.09775493]] [G loss: [11.041939  -1.7590077  4.700967   0.809998 ]]\n",
            "Epoch: 9/35, [Dx loss: [-6.3176646  -6.843947   -0.7670022   0.12932852]] [Dz loss: [ -9.571218     1.9889104  -12.656076     0.10959502]] [G loss: [30.303835    1.1288121  21.810104    0.73649186]]\n",
            "Epoch: 10/35, [Dx loss: [-6.5963655 -4.01233   -3.9460437  0.1362008]] [Dz loss: [-30.979229     1.9683826  -33.9589       0.10112935]] [G loss: [55.96322   4.056817 44.98803   0.691837]]\n",
            "Epoch: 11/35, [Dx loss: [-6.5557985  -4.562006   -3.3546524   0.13608599]] [Dz loss: [-31.845709     1.9862478  -35.691917     0.18599564]] [G loss: [49.722427    3.3375037  39.390827    0.69940937]]\n",
            "Epoch: 12/35, [Dx loss: [-6.5585732  -5.1944885  -2.7937222   0.14296383]] [Dz loss: [-4.3986616  2.1188586 -9.025612   0.2508093]] [G loss: [19.462307    2.7385333  10.113786    0.66099876]]\n",
            "Epoch: 13/35, [Dx loss: [-6.302831   -6.5485506  -1.090173    0.13358924]] [Dz loss: [ -6.3572083    2.138218   -10.308377     0.18129501]] [G loss: [20.459644    1.0023223  12.740946    0.67163765]]\n",
            "Epoch: 14/35, [Dx loss: [-6.128734   -7.1975927  -0.1389831   0.12078413]] [Dz loss: [-17.136177    2.314965  -21.403479    0.1952341]] [G loss: [29.159363    0.07857089 22.466015    0.6614779 ]]\n",
            "Epoch: 15/35, [Dx loss: [-6.04724    -7.4649925   0.09370583  0.13240471]] [Dz loss: [-10.2108555    2.4010863  -15.598882     0.29869395]] [G loss: [ 2.3640194e+01 -1.8585257e-02  1.6828074e+01  6.8307054e-01]]\n",
            "Epoch: 16/35, [Dx loss: [-5.891486   -6.8677053  -0.25302637  0.12292463]] [Dz loss: [ -5.8150096    2.4136074  -11.191149     0.29625306]] [G loss: [18.56105     0.09294567 11.351562    0.71165425]]\n",
            "Epoch: 17/35, [Dx loss: [-5.7804556  -7.303823    0.27500376  0.12483648]] [Dz loss: [-2.8347616   2.3961425  -7.4700484   0.22391441]] [G loss: [13.987673   -0.22966164  7.599401    0.66179323]]\n",
            "Epoch: 18/35, [Dx loss: [-5.9150133  -5.8397427  -1.3572593   0.12819894]] [Dz loss: [-0.5485003   2.2863553  -5.008891    0.21740358]] [G loss: [13.099997    1.4997044   4.984227    0.66160655]]\n",
            "Epoch: 19/35, [Dx loss: [-5.87675   -5.048623  -2.1000216  0.1271896]] [Dz loss: [ 1.4238335   2.1926532  -2.680407    0.19115868]] [G loss: [11.480275   2.0839593  2.7565217  0.6639794]]\n",
            "Epoch: 20/35, [Dx loss: [-5.6407514  -5.3513613  -1.5425901   0.12531999]] [Dz loss: [ 2.6156125   2.16138    -1.2967262   0.17509595]] [G loss: [9.384232  1.557109  1.3652697 0.6461853]]\n",
            "Epoch: 21/35, [Dx loss: [-5.5555124  -5.9729185  -0.741772    0.11591786]] [Dz loss: [ 1.9079487   2.0383716  -1.8581845   0.17277616]] [G loss: [9.598543  0.9649792 2.0258043 0.660776 ]]\n",
            "Epoch: 22/35, [Dx loss: [-5.3831625  -5.590898   -0.93509835  0.11428335]] [Dz loss: [ 0.34954476  1.9976362  -3.361655    0.17135634]] [G loss: [11.362734   0.8011868  3.5704193  0.6991128]]\n",
            "Epoch: 23/35, [Dx loss: [-5.078164   -5.1306167  -0.9766393   0.10290913]] [Dz loss: [ 0.07762582  2.000072   -3.7940547   0.18716083]] [G loss: [12.178978    0.90713894  3.9943357   0.72775036]]\n",
            "Epoch: 24/35, [Dx loss: [-4.52641   -2.876083  -2.631782   0.0981455]] [Dz loss: [ 1.8884243  1.985412  -1.9284217  0.1831434]] [G loss: [12.106151   2.8968096  1.9220037  0.7287338]]\n",
            "Epoch: 25/35, [Dx loss: [-3.761615   -3.6644623  -0.88092375  0.07837711]] [Dz loss: [ 3.2113585   1.9332978  -0.58673406  0.1864795 ]] [G loss: [8.750967   0.85319173 0.6477263  0.7250048 ]]\n",
            "Epoch: 26/35, [Dx loss: [-3.6578171  -4.779108    0.38806468  0.07332258]] [Dz loss: [ 2.7249694   1.9284191  -0.3821655   0.11787156]] [G loss: [8.243992   0.5367669  0.49152088 0.7215705 ]]\n",
            "Epoch: 27/35, [Dx loss: [-3.2283046e+00  7.9059007e-04 -3.8272014e+00  5.9810620e-02]] [Dz loss: [ 2.304057    1.8536816  -0.54830474  0.09986797]] [G loss: [10.895127    3.254745    0.6693578   0.69710237]]\n",
            "Epoch: 28/35, [Dx loss: [-2.8734822  -0.3613777  -2.9529908   0.04408861]] [Dz loss: [ 1.7130175   1.7742077  -1.014066    0.09528757]] [G loss: [11.376418    3.0620248   1.1473528   0.71670413]]\n",
            "Epoch: 29/35, [Dx loss: [-2.4680912  -0.80577594 -2.0659223   0.04036069]] [Dz loss: [ 1.8403807   1.7277199  -0.8624083   0.09750687]] [G loss: [9.762808   1.890614   0.9827298  0.68894637]]\n",
            "Epoch: 30/35, [Dx loss: [-2.1930494   0.27214175 -2.801846    0.03366549]] [Dz loss: [ 2.067242    1.7138107  -0.5767935   0.09302247]] [G loss: [10.473875   2.8323934  0.6830119  0.695847 ]]\n",
            "Epoch: 31/35, [Dx loss: [-2.1234882  -0.13630675 -2.4417338   0.04545524]] [Dz loss: [ 2.1676564   1.6464226  -0.48186198  0.10030961]] [G loss: [9.919999  2.608     0.5164645 0.6795536]]\n",
            "Epoch: 32/35, [Dx loss: [-1.8881595   3.3185585  -5.599225    0.03925071]] [Dz loss: [ 1.4941216   1.6860592  -1.2390057   0.10470678]] [G loss: [13.879471   5.8951564  1.353653   0.663066 ]]\n",
            "Epoch: 33/35, [Dx loss: [-2.0025811   1.9691149  -4.3205547   0.03488594]] [Dz loss: [ 0.71287054  1.6998123  -2.0907514   0.11038101]] [G loss: [13.544436    4.234376    2.1442535   0.71658075]]\n",
            "Epoch: 34/35, [Dx loss: [-1.8284025   0.24943273 -2.3775504   0.02997156]] [Dz loss: [-0.74946487  1.7543774  -3.490099    0.09862566]] [G loss: [12.946663   2.1479385  3.6453967  0.7153329]]\n",
            "Epoch: 35/35, [Dx loss: [-2.5661037  -2.916931   -0.13368139  0.04845088]] [Dz loss: [-2.508435    1.8049237  -5.203203    0.08898444]] [G loss: [12.3502865   0.38887495  5.2869477   0.66744655]]\n",
            "precision 0.538888938185852 Signal E-10\n",
            "recall 0.6062501139322587 Signal E-10\n",
            "Accuracy 0.9656632118654402 Signal E-10\n",
            "F1 0.5705883133890546 Signal E-10\n",
            "Epoch: 1/35, [Dx loss: [-3.5322304  -8.104833    1.0411265   0.35314748]] [Dz loss: [ 2.1240356  -0.6771842   2.0686984   0.07325219]] [G loss: [ 5.719641  -1.0449008 -1.6650546  0.8429597]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.175364  -10.889225    4.8679557   0.0845906]] [Dz loss: [ 0.5085334  -0.8118104   0.29951733  0.1020826 ]] [G loss: [ 7.0467772  -4.6624317   4.2425647   0.74666446]]\n",
            "Epoch: 3/35, [Dx loss: [-4.5107946  -6.501029    0.8714391   0.11187961]] [Dz loss: [ 8.878805   -1.1073384   6.622382    0.33637622]] [G loss: [ 4.947739   -0.29269588 -2.5246806   0.7765115 ]]\n",
            "Epoch: 4/35, [Dx loss: [-4.449191   -9.860589    4.5218      0.08895971]] [Dz loss: [84.49721    -0.9420379  83.45448     0.19847544]] [G loss: [-59.55629    -4.6741447 -62.985256    0.8103109]]\n",
            "Epoch: 5/35, [Dx loss: [ -5.263088   -15.020737     8.621473     0.11361744]] [Dz loss: [-75.87397    -0.5342034 -76.55192     0.1212155]] [G loss: [140.40329     -8.605713   140.91602      0.80929935]]\n",
            "Epoch: 6/35, [Dx loss: [ -4.5245256 -10.927978    5.455862    0.0947589]] [Dz loss: [-364.03897       0.43437356 -378.99606       1.4522773 ]] [G loss: [439.96664     -5.171829   437.09753      0.80409515]]\n",
            "Epoch: 7/35, [Dx loss: [ -3.434829   -12.057872     8.084547     0.05384974]] [Dz loss: [-58.897896    1.6445376 -93.048775    3.2506356]] [G loss: [119.51402    -7.8412642 119.3645      0.7990798]]\n",
            "Epoch: 8/35, [Dx loss: [-2.5689373  -9.613253    6.528305    0.05160106]] [Dz loss: [1.7247287e+02 1.9636835e+00 1.6908437e+02 1.4248124e-01]] [G loss: [-146.75073      -6.392205   -147.7983        0.74397635]]\n",
            "Epoch: 9/35, [Dx loss: [-1.9289367  -9.91231     7.675946    0.03074277]] [Dz loss: [-136.4743        2.051813   -140.30972       0.17836021]] [G loss: [186.99315   -7.659906 187.70885    0.69442 ]]\n",
            "Epoch: 10/35, [Dx loss: [-1.6023178  -8.352801    6.3816576   0.03688271]] [Dz loss: [-8.1322394e+02  2.4287782e+00 -8.2341052e+02  7.7576900e-01]] [G loss: [ 9.2246497e+02 -6.6120577e+00  9.2205273e+02  7.0242053e-01]]\n",
            "Epoch: 11/35, [Dx loss: [-1.5520015  -7.617659    5.7389154   0.03267426]] [Dz loss: [-1047.3949        3.2929153 -1136.119         8.543141 ]] [G loss: [ 1.2050643e+03 -5.1184883e+00  1.2035292e+03  6.6537851e-01]]\n",
            "Epoch: 12/35, [Dx loss: [-1.3951366  -9.73832     8.065981    0.02772028]] [Dz loss: [-423.83807     4.112903 -477.41138     4.946042]] [G loss: [544.4833      -8.562183   546.25543      0.67900145]]\n",
            "Epoch: 13/35, [Dx loss: [ -2.2211537  -16.902447    14.428531     0.02527653]] [Dz loss: [ -902.132         5.2632637 -1013.18933      10.579375 ]] [G loss: [ 1.1442725e+03 -1.4222658e+01  1.1518547e+03  6.6404110e-01]]\n",
            "Epoch: 14/35, [Dx loss: [-1.6132824  -4.770841    2.8436732   0.03138854]] [Dz loss: [-388.90652      6.1570234 -542.16974     14.710629 ]] [G loss: [587.5601     -1.7483797 582.67224     0.6636321]]\n",
            "Epoch: 15/35, [Dx loss: [-1.0373034  -5.672491    4.311381    0.03238072]] [Dz loss: [-116.36061      6.3085923 -175.85709      5.3187923]] [G loss: [184.52275    -5.494341  183.57529     0.6441813]]\n",
            "Epoch: 16/35, [Dx loss: [ -1.2059065 -14.868405   13.401792    0.0260708]] [Dz loss: [ -32.58565      5.9545975 -124.44204      8.590178 ]] [G loss: [147.88188   -12.38212   153.56581     0.6698195]]\n",
            "Epoch: 17/35, [Dx loss: [-1.1471072 -4.760443   3.1817138  0.0431622]] [Dz loss: [-165.53181     5.786047 -198.68538     2.73675 ]] [G loss: [226.36835    -2.890605  222.6943      0.6564637]]\n",
            "Epoch: 18/35, [Dx loss: [-1.1217325  -0.95575464 -0.46796593  0.03019885]] [Dz loss: [-169.0167       5.9408712 -218.13943      4.3181844]] [G loss: [255.40085     0.6330475 248.24615     0.6521653]]\n",
            "Epoch: 19/35, [Dx loss: [-1.8201717  -3.8775303   1.8352423   0.02221175]] [Dz loss: [-138.94722      6.2448893 -182.15001      3.6957893]] [G loss: [206.62434    -1.798122  201.94499     0.6477469]]\n",
            "Epoch: 20/35, [Dx loss: [-1.188067    0.28186506 -1.772088    0.03021561]] [Dz loss: [-353.50238     6.612963 -419.3129      5.919747]] [G loss: [457.4031      2.2747288 448.70837     0.6419971]]\n",
            "Epoch: 21/35, [Dx loss: [-0.7772202   0.9411214  -1.9635496   0.02452085]] [Dz loss: [-295.75        7.365438 -420.79987    11.768435]] [G loss: [462.1041      1.5097764 453.8461      0.6748206]]\n",
            "Epoch: 22/35, [Dx loss: [-1.0969828  -3.175066    1.9004406   0.01776426]] [Dz loss: [ -42.549446     7.6413774 -124.85826      7.466741 ]] [G loss: [137.50717    -1.8910586 131.7742      0.7624037]]\n",
            "Epoch: 23/35, [Dx loss: [-1.0970227   1.5171008  -2.999183    0.03850595]] [Dz loss: [ 10.78519     7.3589277 -50.80648     5.423275 ]] [G loss: [67.73891     3.433998   57.560337    0.67445743]]\n",
            "Epoch: 24/35, [Dx loss: [-0.95774335  4.860807   -6.1260614   0.03075115]] [Dz loss: [ 13.084537    7.207443  -45.81514     5.1692224]] [G loss: [64.362015  6.298556 51.34288   0.672058]]\n",
            "Epoch: 25/35, [Dx loss: [-0.93670416  0.3486063  -1.4604347   0.01751248]] [Dz loss: [ 17.775814    6.8589187 -41.40652     5.2323413]] [G loss: [51.97327     1.3821836  43.85619     0.67349017]]\n",
            "Epoch: 26/35, [Dx loss: [-0.93203145 -3.8695073   2.5505254   0.03869491]] [Dz loss: [ 34.32056     6.6510935 -28.236338    5.5905805]] [G loss: [32.656124   -2.1245165  27.487904    0.72927374]]\n",
            "Epoch: 27/35, [Dx loss: [-0.59346414 -1.1255782   0.2850159   0.02470982]] [Dz loss: [ 39.43731     6.2964363 -15.85362     4.8994493]] [G loss: [22.236015   -0.31055295 15.366488    0.71800804]]\n",
            "Epoch: 28/35, [Dx loss: [-1.3597109 -4.257071   2.5980623  0.0299297]] [Dz loss: [ 49.141453    6.028716  -11.115686    5.4228435]] [G loss: [15.332324   -2.6510868  11.268456    0.67149526]]\n",
            "Epoch: 29/35, [Dx loss: [-1.064296   -5.813178    4.36894     0.03799424]] [Dz loss: [46.206703   5.8232336 -8.764066   4.9147534]] [G loss: [11.2589655  -4.282341    8.613096    0.69282115]]\n",
            "Epoch: 30/35, [Dx loss: [-0.77392507 -9.148108    8.149181    0.02249989]] [Dz loss: [40.494976   5.4943457 -6.951032   4.195166 ]] [G loss: [ 5.903305   -8.362497    7.371666    0.68941367]]\n",
            "Epoch: 31/35, [Dx loss: [-0.96282446 -6.1360097   4.9281425   0.02450432]] [Dz loss: [37.754036   5.2578535 -6.6809416  3.9177132]] [G loss: [ 8.6913185  -4.508514    6.7521887   0.64476436]]\n",
            "Epoch: 32/35, [Dx loss: [-0.93885964 -3.6422927   2.4885085   0.02149248]] [Dz loss: [34.231407   5.1774845 -6.2686024  3.5322526]] [G loss: [10.164457   -2.5887468   6.1394515   0.66137534]]\n",
            "Epoch: 33/35, [Dx loss: [-0.920887   -6.6543365   5.5887365   0.01447125]] [Dz loss: [30.521671   5.0057526 -5.1905565  3.0706465]] [G loss: [ 6.1439033  -5.6261225   5.2101364   0.65598893]]\n",
            "Epoch: 34/35, [Dx loss: [-0.74052966 -5.8145614   4.8721876   0.02018443]] [Dz loss: [27.771189  4.831971 -4.104451  2.704367]] [G loss: [ 5.9243736  -4.643666    4.17872     0.63893205]]\n",
            "Epoch: 35/35, [Dx loss: [-0.84936553 -4.147426    2.963344    0.03347155]] [Dz loss: [27.123669   4.6386995 -3.409246   2.589422 ]] [G loss: [ 7.3795395 -2.8515606  3.5081563  0.6722944]]\n",
            "precision 0.07246439045599137 Signal E-11\n",
            "recall 0.017064999031412263 Signal E-11\n",
            "Accuracy 0.9586514687775994 Signal E-11\n",
            "F1 0.027624554574168236 Signal E-11\n",
            "Epoch: 1/35, [Dx loss: [-4.47157   -9.1953     1.5476941  0.3176036]] [Dz loss: [ 3.3076806  -0.04589251  2.243878    0.11096952]] [G loss: [ 4.7990065  -1.5716232  -1.9004242   0.82710534]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.247235   -12.077524     6.022851     0.08074373]] [Dz loss: [ 6.990851   -0.04419776  5.1620293   0.1873019 ]] [G loss: [ 3.6454973 -5.875601   2.2108307  0.7310267]]\n",
            "Epoch: 3/35, [Dx loss: [ -3.9233565  -11.968366     7.1550407    0.08899672]] [Dz loss: [-19.130299    -0.14066686 -20.08812      0.10984848]] [G loss: [33.165077  -7.340617  30.518787   0.9986906]]\n",
            "Epoch: 4/35, [Dx loss: [ -4.5670004  -15.658981    10.184415     0.09075644]] [Dz loss: [ -9.350716    -0.09627195 -10.053034     0.0798589 ]] [G loss: [ 19.403439  -10.37013    21.761786    0.8011781]]\n",
            "Epoch: 5/35, [Dx loss: [ -5.281295   -14.141493     7.796378     0.10638189]] [Dz loss: [-35.48696      0.4029007  -36.896355     0.10064913]] [G loss: [47.704803  -7.5838537 47.17687    0.8111786]]\n",
            "Epoch: 6/35, [Dx loss: [ -5.1890306  -12.877744     6.678122     0.10105897]] [Dz loss: [-58.14966      1.2272234  -60.52657      0.11496928]] [G loss: [87.01952   -6.503845  85.49888    0.8024497]]\n",
            "Epoch: 7/35, [Dx loss: [ -3.724378   -10.91129      6.4206305    0.07662822]] [Dz loss: [ -97.00212       2.0436687  -102.94617       0.39004046]] [G loss: [116.1925     -5.925085  114.08422     0.8033358]]\n",
            "Epoch: 8/35, [Dx loss: [-3.0535274  -7.8819213   4.2631426   0.05652497]] [Dz loss: [-29.578588     2.485568   -33.414143     0.13499874]] [G loss: [38.833164   -4.2186832  35.42571     0.76261395]]\n",
            "Epoch: 9/35, [Dx loss: [-2.2513704  -8.085778    5.446217    0.03881904]] [Dz loss: [ -7.3553953    2.4058902  -11.140447     0.13791601]] [G loss: [14.092362  -5.475948  11.680566   0.7887744]]\n",
            "Epoch: 10/35, [Dx loss: [-2.10646    -8.127007    5.553848    0.04666983]] [Dz loss: [ 0.5089918   2.3540566  -4.4180307   0.25729668]] [G loss: [ 6.1733665 -5.5705066  4.6941867  0.7049686]]\n",
            "Epoch: 11/35, [Dx loss: [-1.8874397  -8.6730385   6.4687004   0.03168992]] [Dz loss: [ 2.7632096   2.2784336  -1.5338583   0.20186348]] [G loss: [ 0.7297457  -6.2284293   1.6121546   0.53460205]]\n",
            "Epoch: 12/35, [Dx loss: [-1.7945864  -6.8604302   4.7894354   0.02764096]] [Dz loss: [ 3.1186757   2.1329563  -0.66215336  0.16478729]] [G loss: [ 0.21053407 -4.8447857   0.6805873   0.43747324]]\n",
            "Epoch: 13/35, [Dx loss: [-1.5469124  -4.7827654   2.9572506   0.02786028]] [Dz loss: [ 3.378117    2.01356    -0.31747887  0.16820355]] [G loss: [ 0.8036907  -3.0040896   0.39148888  0.34162912]]\n",
            "Epoch: 14/35, [Dx loss: [-1.293451   -5.327586    3.7728302   0.02613048]] [Dz loss: [ 2.8292468   1.94583    -0.5402295   0.14236465]] [G loss: [-0.7073169  -3.530936    0.54971176  0.22739074]]\n",
            "Epoch: 15/35, [Dx loss: [-1.2079628  -4.4460897   2.9532695   0.02848569]] [Dz loss: [ 2.1877358   1.8553139  -1.0930064   0.14254285]] [G loss: [-0.24497855 -3.2075374   1.1842102   0.17783488]]\n",
            "Epoch: 16/35, [Dx loss: [-1.1475834  -3.2755806   1.8558899   0.02721075]] [Dz loss: [ 1.3802131   1.8422201  -1.7769182   0.13149115]] [G loss: [ 1.6821424  -1.7672086   1.9333622   0.15159886]]\n",
            "Epoch: 17/35, [Dx loss: [-1.063691   -5.101657    3.8131785   0.02247884]] [Dz loss: [ 0.63869065  1.8245087  -2.490696    0.13048781]] [G loss: [ 0.32322794 -3.9032962   2.6166353   0.16098887]]\n",
            "Epoch: 18/35, [Dx loss: [-1.0715483  -1.3789679   0.05082649  0.0256593 ]] [Dz loss: [ 0.44738954  1.837369   -2.7144547   0.13244751]] [G loss: [4.479512   0.19511226 2.824901   0.14594986]]\n",
            "Epoch: 19/35, [Dx loss: [-1.0872451  -2.9037135   1.5667858   0.02496822]] [Dz loss: [ 1.1101625   1.9126285  -2.2595687   0.14571026]] [G loss: [ 2.530278   -1.4413241   2.3433144   0.16282877]]\n",
            "Epoch: 20/35, [Dx loss: [-1.1511877   2.16168    -3.5945382   0.02816704]] [Dz loss: [ 1.40157     1.8811048  -1.6864656   0.12069305]] [G loss: [6.941681   3.8249943  1.7358204  0.13808656]]\n",
            "Epoch: 21/35, [Dx loss: [-1.06159    -1.3379707   0.05766021  0.02187206]] [Dz loss: [ 2.288313    1.8657357  -0.91474354  0.13373208]] [G loss: [ 2.245513   -0.16662998  0.9401682   0.1471975 ]]\n",
            "Epoch: 22/35, [Dx loss: [-1.014955   -0.99749327 -0.24560103  0.02281393]] [Dz loss: [ 2.5822563   1.8006433  -0.50241715  0.1284031 ]] [G loss: [2.2781289  0.44049168 0.5050457  0.13325916]]\n",
            "Epoch: 23/35, [Dx loss: [-0.8630029  -2.6786995   1.5684755   0.02472216]] [Dz loss: [ 2.8129597   1.7668784  -0.37811518  0.14241973]] [G loss: [-0.24756159 -1.8065639   0.4000676   0.11589346]]\n",
            "Epoch: 24/35, [Dx loss: [-0.83336085 -2.092836    0.9946171   0.02648574]] [Dz loss: [ 2.7088892   1.6431879  -0.3911328   0.14568341]] [G loss: [ 0.8392977  -0.9173063   0.41877457  0.13378295]]\n",
            "Epoch: 25/35, [Dx loss: [-0.74631774 -1.410197    0.42056313  0.02433163]] [Dz loss: [ 2.5259805   1.5952398  -0.43190345  0.13626443]] [G loss: [ 1.0353357  -0.53348184  0.45752224  0.11112953]]\n",
            "Epoch: 26/35, [Dx loss: [-0.71431094 -1.4412675   0.46226922  0.02646873]] [Dz loss: [ 2.5037768   1.5309647  -0.37970373  0.1352515 ]] [G loss: [ 1.3382807  -0.25912356  0.39178607  0.12056182]]\n",
            "Epoch: 27/35, [Dx loss: [-0.5976568  -1.5487776   0.74119174  0.02099293]] [Dz loss: [ 2.5202973  1.4658277 -0.3717161  0.1426185]] [G loss: [ 0.57888937 -0.9284904   0.39079326  0.11165866]]\n",
            "Epoch: 28/35, [Dx loss: [-0.69767404 -2.728101    1.845177    0.01852499]] [Dz loss: [ 2.5459037   1.4044974  -0.31122312  0.14526299]] [G loss: [-0.41845196 -1.8001027   0.29786304  0.10837878]]\n",
            "Epoch: 29/35, [Dx loss: [-0.636169   -2.4593782   1.6140858   0.02091235]] [Dz loss: [ 2.6382575   1.3646615  -0.23817053  0.15117668]] [G loss: [-0.33791846 -1.6299374   0.21350665  0.10785124]]\n",
            "Epoch: 30/35, [Dx loss: [-0.66351473 -2.0611136   1.2263615   0.0171237 ]] [Dz loss: [ 2.7425437   1.2916541  -0.19353506  0.16444245]] [G loss: [ 0.16574964 -1.1621287   0.19617753  0.11317009]]\n",
            "Epoch: 31/35, [Dx loss: [-0.64714354 -1.8357632   0.9404416   0.02481777]] [Dz loss: [ 2.8398597  1.2771199 -0.1319583  0.1694698]] [G loss: [ 0.34986806 -1.0126088   0.144227    0.12182499]]\n",
            "Epoch: 32/35, [Dx loss: [-0.594213   -1.9143665   1.1513984   0.01687548]] [Dz loss: [ 2.7562506   1.1348306  -0.12530366  0.1746723 ]] [G loss: [ 0.17901026 -1.0993441   0.12195024  0.1156404 ]]\n",
            "Epoch: 33/35, [Dx loss: [-0.60535634 -1.8500288   1.0936711   0.01510016]] [Dz loss: [ 2.565709    1.1168381  -0.12881427  0.15776855]] [G loss: [ 0.07009514 -1.1379155   0.11529593  0.10927148]]\n",
            "Epoch: 34/35, [Dx loss: [-0.5439986  -1.7849518   1.0391957   0.02017576]] [Dz loss: [ 2.786107    1.0978009  -0.06883308  0.17571396]] [G loss: [ 0.02693755 -1.1015239   0.07090268  0.10575588]]\n",
            "Epoch: 35/35, [Dx loss: [-0.48921657 -2.3162613   1.6689104   0.01581342]] [Dz loss: [ 2.8431375   1.0180674  -0.06271246  0.18877828]] [G loss: [-0.57505244 -1.6856624   0.05139861  0.10592113]]\n",
            "precision 0.07633592156632685 Signal E-12\n",
            "recall 0.0860585857623214 Signal E-12\n",
            "Accuracy 0.8665256454609939 Signal E-12\n",
            "F1 0.08090620256714394 Signal E-12\n",
            "Epoch: 1/35, [Dx loss: [-2.9036925  -6.2836123   0.6051279   0.27747926]] [Dz loss: [ 2.7696705  -0.1772714   2.2968307   0.06501116]] [G loss: [ 3.0555487  -0.48733413 -1.9842768   0.55271596]]\n",
            "Epoch: 2/35, [Dx loss: [-3.4306073  -5.7907214   1.5860267   0.07740876]] [Dz loss: [-2.5782924  -0.0844954  -3.4643867   0.09705896]] [G loss: [10.157449   -0.95856786  7.063271    0.4052746 ]]\n",
            "Epoch: 3/35, [Dx loss: [-2.4691508 -0.7503373 -2.13213    0.0413316]] [Dz loss: [-1.6842287   0.13605937 -3.073684    0.12533957]] [G loss: [10.485172   1.9728186  4.0071244  0.4505229]]\n",
            "Epoch: 4/35, [Dx loss: [-3.4662495  -1.9222122  -2.0872173   0.05431801]] [Dz loss: [3.8974795  0.1654595  2.5791512  0.11528695]] [G loss: [ 5.6550417  2.6281667 -1.3393692  0.4366244]]\n",
            "Epoch: 5/35, [Dx loss: [-3.490971   -3.4363618  -0.5347393   0.04801296]] [Dz loss: [-1.2455751   0.2288522  -3.3864677   0.19120403]] [G loss: [13.1004925   0.3521939   8.327206    0.44210917]]\n",
            "Epoch: 6/35, [Dx loss: [-2.4416118  -4.9453926   2.0765257   0.04272545]] [Dz loss: [ -9.190062     0.5884998  -10.92993      0.11513706]] [G loss: [15.756956   -2.0004127  13.697232    0.40601355]]\n",
            "Epoch: 7/35, [Dx loss: [-2.3514905 -6.25068    3.4539783  0.0445212]] [Dz loss: [-0.04861426  0.9291765  -2.930397    0.19526058]] [G loss: [ 3.6888118 -3.3704524  3.3639553  0.3695309]]\n",
            "Epoch: 8/35, [Dx loss: [-2.291862   -8.926177    6.213424    0.04208904]] [Dz loss: [-0.17454717  1.0557702  -2.2845945   0.10542773]] [G loss: [ 0.04406074 -6.5970054   2.965743    0.36753225]]\n",
            "Epoch: 9/35, [Dx loss: [ -1.6755865  -12.07859     10.252739     0.01502665]] [Dz loss: [-1.3160568   1.1082783  -3.3608868   0.09365515]] [G loss: [ -2.7218533  -10.201705     3.8215325    0.36583188]]\n",
            "Epoch: 10/35, [Dx loss: [-1.3563001  -7.5454283   5.949584    0.02395436]] [Dz loss: [-1.5436354   1.2496254  -3.7450573   0.09517957]] [G loss: [ 2.0815425 -5.186829   4.067146   0.3201226]]\n",
            "Epoch: 11/35, [Dx loss: [-1.495846    2.2084293  -3.96194     0.02576642]] [Dz loss: [ 0.8647358  1.2419693 -1.5059564  0.1128723]] [G loss: [8.884103   4.357772   1.5822111  0.29441208]]\n",
            "Epoch: 12/35, [Dx loss: [-1.1040261  -2.3442426   1.0074384   0.02327786]] [Dz loss: [ 2.0008342   1.1219251  -0.06408545  0.09429943]] [G loss: [ 0.863709   -1.5175656   0.06844495  0.23128298]]\n",
            "Epoch: 13/35, [Dx loss: [-0.517877   -1.5984619   0.91506356  0.01655212]] [Dz loss: [2.2005317  1.07636    0.16850099 0.09556711]] [G loss: [ 2.1798754   0.49401033 -0.12565167  0.1811517 ]]\n",
            "Epoch: 14/35, [Dx loss: [ -1.0904648    9.577651   -10.793808     0.01256957]] [Dz loss: [ 1.8374792   1.02319    -0.12978712  0.09440768]] [G loss: [12.041874   10.354955    0.21372212  0.14731961]]\n",
            "Epoch: 15/35, [Dx loss: [-1.089031    4.2475953  -5.452119    0.01154929]] [Dz loss: [ 1.5105658   1.0215023  -0.43979797  0.09288616]] [G loss: [6.833397  5.248947  0.481478  0.1102972]]\n",
            "Epoch: 16/35, [Dx loss: [-0.8669464   2.1044514  -3.1110723   0.01396747]] [Dz loss: [ 1.3755378   0.9926535  -0.50840074  0.08912848]] [G loss: [4.443788   3.01416    0.5296038  0.09000242]]\n",
            "Epoch: 17/35, [Dx loss: [-0.8638567  -2.2248044   1.1999695   0.01609782]] [Dz loss: [ 1.4601641  0.9485534 -0.3830736  0.0894684]] [G loss: [-0.02516802 -1.3551832   0.3890854   0.09409298]]\n",
            "Epoch: 18/35, [Dx loss: [-0.975602   -1.2956909   0.17946188  0.01406271]] [Dz loss: [ 1.5721158   0.900735   -0.18439028  0.08557709]] [G loss: [ 0.78569204 -0.29347423  0.18713164  0.08920346]]\n",
            "Epoch: 19/35, [Dx loss: [-0.8544224  -2.0686548   1.082204    0.01320287]] [Dz loss: [1.702132   0.83042765 0.0173843  0.08543202]] [G loss: [ 0.14944336 -0.7362951  -0.02523691  0.09109753]]\n",
            "Epoch: 20/35, [Dx loss: [-0.76968426  1.6645193  -2.5682867   0.01340829]] [Dz loss: [1.732263   0.79124403 0.09304084 0.0847978 ]] [G loss: [ 2.9783711   2.1989646  -0.06191821  0.08413247]]\n",
            "Epoch: 21/35, [Dx loss: [-0.71771115 -3.3840535   2.519851    0.01464919]] [Dz loss: [ 1.6493638   0.7712948  -0.00710272  0.08851714]] [G loss: [-1.4726634  -2.3828208   0.05898277  0.08511746]]\n",
            "Epoch: 22/35, [Dx loss: [-0.5613634   5.571636   -6.2391386   0.01061396]] [Dz loss: [ 1.3540602   0.77322257 -0.22648561  0.08073234]] [G loss: [8.241852   7.1953025  0.2529854  0.07935648]]\n",
            "Epoch: 23/35, [Dx loss: [-6.963037e-01  8.980810e+00 -9.755869e+00  7.875708e-03]] [Dz loss: [ 1.2997754   0.75802314 -0.25278702  0.07945395]] [G loss: [10.826307    9.672511    0.27819082  0.08756053]]\n",
            "Epoch: 24/35, [Dx loss: [ -0.6733197   10.669954   -11.459543     0.01162709]] [Dz loss: [ 1.5380414   0.7310586  -0.01602381  0.08230069]] [G loss: [12.382653   11.510143    0.04119774  0.08313119]]\n",
            "Epoch: 25/35, [Dx loss: [-0.724247    9.017466   -9.877755    0.01360426]] [Dz loss: [1.8181412  0.73322487 0.20253694 0.08823791]] [G loss: [10.345091    9.620379   -0.17785968  0.09025719]]\n",
            "Epoch: 26/35, [Dx loss: [-0.59282655 -1.7337059   0.96005476  0.01808246]] [Dz loss: [1.800175   0.73329204 0.17273772 0.08941452]] [G loss: [-0.8599169  -1.6255078  -0.1710712   0.09366623]]\n",
            "Epoch: 27/35, [Dx loss: [-5.0253409e-01 -7.0157690e+00  6.4540596e+00  5.9177401e-03]] [Dz loss: [ 1.5947957   0.7299367  -0.00598241  0.08708416]] [G loss: [-5.3169775  -6.1754436   0.04768462  0.08107805]]\n",
            "Epoch: 28/35, [Dx loss: [-0.6374593   6.4120917  -7.155412    0.01058603]] [Dz loss: [ 1.6314968   0.7424339  -0.03660428  0.09256674]] [G loss: [9.519033   8.454873   0.09672987 0.09674303]]\n",
            "Epoch: 29/35, [Dx loss: [-6.6080338e-01  9.4957943e+00 -1.0220630e+01  6.4030625e-03]] [Dz loss: [ 1.5275687   0.65932006 -0.06286297  0.09311114]] [G loss: [10.843463    9.821171    0.10725835  0.09150335]]\n",
            "Epoch: 30/35, [Dx loss: [-0.5808936   3.831678   -4.5292697   0.01166988]] [Dz loss: [ 1.5234226   0.63555753 -0.04053584  0.09284009]] [G loss: [5.4849024  4.6724463  0.0417826  0.07706736]]\n",
            "Epoch: 31/35, [Dx loss: [-0.58332425  8.047452   -8.785087    0.01543101]] [Dz loss: [1.7124399  0.5533695  0.1756176  0.09834527]] [G loss: [ 9.71187     9.088268   -0.20039892  0.08240014]]\n",
            "Epoch: 32/35, [Dx loss: [-0.7508739   8.084028   -8.982395    0.01474932]] [Dz loss: [1.9621766  0.5220435  0.45731467 0.09828184]] [G loss: [ 8.895315    8.607273   -0.41621283  0.07042541]]\n",
            "Epoch: 33/35, [Dx loss: [-0.49547434  2.8076138  -3.4045727   0.01014843]] [Dz loss: [1.9944931  0.55492175 0.6061911  0.08333805]] [G loss: [ 3.5038743   3.2837272  -0.577934    0.07980813]]\n",
            "Epoch: 34/35, [Dx loss: [-6.7384273e-01  9.5104389e+00 -1.0283619e+01  9.9338070e-03]] [Dz loss: [1.6758251  0.6058915  0.18004528 0.0889888 ]] [G loss: [11.952871   11.206045   -0.0674808   0.08143075]]\n",
            "Epoch: 35/35, [Dx loss: [-8.39592576e-01  1.66807518e+01 -1.76401978e+01  1.19855525e-02]] [Dz loss: [ 0.7430932   0.7279257  -0.67763114  0.06927985]] [G loss: [18.811903   17.231121    0.7786278   0.08021539]]\n",
            "precision 0.3170731768519108 Signal E-13\n",
            "recall 0.4482758009033272 Signal E-13\n",
            "Accuracy 0.9541613398327138 Signal E-13\n",
            "F1 0.3714285546317367 Signal E-13\n",
            "Epoch: 1/35, [Dx loss: [-4.175506  -9.007507   1.1487503  0.368325 ]] [Dz loss: [3.5102944  0.03016039 2.743816   0.07363181]] [G loss: [ 2.4224408 -1.2016937 -2.2309923  0.5855126]]\n",
            "Epoch: 2/35, [Dx loss: [ -5.032828   -13.484159     7.728053     0.07232767]] [Dz loss: [-3.7037253   0.2643774  -4.9076223   0.09395204]] [G loss: [ 1.6428505  -7.9926896   9.447433    0.01881067]]\n",
            "Epoch: 3/35, [Dx loss: [-2.2873342e-01 -1.4212410e+01  1.3941089e+01  4.2584385e-03]] [Dz loss: [-6.154091    0.34070694 -7.4713326   0.0976534 ]] [G loss: [-5.3625579e+00 -1.4065108e+01  8.7025480e+00  3.1937336e-07]]\n",
            "Epoch: 4/35, [Dx loss: [ 4.0616143e-02 -1.4303164e+01  1.4320600e+01  2.3175695e-03]] [Dz loss: [17.669075    0.2431877  16.51741     0.09084736]] [G loss: [-2.7890718e+01 -1.4201903e+01 -1.3688816e+01  4.3996138e-08]]\n",
            "Epoch: 5/35, [Dx loss: [ 8.59713741e-03 -1.43392515e+01  1.43245640e+01  2.32798327e-03]] [Dz loss: [-20.28308      0.42129293 -21.864285     0.1159914 ]] [G loss: [ 2.7369343e+01 -1.4393298e+01  4.1762642e+01  7.7327078e-09]]\n",
            "Epoch: 6/35, [Dx loss: [ 5.0004113e-02 -1.4713135e+01  1.4736837e+01  2.6303113e-03]] [Dz loss: [-186.55855      1.1360339 -199.63791      1.1943297]] [G loss: [ 2.1806711e+02 -1.4700615e+01  2.3276772e+02  7.9609175e-10]]\n",
            "Epoch: 7/35, [Dx loss: [ 3.5510734e-02 -1.5429480e+01  1.5441035e+01  2.3956182e-03]] [Dz loss: [8.155859   1.9086297  4.9643326  0.12828976]] [G loss: [-9.2744875e+00 -1.5530905e+01  6.2564173e+00  4.9907786e-11]]\n",
            "Epoch: 8/35, [Dx loss: [-7.1347235e-03 -1.6124170e+01  1.6094816e+01  2.2218537e-03]] [Dz loss: [ 3.3295894   2.27268    -0.24352756  0.13004363]] [G loss: [-1.1745352e+01 -1.6166649e+01  4.4212985e+00  2.4418089e-12]]\n",
            "Epoch: 9/35, [Dx loss: [ 1.6481319e-02 -1.6387218e+01  1.6377529e+01  2.6168765e-03]] [Dz loss: [7.3730865  2.1864276  3.2993844  0.18872735]] [G loss: [-1.8498367e+01 -1.6438648e+01 -2.0597196e+00  3.5675367e-12]]\n",
            "Epoch: 10/35, [Dx loss: [ 3.7801705e-02 -1.6404463e+01  1.6415764e+01  2.6495564e-03]] [Dz loss: [-3.7986825   2.1585462  -7.5139723   0.15567425]] [G loss: [-5.5983291e+00 -1.6407513e+01  1.0809183e+01  3.6588137e-12]]\n",
            "Epoch: 11/35, [Dx loss: [-4.8497692e-03 -1.6756781e+01  1.6729681e+01  2.2249655e-03]] [Dz loss: [-23.560884     2.1207666  -28.04361      0.23619616]] [G loss: [ 1.6524788e+01 -1.6833454e+01  3.3358242e+01  6.4310792e-12]]\n",
            "Epoch: 12/35, [Dx loss: [ 8.1269396e-03 -1.7590191e+01  1.7573193e+01  2.5127712e-03]] [Dz loss: [-27.411133    2.2009106 -34.72137     0.5109339]] [G loss: [ 1.9894367e+01 -1.7627268e+01  3.7521633e+01  4.8227546e-13]]\n",
            "Epoch: 13/35, [Dx loss: [ 2.6497155e-02 -1.7752737e+01  1.7759359e+01  1.9876226e-03]] [Dz loss: [-1.141       2.4732313  -5.95275     0.23385188]] [G loss: [-1.0495064e+01 -1.7723261e+01  7.2281981e+00  2.0969528e-12]]\n",
            "Epoch: 14/35, [Dx loss: [ 3.4447283e-02 -1.7622204e+01  1.7635410e+01  2.1239656e-03]] [Dz loss: [ -6.2891245    2.6049237  -11.991218     0.30971694]] [G loss: [-4.3214583e+00 -1.7607281e+01  1.3285822e+01  2.5135113e-12]]\n",
            "Epoch: 15/35, [Dx loss: [ 2.6309595e-02 -1.7467314e+01  1.7475090e+01  1.8534383e-03]] [Dz loss: [ -5.38569      2.6036496  -10.368656     0.23793156]] [G loss: [-6.0381222e+00 -1.7571264e+01  1.1533142e+01  6.8868964e-12]]\n",
            "Epoch: 16/35, [Dx loss: [ 3.1119132e-02 -1.7891533e+01  1.7902174e+01  2.0476934e-03]] [Dz loss: [ 0.26102933  2.514381   -3.6886113   0.14352603]] [G loss: [-1.3855253e+01 -1.7933460e+01  4.0782084e+00  8.4431431e-14]]\n",
            "Epoch: 17/35, [Dx loss: [ 1.7376876e-02 -1.8194921e+01  1.8191362e+01  2.0934890e-03]] [Dz loss: [ 0.49040452  2.3815265  -3.7268448   0.18357225]] [G loss: [-1.4001343e+01 -1.8233765e+01  4.2324228e+00  6.7325031e-14]]\n",
            "Epoch: 18/35, [Dx loss: [ 5.4504462e-02 -1.8554857e+01  1.8584738e+01  2.4624565e-03]] [Dz loss: [ -5.615467     2.3021579  -10.256655     0.23390296]] [G loss: [-7.0853543e+00 -1.8491659e+01  1.1406305e+01  4.3200584e-14]]\n",
            "Epoch: 19/35, [Dx loss: [-3.2938484e-02 -1.8643276e+01  1.8588577e+01  2.1763274e-03]] [Dz loss: [-4.2286468   2.2767053  -8.242804    0.17374519]] [G loss: [-1.0373206e+01 -1.8646118e+01  8.2729130e+00  5.5354970e-12]]\n",
            "Epoch: 20/35, [Dx loss: [ 3.2101702e-02 -1.8718845e+01  1.8730139e+01  2.0811004e-03]] [Dz loss: [ -6.291503     2.3349118  -10.147573     0.15211579]] [G loss: [-7.1344299e+00 -1.8633631e+01  1.1499201e+01  2.1596245e-12]]\n",
            "Epoch: 21/35, [Dx loss: [ 3.4518443e-02 -1.8355371e+01  1.8365911e+01  2.3977004e-03]] [Dz loss: [-14.961214     2.430101   -20.77068      0.33793622]] [G loss: [ 3.6517162e+00 -1.8324532e+01  2.1976246e+01  2.8012523e-13]]\n",
            "Epoch: 22/35, [Dx loss: [ 4.1265186e-02 -1.8096245e+01  1.8114647e+01  2.2862705e-03]] [Dz loss: [ -9.105556     2.4745345  -15.297089     0.37169975]] [G loss: [-1.7119354e+00 -1.8163837e+01  1.6451902e+01  8.4041796e-14]]\n",
            "Epoch: 23/35, [Dx loss: [ 2.9280970e-02 -1.7640263e+01  1.7648918e+01  2.0623466e-03]] [Dz loss: [-15.486653     2.50667    -20.664503     0.26711747]] [G loss: [ 4.9297686e+00 -1.7586082e+01  2.2515852e+01  3.3137243e-14]]\n",
            "Epoch: 24/35, [Dx loss: [ 1.6446102e-02 -1.8277338e+01  1.8275047e+01  1.8734727e-03]] [Dz loss: [ -7.3696494    2.6399004  -13.103955     0.30944046]] [G loss: [-4.4883690e+00 -1.8332472e+01  1.3844105e+01  3.9669101e-14]]\n",
            "Epoch: 25/35, [Dx loss: [ 8.8449102e-03 -1.8887699e+01  1.8874887e+01  2.1659196e-03]] [Dz loss: [-4.601945    2.6855443  -9.137561    0.18500714]] [G loss: [-8.2233963e+00 -1.8931389e+01  1.0707993e+01  1.3902223e-11]]\n",
            "Epoch: 26/35, [Dx loss: [-4.3661785e-03 -1.9215897e+01  1.9191484e+01  2.0044595e-03]] [Dz loss: [ -8.787195     2.6946697  -14.204544     0.27226782]] [G loss: [-1.5632041e+00 -1.9302473e+01  1.7739269e+01  3.0988212e-10]]\n",
            "Epoch: 27/35, [Dx loss: [ 3.5905894e-02 -1.9601849e+01  1.9617664e+01  2.0091541e-03]] [Dz loss: [-12.162619     2.794272   -17.748991     0.27920982]] [G loss: [-6.6993248e-01 -1.9528156e+01  1.8858223e+01  3.2500877e-11]]\n",
            "Epoch: 28/35, [Dx loss: [ 1.2371119e-03 -1.9469172e+01  1.9448965e+01  2.1446138e-03]] [Dz loss: [ -7.482114     2.8585     -12.328547     0.19879334]] [G loss: [-5.7304153e+00 -1.9429729e+01  1.3699315e+01  8.7276859e-14]]\n",
            "Epoch: 29/35, [Dx loss: [ 5.1394992e-02 -1.9635328e+01  1.9661037e+01  2.5682417e-03]] [Dz loss: [ -9.820104     2.7920287  -15.528842     0.29167116]] [G loss: [-2.6383388e+00 -1.9664261e+01  1.7025921e+01  7.0009482e-14]]\n",
            "Epoch: 30/35, [Dx loss: [-2.4972657e-02 -2.0083895e+01  2.0036854e+01  2.2069868e-03]] [Dz loss: [-13.950369     2.795323   -20.463932     0.37182385]] [G loss: [ 1.5126135e+00 -2.0179884e+01  2.1692497e+01  5.0076401e-14]]\n",
            "Epoch: 31/35, [Dx loss: [ 4.5132063e-02 -2.0268085e+01  2.0292492e+01  2.0730160e-03]] [Dz loss: [ -6.9978547    2.8896747  -14.01516      0.41276294]] [G loss: [-5.3233433e+00 -2.0187809e+01  1.4864468e+01  4.0247665e-14]]\n",
            "Epoch: 32/35, [Dx loss: [ 5.2570980e-02 -1.9341715e+01  1.9373343e+01  2.0941703e-03]] [Dz loss: [-0.13458028  2.8638906  -4.996002    0.19975312]] [G loss: [-1.4281897e+01 -1.9318989e+01  5.0370922e+00  4.9800787e-14]]\n",
            "Epoch: 33/35, [Dx loss: [ 5.8150113e-02 -1.9005442e+01  1.9042856e+01  2.0734689e-03]] [Dz loss: [ 1.031718   2.6610765 -3.0221782  0.139282 ]] [G loss: [-1.5951543e+01 -1.9111492e+01  3.1599503e+00  6.8648632e-14]]\n",
            "Epoch: 34/35, [Dx loss: [ 1.3971192e-02 -1.8835426e+01  1.8828859e+01  2.0536953e-03]] [Dz loss: [ 0.7922909   2.5274978  -2.9833646   0.12481569]] [G loss: [-1.5575437e+01 -1.8702118e+01  3.1266820e+00  7.1847185e-14]]\n",
            "Epoch: 35/35, [Dx loss: [-1.8503394e-02 -1.9337194e+01  1.9297955e+01  2.0737918e-03]] [Dz loss: [ 0.81336486  2.4774644  -2.9647102   0.13006103]] [G loss: [-1.6245632e+01 -1.9321478e+01  3.0758443e+00  7.3460755e-14]]\n",
            "precision 0.48837223073529534 Signal A-1\n",
            "recall 1.0 Signal A-1\n",
            "Accuracy 0.9898136358374812 Signal A-1\n",
            "F1 0.6562501243308289 Signal A-1\n",
            "Epoch: 1/35, [Dx loss: [ 1.4267881  -0.76558477  0.26918015  0.19231927]] [Dz loss: [ 1.0668652  -0.43843812  0.53749603  0.09678072]] [G loss: [ 0.12565698 -0.3127727  -0.49782902  0.09362587]]\n",
            "Epoch: 2/35, [Dx loss: [-0.4763121  -3.5992036   2.9511998   0.01716921]] [Dz loss: [ 9.258758   -0.7877093   8.807228    0.12392386]] [G loss: [-6.467604   -3.206062   -5.0976667   0.18361245]]\n",
            "Epoch: 3/35, [Dx loss: [-0.96039593 -7.772699    6.623568    0.0188733 ]] [Dz loss: [-38.22717     -0.9863699  -39.695976     0.24551766]] [G loss: [48.490833   -6.302828   53.15551     0.16381523]]\n",
            "Epoch: 4/35, [Dx loss: [-1.7236468  -4.3785443   2.4706054   0.01842922]] [Dz loss: [13.07565   -0.7551898  8.814871   0.5015971]] [G loss: [-3.021967   -2.4691858  -1.7599115   0.12071311]]\n",
            "Epoch: 5/35, [Dx loss: [-1.4090809  -4.5962095   3.0694227   0.01177055]] [Dz loss: [-11.520527     0.24671355 -13.362253     0.15950125]] [G loss: [12.245723   -3.0667884  14.276852    0.10356595]]\n",
            "Epoch: 6/35, [Dx loss: [-0.75809276 -5.2597036   4.340837    0.01607735]] [Dz loss: [-121.72695       1.1845965  -125.36684       0.24552679]] [G loss: [ 1.4313976e+02 -4.4531989e+00  1.4657684e+02  1.0161132e-01]]\n",
            "Epoch: 7/35, [Dx loss: [-1.1443369  -9.318075    7.981209    0.01925281]] [Dz loss: [-156.58081      1.8607566 -164.7421       0.6300528]] [G loss: [ 1.7349440e+02 -8.1148624e+00  1.8046033e+02  1.1489234e-01]]\n",
            "Epoch: 8/35, [Dx loss: [-0.722963   -7.68834     6.7864394   0.01789371]] [Dz loss: [-24.3905       2.206612   -35.19369      0.85965806]] [G loss: [32.41141    -6.545277   37.723904    0.12327797]]\n",
            "Epoch: 9/35, [Dx loss: [-1.2551383  -6.20909     4.833979    0.01199742]] [Dz loss: [ 3.706103   2.215158  -2.2491832  0.3740128]] [G loss: [-1.6465504  -4.8193774   1.8948298   0.12779972]]\n",
            "Epoch: 10/35, [Dx loss: [-1.0816197  -6.110701    4.9440217   0.00850603]] [Dz loss: [7.6411963 2.1042733 3.0228648 0.2514057]] [G loss: [-6.3045707  -4.9743404  -2.4315803   0.11013499]]\n",
            "Epoch: 11/35, [Dx loss: [-0.5866244 -6.562909   5.632189   0.0344096]] [Dz loss: [9.478522   2.010489   5.6607513  0.18072832]] [G loss: [-9.361306   -5.495677   -4.9732294   0.11075988]]\n",
            "Epoch: 12/35, [Dx loss: [ -0.82915294 -12.758535    11.578707     0.03506792]] [Dz loss: [5.887615  1.9156189 2.3893452 0.1582651]] [G loss: [-11.651503   -11.732747    -0.95846367   0.10397078]]\n",
            "Epoch: 13/35, [Dx loss: [-4.4090134e-01 -1.0239733e+01  9.7018137e+00  9.7019952e-03]] [Dz loss: [-6.227384    2.0180118  -9.435241    0.11898442]] [G loss: [ 2.9141448  -9.397918   11.322262    0.09898011]]\n",
            "Epoch: 14/35, [Dx loss: [-1.0119908  -7.7506614   6.5511274   0.01875426]] [Dz loss: [-20.36364      2.0590317  -23.740421     0.13177508]] [G loss: [21.281391   -6.198686   26.495312    0.09847671]]\n",
            "Epoch: 15/35, [Dx loss: [-0.68092245 -8.810617    8.030047    0.00996486]] [Dz loss: [-14.980868     2.2781498  -20.424238     0.31652167]] [G loss: [15.453069 -8.147665 22.401743  0.119899]]\n",
            "Epoch: 16/35, [Dx loss: [-0.9447997  -8.166702    7.0520835   0.01698203]] [Dz loss: [-1.608119    2.337689   -7.402011    0.34562024]] [G loss: [ 2.209122   -7.00434     7.8271227   0.13863394]]\n",
            "Epoch: 17/35, [Dx loss: [-0.9078228  -8.507072    7.492509    0.01067389]] [Dz loss: [ 2.7149575   2.298182   -2.0996265   0.25164017]] [G loss: [-4.121257   -7.4910693   2.1776147   0.11921978]]\n",
            "Epoch: 18/35, [Dx loss: [-0.4999053  -8.784002    8.156819    0.01272771]] [Dz loss: [ 0.996679    2.2750726  -3.756261    0.24778669]] [G loss: [-2.233048   -7.907046    4.578053    0.10959451]]\n",
            "Epoch: 19/35, [Dx loss: [-0.970054   -9.582018    8.514282    0.00976822]] [Dz loss: [-0.45746523  2.2681375  -4.685403    0.1959801 ]] [G loss: [-2.7542129  -8.827966    4.933692    0.11400615]]\n",
            "Epoch: 20/35, [Dx loss: [ -0.7250694  -11.57229     10.699522     0.01476968]] [Dz loss: [ 1.1094213   2.2599938  -2.7849388   0.16343667]] [G loss: [ -6.729989   -10.573827     2.8231819    0.10206563]]\n",
            "Epoch: 21/35, [Dx loss: [-1.2927887  -8.922803    7.437655    0.01923586]] [Dz loss: [ 2.5929494   2.219271   -1.8264719   0.22001502]] [G loss: [-4.2745967  -7.2809362   1.9046553   0.11016843]]\n",
            "Epoch: 22/35, [Dx loss: [-0.58033496 -7.9552407   7.2367196   0.01381854]] [Dz loss: [ 2.0019772  2.169226  -1.9926809  0.1825432]] [G loss: [-3.5822792  -6.9095755   2.2005317   0.11267646]]\n",
            "Epoch: 23/35, [Dx loss: [-0.61593163 -5.693511    4.929242    0.01483381]] [Dz loss: [ 1.245055    2.1638398  -2.7215562   0.18027717]] [G loss: [-0.48632383 -4.6552024   2.804469    0.13644098]]\n",
            "Epoch: 24/35, [Dx loss: [-0.5197901 -9.261029   8.628567   0.0112672]] [Dz loss: [ 1.6389246  2.110434  -1.9736106  0.1502101]] [G loss: [-5.717574  -8.8667     2.0425649  0.1106561]]\n",
            "Epoch: 25/35, [Dx loss: [-7.2474903e-01 -1.0757521e+01  9.9346380e+00  9.8134410e-03]] [Dz loss: [ 2.539953   2.0814247 -1.0577502  0.1516279]] [G loss: [ -8.061798   -10.166284     1.0901442    0.10143419]]\n",
            "Epoch: 26/35, [Dx loss: [ -0.68132836 -10.805124     9.969911     0.0153884 ]] [Dz loss: [ 3.0631623   2.0019207  -0.42760077  0.14888422]] [G loss: [-8.256759   -9.816216    0.46242312  0.10970349]]\n",
            "Epoch: 27/35, [Dx loss: [-0.5174456  -9.218161    8.562749    0.01379663]] [Dz loss: [ 2.8727381   1.9348338  -0.3367479   0.12746516]] [G loss: [-6.7227597  -8.190302    0.43565524  0.10318874]]\n",
            "Epoch: 28/35, [Dx loss: [-0.80254614 -6.65866     5.772904    0.00832105]] [Dz loss: [ 1.6579263  1.8587824 -1.293609   0.1092753]] [G loss: [-3.4244962  -5.8129253   1.418979    0.09694497]]\n",
            "Epoch: 29/35, [Dx loss: [-0.6788124  -6.210889    5.438345    0.00937318]] [Dz loss: [ 0.81416255  1.8377272  -1.9626974   0.09391326]] [G loss: [-2.3233738  -5.497284    2.1257668   0.10481437]]\n",
            "Epoch: 30/35, [Dx loss: [-0.5487175  -9.020021    8.33747     0.01338344]] [Dz loss: [ 2.0886035   1.8795801  -0.8865015   0.10955247]] [G loss: [-6.7001514  -8.6390915   0.9388732   0.10000674]]\n",
            "Epoch: 31/35, [Dx loss: [ -1.0411913  -11.894775    10.708296     0.01452879]] [Dz loss: [ 1.9228048   1.7771356  -1.0476205   0.11932898]] [G loss: [ -8.763586   -10.8101       1.0773859    0.09691285]]\n",
            "Epoch: 32/35, [Dx loss: [-6.5949267e-01 -1.1458207e+01  1.0694700e+01  1.0401534e-02]] [Dz loss: [ 1.7798874   1.7730347  -1.1070797   0.11139324]] [G loss: [ -8.403185   -10.523053     1.161816     0.09580526]]\n",
            "Epoch: 33/35, [Dx loss: [-0.57640636 -9.614367    8.914175    0.01237846]] [Dz loss: [ 0.7074951   1.7325232  -2.0354578   0.10104295]] [G loss: [-5.5353055  -8.6661      2.0655165   0.10652773]]\n",
            "Epoch: 34/35, [Dx loss: [-0.860268  -6.1502953  5.179758   0.011027 ]] [Dz loss: [ 1.5970705   1.7649063  -1.2670112   0.10991752]] [G loss: [-2.679567   -4.989656    1.352718    0.09573707]]\n",
            "Epoch: 35/35, [Dx loss: [-0.6746282  -6.772358    5.9866      0.01111297]] [Dz loss: [ 1.8623426   1.6982784  -0.95169795  0.11157622]] [G loss: [-4.24068    -6.1974487   1.0370303   0.09197381]]\n",
            "precision 1.0 Signal D-1\n",
            "recall 0.058931873409444085 Signal D-1\n",
            "Accuracy 0.6396332882796949 Signal D-1\n",
            "F1 0.1113043716772847 Signal D-1\n",
            "Epoch: 1/35, [Dx loss: [ 0.28029788 -2.0253425   0.4460445   0.1859596 ]] [Dz loss: [ 1.5018127  -0.61709267  1.1074      0.10115054]] [G loss: [-0.45793653 -0.43232298 -1.0240738   0.09984604]]\n",
            "Epoch: 2/35, [Dx loss: [-0.06801764 -3.1166463   2.8544211   0.01942074]] [Dz loss: [12.925921   -0.71420056 12.431899    0.12082197]] [G loss: [-7.9601517  -2.8808174  -6.972558    0.18932241]]\n",
            "Epoch: 3/35, [Dx loss: [-1.0028895  -5.844957    4.5611377   0.02809301]] [Dz loss: [-25.273014   -0.8169945 -27.488565    0.3032547]] [G loss: [34.580563   -4.4751277  37.471905    0.15837893]]\n",
            "Epoch: 4/35, [Dx loss: [-0.15179202 -4.9632335   4.6327066   0.01787351]] [Dz loss: [-13.744986   -1.0461295 -16.52037     0.3821512]] [G loss: [25.353815   -4.3829107  28.649563    0.10871617]]\n",
            "Epoch: 5/35, [Dx loss: [-1.4419146  -6.1136923   4.395868    0.02759106]] [Dz loss: [50.332462  -0.7019153 46.864784   0.4169601]] [G loss: [-31.127287    -4.4560413  -27.618223     0.09469753]]\n",
            "Epoch: 6/35, [Dx loss: [-1.0053724  -6.687837    5.5127287   0.01697362]] [Dz loss: [-19.841915     0.163064   -21.867378     0.18623988]] [G loss: [39.373848  -5.6741776 44.098602   0.0949423]]\n",
            "Epoch: 7/35, [Dx loss: [ -0.16986568 -11.992933    11.450015     0.03730541]] [Dz loss: [-146.36267       1.1476252  -150.61226       0.31019482]] [G loss: [ 1.8317435e+02 -1.1544263e+01  1.9372960e+02  9.8901659e-02]]\n",
            "Epoch: 8/35, [Dx loss: [ -2.0377288 -10.573655    8.201835    0.0334092]] [Dz loss: [-284.13275      1.9490763 -297.9245       1.1842692]] [G loss: [ 3.1908868e+02 -7.5225277e+00  3.2569635e+02  9.1486730e-02]]\n",
            "Epoch: 9/35, [Dx loss: [-0.12033367 -3.388886    3.1627355   0.01058163]] [Dz loss: [-127.89156      2.5935829 -145.54538      1.5060228]] [G loss: [ 1.6839676e+02 -2.4411831e+00  1.6993530e+02  9.0266652e-02]]\n",
            "Epoch: 10/35, [Dx loss: [ -1.1432449   11.49143    -12.921842     0.02871664]] [Dz loss: [-26.00433     2.627339  -34.513725    0.5882061]] [G loss: [1.0296174e+02 1.3765956e+01 8.8244263e+01 9.5151834e-02]]\n",
            "Epoch: 11/35, [Dx loss: [ -0.9982208   12.331826   -13.531276     0.02012296]] [Dz loss: [-527.935        2.6892283 -538.81146      0.8187264]] [G loss: [6.2918652e+02 1.3527890e+01 6.1476819e+02 8.9040935e-02]]\n",
            "Epoch: 12/35, [Dx loss: [-1.0772693  6.7436705 -7.966738   0.0145798]] [Dz loss: [-336.48468      3.2248173 -354.7075       1.4998   ]] [G loss: [4.3206641e+02 7.4144673e+00 4.2374911e+02 9.0280399e-02]]\n",
            "Epoch: 13/35, [Dx loss: [-0.39067632 -3.7521596   3.2218711   0.0139612 ]] [Dz loss: [-667.02374     4.219025 -740.4424      6.919963]] [G loss: [ 8.6681189e+02 -4.5249200e+00  8.7041235e+02  9.2442773e-02]]\n",
            "Epoch: 14/35, [Dx loss: [ -1.0284117  -17.507307    16.248018     0.02308741]] [Dz loss: [-453.09625      5.4202857 -525.9456       6.742901 ]] [G loss: [ 5.6568378e+02 -1.5933406e+01  5.8067230e+02  9.4487160e-02]]\n",
            "Epoch: 15/35, [Dx loss: [-0.53233355 -8.172918    7.481723    0.01588625]] [Dz loss: [-323.33643      5.984772  -377.5275       4.8206267]] [G loss: [ 3.9619180e+02 -6.0173740e+00  4.0130878e+02  9.0040274e-02]]\n",
            "Epoch: 16/35, [Dx loss: [-1.0589188   4.321113   -5.556315    0.01762835]] [Dz loss: [ 10.734746    5.9953184 -56.88029     6.161971 ]] [G loss: [77.43748     5.5281568  70.99726     0.09120585]]\n",
            "Epoch: 17/35, [Dx loss: [-1.1335518   0.84217644 -2.1168861   0.01411579]] [Dz loss: [-34.64872     5.9761305 -76.1496      3.5524743]] [G loss: [9.1798820e+01 1.6737126e+00 8.9208687e+01 9.1642022e-02]]\n",
            "Epoch: 18/35, [Dx loss: [-0.90511495 -5.777408    4.766051    0.01062422]] [Dz loss: [ -0.19902149   5.906296   -58.19333      5.2088    ]] [G loss: [55.99266    -5.115357   60.20542     0.09025967]]\n",
            "Epoch: 19/35, [Dx loss: [-0.73952043 -9.441343    8.604422    0.00974006]] [Dz loss: [  0.24506387   5.7668004  -41.323402     3.5801659 ]] [G loss: [35.64707    -8.903987   43.65988     0.08911746]]\n",
            "Epoch: 20/35, [Dx loss: [-7.2501004e-01 -1.4049954e+01  1.3211850e+01  1.1309236e-02]] [Dz loss: [ -0.50257146   5.7543335  -42.99787      3.6740975 ]] [G loss: [ 30.901436   -13.619025    43.701855     0.08186038]]\n",
            "Epoch: 21/35, [Dx loss: [-5.2603179e-01 -1.5840701e+01  1.5243765e+01  7.0903962e-03]] [Dz loss: [ 24.455128    5.7563324 -25.871267    4.4570055]] [G loss: [ 13.022532   -14.703863    26.64486      0.10815345]]\n",
            "Epoch: 22/35, [Dx loss: [-0.87794197 -0.10812163 -0.93355113  0.01637307]] [Dz loss: [ 36.203274    5.5253158 -10.278303    4.095626 ]] [G loss: [12.987021    1.9875674  10.103132    0.08963219]]\n",
            "Epoch: 23/35, [Dx loss: [-0.62884307 -1.3077095   0.54524064  0.0133626 ]] [Dz loss: [37.86544    5.3475018 -5.0003657  3.7518303]] [G loss: [ 4.898366   -1.2513343   5.097542    0.10521588]]\n",
            "Epoch: 24/35, [Dx loss: [-3.2300657e-01 -1.3622681e+01  1.3181949e+01  1.1772560e-02]] [Dz loss: [34.670532   5.180713  -2.6240163  3.211383 ]] [G loss: [-10.061199  -13.661875    2.6575084   0.0943168]]\n",
            "Epoch: 25/35, [Dx loss: [-0.4721946  -9.24811     8.590052    0.01858615]] [Dz loss: [31.268728   4.9463925 -1.5278422  2.7850177]] [G loss: [-4.943262   -7.0650263   1.5078053   0.06139595]]\n",
            "Epoch: 26/35, [Dx loss: [-0.69990146  5.163179   -6.003567    0.01404863]] [Dz loss: [27.166874   4.665319  -0.8768361  2.3378384]] [G loss: [7.6709795  6.302998   0.8252598  0.05427223]]\n",
            "Epoch: 27/35, [Dx loss: [-0.49328002 -2.274504    1.6142979   0.01669263]] [Dz loss: [24.759699   4.2984257 -0.5520127  2.1013293]] [G loss: [-1.2694755  -2.3984401   0.54437524  0.05845894]]\n",
            "Epoch: 28/35, [Dx loss: [-5.5663455e-01 -1.9319927e+01  1.8646997e+01  1.1629403e-02]] [Dz loss: [20.919607    4.0628767  -0.26397523  1.7120705 ]] [G loss: [-18.99669    -19.802547     0.27502823   0.05308272]]\n",
            "Epoch: 29/35, [Dx loss: [-2.2818001e-01 -1.5436468e+01  1.5106905e+01  1.0138160e-02]] [Dz loss: [17.842163    3.7836406  -0.11884879  1.4177374 ]] [G loss: [-12.789177   -13.555231     0.12147918   0.06445752]]\n",
            "Epoch: 30/35, [Dx loss: [-0.39225018 -1.2050427   0.69347036  0.01193224]] [Dz loss: [1.6047726e+01 3.5421023e+00 9.1227086e-04 1.2504710e+00]] [G loss: [-0.07832682 -0.52279747 -0.01269921  0.04571698]]\n",
            "Epoch: 31/35, [Dx loss: [ -0.35858133 -10.537947    10.001936     0.01774304]] [Dz loss: [14.121225    3.1750145   0.08508034  1.0861129 ]] [G loss: [-10.982842   -11.403032    -0.08683193   0.05070221]]\n",
            "Epoch: 32/35, [Dx loss: [-5.4528564e-01 -2.3406748e+01  2.2744328e+01  1.1713439e-02]] [Dz loss: [11.964923    2.9326756   0.13598348  0.8896263 ]] [G loss: [-22.466219   -22.668873    -0.14369723   0.03463518]]\n",
            "Epoch: 33/35, [Dx loss: [-3.5527033e-01 -1.5089841e+01  1.4652911e+01  8.1662368e-03]] [Dz loss: [11.012693    2.6670957   0.18087393  0.81647223]] [G loss: [-13.367427   -13.595422    -0.18812507   0.04161209]]\n",
            "Epoch: 34/35, [Dx loss: [-0.49779528 -1.609245    1.0122648   0.00991848]] [Dz loss: [10.091358    2.53851     0.22138813  0.7331461 ]] [G loss: [-0.16430768 -0.37358165 -0.2160336   0.04253075]]\n",
            "Epoch: 35/35, [Dx loss: [-0.38329574 -2.98818     2.5163534   0.0088531 ]] [Dz loss: [9.252127   2.337506   0.25844425 0.66561764]] [G loss: [-3.3014915  -3.3592699  -0.26260328  0.03203816]]\n",
            "precision 0.9774919681160033 Signal P-3\n",
            "recall 0.22771541726607653 Signal P-3\n",
            "Accuracy 0.8777673158615517 Signal P-3\n",
            "F1 0.369380397255378 Signal P-3\n",
            "Epoch: 1/35, [Dx loss: [-4.3932176  -9.288875    1.4270737   0.34685832]] [Dz loss: [3.8716722  0.20105115 2.7555187  0.09151016]] [G loss: [ 1.835173  -1.498565  -2.401661   0.5735399]]\n",
            "Epoch: 2/35, [Dx loss: [ -4.450019   -11.104555     6.0560293    0.05985075]] [Dz loss: [-7.57718     0.4171126  -8.772997    0.07787044]] [G loss: [10.779792   -5.7960033  16.36625     0.02095465]]\n",
            "Epoch: 3/35, [Dx loss: [-1.0384443e-01 -1.0469404e+01  1.0311956e+01  5.3599719e-03]] [Dz loss: [-14.544817     0.7938376  -16.891504     0.15528549]] [G loss: [ 8.8042774e+00 -1.0493132e+01  1.9297323e+01  8.5632209e-06]]\n",
            "Epoch: 4/35, [Dx loss: [ 6.48012608e-02 -1.14508705e+01  1.14835100e+01  3.21638538e-03]] [Dz loss: [6.7379746  0.7628757  4.4199386  0.15551598]] [G loss: [-1.5380941e+01 -1.1594352e+01 -3.8620844e+00  7.5496421e-03]]\n",
            "Epoch: 5/35, [Dx loss: [ 2.5014449e-02 -1.2610810e+01  1.2616388e+01  1.9437004e-03]] [Dz loss: [20.511425    0.53450865 17.356245    0.26206675]] [G loss: [-2.7509001e+01 -1.2673754e+01 -1.4835247e+01  4.4445159e-12]]\n",
            "Epoch: 6/35, [Dx loss: [ 2.2986110e-02 -1.4251413e+01  1.4255511e+01  1.8885363e-03]] [Dz loss: [-15.748105     0.32326713 -19.93545      0.38640767]] [G loss: [ 1.8535419e+01 -1.4319495e+01  3.2854916e+01  3.2859594e-11]]\n",
            "Epoch: 7/35, [Dx loss: [ 2.2785638e-02 -1.4326414e+01  1.4330338e+01  1.8860506e-03]] [Dz loss: [-52.73982      0.28486317 -57.246574     0.42218924]] [G loss: [ 7.3744797e+01 -1.4287377e+01  8.8032173e+01  4.9962942e-12]]\n",
            "Epoch: 8/35, [Dx loss: [-3.9413013e-02 -1.4161726e+01  1.4103079e+01  1.9235946e-03]] [Dz loss: [-23.698727     1.0580829  -28.625683     0.38688755]] [G loss: [ 4.6731033e+01 -1.4036309e+01  6.0767342e+01  1.0238973e-12]]\n",
            "Epoch: 9/35, [Dx loss: [ 1.6759846e-02 -1.4260793e+01  1.4257051e+01  2.0497222e-03]] [Dz loss: [6.8568015  1.6236904  4.30742    0.09256937]] [G loss: [-1.6640068e+01 -1.4430691e+01 -2.2093771e+00  3.6570261e-14]]\n",
            "Epoch: 10/35, [Dx loss: [ 5.6866013e-02 -1.5401314e+01  1.5436404e+01  2.1776310e-03]] [Dz loss: [ -7.7685065    1.7933117  -10.367701     0.08058827]] [G loss: [ 1.5149248e+00 -1.5487594e+01  1.7002518e+01  5.9616273e-14]]\n",
            "Epoch: 11/35, [Dx loss: [ 9.2665628e-03 -1.6266190e+01  1.6253222e+01  2.2235673e-03]] [Dz loss: [-33.57879     2.0119452 -38.615833    0.3025117]] [G loss: [ 2.6989407e+01 -1.6267874e+01  4.3257282e+01  2.3575309e-14]]\n",
            "Epoch: 12/35, [Dx loss: [-8.7994142e-03 -1.6550072e+01  1.6520239e+01  2.1035927e-03]] [Dz loss: [-4.867545    2.073197   -9.28089     0.23401499]] [G loss: [-7.0397983e+00 -1.6642670e+01  9.6028700e+00  7.3149816e-15]]\n",
            "Epoch: 13/35, [Dx loss: [ 2.8372830e-02 -1.6907246e+01  1.6913774e+01  2.1846741e-03]] [Dz loss: [-0.52416015  2.122298   -3.9964383   0.13499801]] [G loss: [-1.2458784e+01 -1.6986876e+01  4.5280895e+00  3.7824050e-14]]\n",
            "Epoch: 14/35, [Dx loss: [ 2.9633865e-02 -1.6586639e+01  1.6595184e+01  2.1090326e-03]] [Dz loss: [-1.6482599   2.0424705  -5.2534065   0.15626755]] [G loss: [-1.0694025e+01 -1.6532299e+01  5.8382740e+00  5.3219656e-14]]\n",
            "Epoch: 15/35, [Dx loss: [ 1.8949619e-02 -1.6296787e+01  1.6292917e+01  2.2815815e-03]] [Dz loss: [-2.1916485  2.041736  -6.142486   0.19091  ]] [G loss: [-9.8608437e+00 -1.6312162e+01  6.4513187e+00  3.4282856e-14]]\n",
            "Epoch: 16/35, [Dx loss: [ 3.6693856e-02 -1.6335871e+01  1.6350918e+01  2.1649762e-03]] [Dz loss: [-0.9299685   2.064993   -4.6334276   0.16384669]] [G loss: [-1.1675216e+01 -1.6367140e+01  4.6919236e+00  8.2492344e-15]]\n",
            "Epoch: 17/35, [Dx loss: [ 7.3536783e-03 -1.6501854e+01  1.6489094e+01  2.0111506e-03]] [Dz loss: [ 1.0645283   1.9883254  -2.2144408   0.12906438]] [G loss: [-1.4226324e+01 -1.6460960e+01  2.2346351e+00  2.7947092e-15]]\n",
            "Epoch: 18/35, [Dx loss: [-1.2585011e-02 -1.6665846e+01  1.6632893e+01  2.0363252e-03]] [Dz loss: [ 1.2880533   1.937191   -1.9591401   0.13100022]] [G loss: [-1.4568335e+01 -1.6719639e+01  2.1513028e+00  5.7562288e-15]]\n",
            "Epoch: 19/35, [Dx loss: [ 4.0185068e-02 -1.7015951e+01  1.7033281e+01  2.2860325e-03]] [Dz loss: [ 0.10040762  1.9306991  -3.4850602   0.16547692]] [G loss: [-1.3293655e+01 -1.7051195e+01  3.7575400e+00  4.0456530e-15]]\n",
            "Epoch: 20/35, [Dx loss: [ 1.52584715e-02 -1.66609230e+01  1.66546135e+01  2.15646019e-03]] [Dz loss: [-0.4965756   1.9142517  -3.6111655   0.12003378]] [G loss: [-1.2816091e+01 -1.6601412e+01  3.7853208e+00  1.4979129e-14]]\n",
            "Epoch: 21/35, [Dx loss: [ 1.0668700e-02 -1.6720098e+01  1.6710270e+01  2.0497651e-03]] [Dz loss: [ 0.9522678   1.9303287  -2.037109    0.10590477]] [G loss: [-1.4650795e+01 -1.6747818e+01  2.0970249e+00  4.7660138e-14]]\n",
            "Epoch: 22/35, [Dx loss: [ 3.7421994e-02 -1.7215630e+01  1.7229961e+01  2.3092998e-03]] [Dz loss: [ 3.1394992   1.901158   -0.22448209  0.14628229]] [G loss: [-1.7031675e+01 -1.7304857e+01  2.7318147e-01  8.3671127e-14]]\n",
            "Epoch: 23/35, [Dx loss: [ 2.6925171e-02 -1.6948118e+01  1.6954344e+01  2.0695913e-03]] [Dz loss: [ 3.6314664   1.7695862  -0.0409318   0.19028111]] [G loss: [-1.6851213e+01 -1.6927822e+01  7.6607704e-02  3.0075524e-14]]\n",
            "Epoch: 24/35, [Dx loss: [ 4.9821764e-02 -1.6828354e+01  1.6859035e+01  1.9143822e-03]] [Dz loss: [ 2.6353168   1.6551206  -0.1917366   0.11719333]] [G loss: [-1.6553019e+01 -1.6839725e+01  2.8670600e-01  2.2554458e-14]]\n",
            "Epoch: 25/35, [Dx loss: [ 4.9624792e-03 -1.6493988e+01  1.6480473e+01  1.8478144e-03]] [Dz loss: [ 1.2349554   1.6410469  -1.3911989   0.09851079]] [G loss: [-1.4908854e+01 -1.6479061e+01  1.5702083e+00  2.5438747e-14]]\n",
            "Epoch: 26/35, [Dx loss: [ 4.6564367e-02 -1.6332626e+01  1.6360310e+01  1.8879224e-03]] [Dz loss: [-0.15473771  1.6163518  -2.776555    0.10054654]] [G loss: [-1.3423100e+01 -1.6380917e+01  2.9578156e+00  2.0457108e-14]]\n",
            "Epoch: 27/35, [Dx loss: [ 3.5782479e-02 -1.5969185e+01  1.5986898e+01  1.8067142e-03]] [Dz loss: [ 1.851814    1.6318057  -0.82633144  0.10463397]] [G loss: [-1.5169259e+01 -1.6011288e+01  8.4202909e-01  8.3087698e-15]]\n",
            "Epoch: 28/35, [Dx loss: [ 1.1631255e-02 -1.5127795e+01  1.5120929e+01  1.8497689e-03]] [Dz loss: [2.8427937  1.5150836  0.04417191 0.12835383]] [G loss: [-1.5081090e+01 -1.5022901e+01 -5.8188155e-02  4.1978224e-15]]\n",
            "Epoch: 29/35, [Dx loss: [ 1.4490122e-02 -1.4948471e+01  1.4942149e+01  2.0810405e-03]] [Dz loss: [3.1041322  1.430606   0.32910424 0.13444217]] [G loss: [-1.5260055e+01 -1.4955726e+01 -3.0432934e-01  3.6731033e-15]]\n",
            "Epoch: 30/35, [Dx loss: [ 3.0577336e-02 -1.5226625e+01  1.5237677e+01  1.9525366e-03]] [Dz loss: [2.9213777  1.410574   0.2527426  0.12580612]] [G loss: [-1.5523590e+01 -1.5320417e+01 -2.0317279e-01  4.0271953e-15]]\n",
            "Epoch: 31/35, [Dx loss: [ 4.2677470e-02 -1.5360380e+01  1.5383090e+01  1.9970178e-03]] [Dz loss: [ 1.8730036   1.3627121  -0.5170026   0.10272942]] [G loss: [-1.4699967e+01 -1.5327696e+01  6.2773013e-01  4.2515993e-15]]\n",
            "Epoch: 32/35, [Dx loss: [ 7.0385719e-03 -1.5243434e+01  1.5234085e+01  1.6390806e-03]] [Dz loss: [ 1.4890299   1.3655738  -0.82800025  0.09514564]] [G loss: [-1.4399979e+01 -1.5240854e+01  8.4087539e-01  9.7530321e-15]]\n",
            "Epoch: 33/35, [Dx loss: [ 3.1825309e-04 -1.5647829e+01  1.5629285e+01  1.8863718e-03]] [Dz loss: [ 1.5057313   1.3104607  -0.6693174   0.08645877]] [G loss: [-1.5028782e+01 -1.5734998e+01  7.0621592e-01  7.7059195e-15]]\n",
            "Epoch: 34/35, [Dx loss: [ 2.1841686e-02 -1.5986961e+01  1.5988886e+01  1.9918196e-03]] [Dz loss: [ 2.114716    1.3274856  -0.26984125  0.10570718]] [G loss: [-1.5739225e+01 -1.6000566e+01  2.6134044e-01  1.2912866e-14]]\n",
            "Epoch: 35/35, [Dx loss: [ 2.2233007e-02 -1.6149561e+01  1.6153711e+01  1.8081948e-03]] [Dz loss: [2.6095529  1.275331   0.04787298 0.1286349 ]] [G loss: [-1.6170963e+01 -1.6128260e+01 -4.2705733e-02  1.2302243e-14]]\n",
            "precision 1.0 Signal D-2\n",
            "recall 0.034384644226799765 Signal D-2\n",
            "Accuracy 0.5261810565510822 Signal D-2\n",
            "F1 0.06648328437339132 Signal D-2\n",
            "Epoch: 1/35, [Dx loss: [ 0.19101103 -2.5865695   0.52339345  0.22541872]] [Dz loss: [ 2.037658   -0.17702368  1.4891292   0.07255521]] [G loss: [ 0.20685154 -0.599929   -1.3568329   0.21636133]]\n",
            "Epoch: 2/35, [Dx loss: [-1.0518314 -5.492495   4.1830344  0.0257629]] [Dz loss: [1.0889428  0.13703156 0.1370349  0.08148758]] [G loss: [ 1.1376898 -4.0800457  3.0879228  0.2129813]]\n",
            "Epoch: 3/35, [Dx loss: [-1.8486226  -1.9483095  -0.44107658  0.05407631]] [Dz loss: [-4.034169    0.72968084 -5.790814    0.10269634]] [G loss: [13.405435   1.7259828  8.450364   0.3229087]]\n",
            "Epoch: 4/35, [Dx loss: [-1.4563632  3.3527474 -5.1049476  0.0295836]] [Dz loss: [-2.4314523   1.0790391  -4.4344983   0.09240062]] [G loss: [11.9869585  4.8898764  4.7738466  0.2323235]]\n",
            "Epoch: 5/35, [Dx loss: [ 0.20319124 -9.083216    8.674507    0.06119008]] [Dz loss: [ 0.25103635  1.1659255  -1.9798721   0.10649829]] [G loss: [-6.714771   -9.96519     2.147307    0.11031126]]\n",
            "Epoch: 6/35, [Dx loss: [ -2.9589877  -17.1804      13.864589     0.03568237]] [Dz loss: [ 1.0153661   1.1705923  -1.0928227   0.09375964]] [G loss: [-11.415743   -13.416612     1.160258     0.08406115]]\n",
            "Epoch: 7/35, [Dx loss: [ -1.3808064  -12.69351     11.143181     0.01695225]] [Dz loss: [ 0.9376928   1.327001   -1.1452549   0.07559467]] [G loss: [ -8.986094   -11.087854     1.2241331    0.08776257]]\n",
            "Epoch: 8/35, [Dx loss: [-0.22147088 -3.3038661   2.8544996   0.02278961]] [Dz loss: [ 1.2496346   1.4054044  -0.92497665  0.07692069]] [G loss: [ 1.3484969  -0.68933225  0.94611675  0.10917119]]\n",
            "Epoch: 9/35, [Dx loss: [ -0.83516026  11.571359   -12.650677     0.02441587]] [Dz loss: [ 1.7687289   1.3616898  -0.48645753  0.08934969]] [G loss: [13.663971   12.548534    0.50517213  0.06102645]]\n",
            "Epoch: 10/35, [Dx loss: [ 0.04919095  5.3501225  -5.491145    0.01902136]] [Dz loss: [ 1.6740853   1.2561061  -0.3830743   0.08010533]] [G loss: [5.103532   4.2856326  0.3990152  0.04188845]]\n",
            "Epoch: 11/35, [Dx loss: [-1.675894   -5.8882127   3.9281483   0.02841701]] [Dz loss: [ 1.7348295   1.1636817  -0.29681     0.08679583]] [G loss: [-3.0524654  -3.7644372   0.31414625  0.03978253]]\n",
            "Epoch: 12/35, [Dx loss: [-0.6685084  -5.5607543   4.7395334   0.01527124]] [Dz loss: [ 1.6792152   1.1172519  -0.24656768  0.08085311]] [G loss: [-3.7290401  -4.499049    0.24331725  0.05266921]]\n",
            "Epoch: 13/35, [Dx loss: [-0.25889578  6.917473   -7.4198084   0.02434392]] [Dz loss: [ 1.8166285   1.0822532  -0.14824969  0.08826248]] [G loss: [10.13476     9.455       0.15361662  0.05261429]]\n",
            "Epoch: 14/35, [Dx loss: [ -1.2293165   16.087791   -17.540764     0.02236584]] [Dz loss: [1.8323263  0.8714665  0.01639101 0.09444688]] [G loss: [ 1.7456133e+01  1.7110527e+01 -1.6317295e-02  3.6192372e-02]]\n",
            "Epoch: 15/35, [Dx loss: [ -0.67871535   9.963751   -10.766861     0.01243944]] [Dz loss: [1.9564393  0.73977786 0.1987798  0.10178813]] [G loss: [10.203515   10.111405   -0.19358611  0.02856952]]\n",
            "Epoch: 16/35, [Dx loss: [-0.8439695  -1.9896774   0.96441585  0.01812918]] [Dz loss: [2.0084047  0.59559166 0.46850973 0.09443036]] [G loss: [-1.8241806  -1.7396145  -0.43180364  0.03472375]]\n",
            "Epoch: 17/35, [Dx loss: [-0.8617803  -4.5089736   3.5031593   0.01440334]] [Dz loss: [1.9221503  0.58397365 0.5028087  0.0835368 ]] [G loss: [-3.0570638  -3.140173   -0.36362988  0.04467392]]\n",
            "Epoch: 18/35, [Dx loss: [-0.39982     5.1322093  -5.6800313   0.01480024]] [Dz loss: [ 1.302926    0.7237569  -0.21600285  0.07951719]] [G loss: [7.6237707  6.762474   0.3728903  0.04884062]]\n",
            "Epoch: 19/35, [Dx loss: [-6.0476613e-01  1.4407141e+01 -1.5130987e+01  1.1908067e-02]] [Dz loss: [ 1.2843162   0.8175329  -0.35819802  0.08249812]] [G loss: [15.815131   14.997882    0.386711    0.04305385]]\n",
            "Epoch: 20/35, [Dx loss: [-0.34108883  4.900607   -5.426485    0.01847887]] [Dz loss: [2.3175895  0.7401496  0.0574598  0.15199801]] [G loss: [ 4.2315254   4.020568   -0.06780048  0.02787585]]\n",
            "Epoch: 21/35, [Dx loss: [-0.58667326 -7.095633    6.364941    0.0144018 ]] [Dz loss: [2.2172616  0.56372654 0.2731772  0.13803582]] [G loss: [-6.0032153  -6.11637    -0.25553805  0.0368693 ]]\n",
            "Epoch: 22/35, [Dx loss: [-0.35119942  5.745469   -6.236759    0.01400905]] [Dz loss: [2.1651845  0.3799016  0.6910724  0.10942101]] [G loss: [ 8.180117    8.315292   -0.6528505   0.05176743]]\n",
            "Epoch: 23/35, [Dx loss: [-7.7153552e-01  1.9102459e+01 -2.0028656e+01  1.5465960e-02]] [Dz loss: [2.1002977  0.33644703 0.92242175 0.08414291]] [G loss: [19.602343  19.792116  -0.7685077  0.0578735]]\n",
            "Epoch: 24/35, [Dx loss: [ -0.06122876  10.961569   -11.205255     0.01824568]] [Dz loss: [ 1.1403608   0.49156833 -0.14164065  0.0790433 ]] [G loss: [11.296245   10.159927    0.4910926   0.06452234]]\n",
            "Epoch: 25/35, [Dx loss: [-1.434941   -3.2100155   1.5297632   0.02453111]] [Dz loss: [ 1.2780348   0.59573287 -0.38656634  0.10688683]] [G loss: [-0.8777439  -1.9491649   0.58164847  0.04897725]]\n",
            "Epoch: 26/35, [Dx loss: [-0.5061968  -3.984871    3.3244433   0.01542298]] [Dz loss: [2.1539788  0.60874796 0.18315424 0.13620768]] [G loss: [-2.4482236  -2.9496696  -0.15521753  0.06566637]]\n",
            "Epoch: 27/35, [Dx loss: [ -0.23728485   9.962527   -10.397726     0.01979151]] [Dz loss: [2.201404   0.5072949  0.7665169  0.09275918]] [G loss: [12.346359   12.049928   -0.607517    0.09039485]]\n",
            "Epoch: 28/35, [Dx loss: [-8.4998262e-01  1.8807266e+01 -1.9822145e+01  1.6489463e-02]] [Dz loss: [ 0.49996892  0.55963945 -0.903793    0.08441225]] [G loss: [21.505213   19.613638    1.3016856   0.05898896]]\n",
            "Epoch: 29/35, [Dx loss: [ 2.1451156e-01  1.6617537e+01 -1.6565096e+01  1.6206417e-02]] [Dz loss: [ 0.4920451   0.59013975 -0.9873339   0.08892393]] [G loss: [17.971981   16.293905    1.1634108   0.05146635]]\n",
            "Epoch: 30/35, [Dx loss: [-1.240702    7.738762   -9.304922    0.03254573]] [Dz loss: [ 1.6303746   0.6570493  -0.10905844  0.10823838]] [G loss: [9.241369   8.728837   0.06219305 0.04503396]]\n",
            "Epoch: 31/35, [Dx loss: [-0.7050883   6.748501   -7.5815535   0.01279661]] [Dz loss: [2.4510896  0.6671368  0.4701375  0.13138157]] [G loss: [ 7.976613    7.8567214  -0.43487722  0.05547689]]\n",
            "Epoch: 32/35, [Dx loss: [ -0.15785274  13.637793   -13.987857     0.01922122]] [Dz loss: [2.2669187  0.64112437 0.5988804  0.10269141]] [G loss: [15.165252   14.948942   -0.41330907  0.06296179]]\n",
            "Epoch: 33/35, [Dx loss: [ -0.69107383  19.480629   -20.412388     0.02406867]] [Dz loss: [-0.18722093  0.6567621  -1.6240025   0.07800195]] [G loss: [24.454447   20.701096    1.9131203   0.18402302]]\n",
            "Epoch: 34/35, [Dx loss: [-8.2046402e-01  2.2340412e+01 -2.3339163e+01  1.7828824e-02]] [Dz loss: [ 0.5433682   0.6694535  -1.1507251   0.10246398]] [G loss: [25.009596  22.98599    1.251176   0.0772429]]\n",
            "Epoch: 35/35, [Dx loss: [-8.2919821e-02  1.9521585e+01 -1.9792343e+01  1.8783761e-02]] [Dz loss: [ 1.7674268   0.5940002  -0.2149305   0.13883573]] [G loss: [20.772522   19.955471    0.24616432  0.05708864]]\n",
            "precision nan Signal D-3\n",
            "recall 0.0 Signal D-3\n",
            "Accuracy 0.6209051920018178 Signal D-3\n",
            "F1 nan Signal D-3\n",
            "Epoch: 1/35, [Dx loss: [-0.01660036 -3.0133252   0.566539    0.24301858]] [Dz loss: [ 1.6011645   0.4156494  -0.01562759  0.1201143 ]] [G loss: [ 1.7213476  -0.59622014  0.01338206  0.23041856]]\n",
            "Epoch: 2/35, [Dx loss: [-1.8699576  -6.1673574   3.9245777   0.03728227]] [Dz loss: [2.5188003  0.39719695 0.89034903 0.12312547]] [G loss: [-2.9588714 -3.9262702 -0.7203233  0.1687722]]\n",
            "Epoch: 3/35, [Dx loss: [ -0.34618726 -13.289121    12.401239     0.05416934]] [Dz loss: [-0.5712616   0.62779653 -3.077286    0.18782283]] [G loss: [ -4.606481   -13.051068     5.7779274    0.26666605]]\n",
            "Epoch: 4/35, [Dx loss: [ -2.8567004  -18.199064    13.993075     0.13492875]] [Dz loss: [-3.533495    0.6910951  -5.334949    0.11103579]] [G loss: [ -4.8154335  -13.256702     5.8415775    0.25996912]]\n",
            "Epoch: 5/35, [Dx loss: [ -1.5816619  -12.605351    10.719609     0.03040794]] [Dz loss: [1.9930677  0.6967559  0.28047282 0.1015839 ]] [G loss: [ -9.356116   -10.310953    -0.18353723   0.11383758]]\n",
            "Epoch: 6/35, [Dx loss: [-1.0148757   2.3535578  -4.0063353   0.06379017]] [Dz loss: [-1.7077141   1.1113391  -3.6751525   0.08560997]] [G loss: [11.946226    5.5441875   4.994664    0.14073755]]\n",
            "Epoch: 7/35, [Dx loss: [-0.9643916  3.2331073 -4.4497604  0.025226 ]] [Dz loss: [-1.8190157   1.5273557  -4.8111715   0.14648005]] [G loss: [9.839498   3.520191   5.1236115  0.11956953]]\n",
            "Epoch: 8/35, [Dx loss: [ -1.1912024  -11.820481     9.899173     0.07301039]] [Dz loss: [ 2.066064    1.4986513  -0.6294063   0.11968192]] [G loss: [ -7.9200516  -10.02576      0.6545851    0.14511223]]\n",
            "Epoch: 9/35, [Dx loss: [ -1.5465969  -10.231861     8.246828     0.04384343]] [Dz loss: [ 2.4567735   1.4576217  -0.37848985  0.13776423]] [G loss: [-6.5653143  -8.153679    0.4452608   0.11431037]]\n",
            "Epoch: 10/35, [Dx loss: [  0.83055127 -15.481379    16.106909     0.02050227]] [Dz loss: [ 1.9256909   1.38232    -0.65506124  0.11984321]] [G loss: [-15.597665   -17.245857     0.7345367    0.09136556]]\n",
            "Epoch: 11/35, [Dx loss: [ -1.5863146  -24.05192     21.988947     0.04766595]] [Dz loss: [ 1.5037038   1.3327156  -0.82981193  0.10008005]] [G loss: [-18.959208   -20.630917     0.89691293   0.0774794 ]]\n",
            "Epoch: 12/35, [Dx loss: [ -1.0493581  -12.493014    11.147739     0.02959191]] [Dz loss: [ 1.7760975   1.3315991  -0.58463794  0.10291362]] [G loss: [ -9.719136   -10.834019     0.5872998    0.05275827]]\n",
            "Epoch: 13/35, [Dx loss: [-0.26768547 -4.5003157   3.7332737   0.04993558]] [Dz loss: [ 1.9894826   1.2725012  -0.42202815  0.11390088]] [G loss: [-1.8950007  -2.8715162   0.45224175  0.05242735]]\n",
            "Epoch: 14/35, [Dx loss: [-1.3638967   8.015165   -9.635275    0.02562103]] [Dz loss: [ 1.9777215   1.2489176  -0.31123522  0.10400392]] [G loss: [11.465622   10.644179    0.31532535  0.05061172]]\n",
            "Epoch: 15/35, [Dx loss: [-0.41838074  8.085919   -8.636867    0.0132568 ]] [Dz loss: [ 1.8651749   1.1873257  -0.29668674  0.09745359]] [G loss: [9.323083   8.521344   0.29315573 0.05085835]]\n",
            "Epoch: 16/35, [Dx loss: [-0.93302566  4.4378633  -5.651168    0.02802767]] [Dz loss: [ 1.9141493   1.1254815  -0.24498963  0.1033657 ]] [G loss: [5.514634   4.7847996  0.23199499 0.04978404]]\n",
            "Epoch: 17/35, [Dx loss: [-0.7454761  -7.3848405   6.436956    0.02024074]] [Dz loss: [ 1.7955062   1.0965216  -0.22830927  0.09272937]] [G loss: [-5.9983735  -6.732418    0.25312206  0.04809227]]\n",
            "Epoch: 18/35, [Dx loss: [-0.4905394  -9.488397    8.755048    0.02428105]] [Dz loss: [ 1.8541772   1.078071   -0.1831047   0.09592109]] [G loss: [-8.181511   -8.827176    0.20291416  0.04427506]]\n",
            "Epoch: 19/35, [Dx loss: [-0.8620537  -0.8127019  -0.30301535  0.02536633]] [Dz loss: [ 2.0036962   1.0307324  -0.05763879  0.10306022]] [G loss: [2.3794518  1.8821836  0.06144274 0.04358253]]\n",
            "Epoch: 20/35, [Dx loss: [ -0.38455194  10.239782   -10.764581     0.01402477]] [Dz loss: [ 1.9407161   0.9865406  -0.00237774  0.09565536]] [G loss: [11.859409   11.389267    0.01755902  0.04525839]]\n",
            "Epoch: 21/35, [Dx loss: [ -0.8695547   19.641773   -20.802334     0.02910062]] [Dz loss: [ 1.8235995   0.98845595 -0.02949386  0.08646373]] [G loss: [21.97567    21.379498    0.04015653  0.05560166]]\n",
            "Epoch: 22/35, [Dx loss: [ -0.62822664  11.993225   -12.778167     0.01567144]] [Dz loss: [ 1.6954565   0.9693376  -0.13435659  0.08604755]] [G loss: [12.381015   11.729129    0.14804405  0.05038409]]\n",
            "Epoch: 23/35, [Dx loss: [-0.18237683 -6.3897963   6.0098953   0.01975234]] [Dz loss: [ 1.7128801   0.9419305  -0.16911419  0.09400637]] [G loss: [-7.0085135  -7.6039243   0.14787422  0.04475366]]\n",
            "Epoch: 24/35, [Dx loss: [ -1.1588087  -18.347761    16.974722     0.02142314]] [Dz loss: [ 1.7549171   0.94685614 -0.11005209  0.09181131]] [G loss: [-16.427162   -16.935228     0.12756841   0.03804962]]\n",
            "Epoch: 25/35, [Dx loss: [-5.3616440e-01 -1.4910200e+01  1.4229024e+01  1.4501242e-02]] [Dz loss: [ 1.7931025  0.9034322 -0.1152552  0.1004926]] [G loss: [-13.231655   -13.757768     0.11306234   0.04130511]]\n",
            "Epoch: 26/35, [Dx loss: [-0.1259875  -6.114122    5.7987947   0.01893389]] [Dz loss: [ 1.8184431   0.81806153 -0.0735452   0.10739271]] [G loss: [-3.5452034  -4.041139    0.07502918  0.04209065]]\n",
            "Epoch: 27/35, [Dx loss: [-1.1631101  8.209408  -9.522254   0.0149737]] [Dz loss: [ 1.7769816   0.74621993 -0.042722    0.10734836]] [G loss: [9.619396   9.023922   0.02830568 0.05671686]]\n",
            "Epoch: 28/35, [Dx loss: [-0.18434513 -0.34033096  0.04589512  0.01100909]] [Dz loss: [ 1.7683519   0.71977025 -0.00186966  0.10504514]] [G loss: [-0.6556046  -1.0594373   0.02040363  0.0383429 ]]\n",
            "Epoch: 29/35, [Dx loss: [ -0.6295986  -19.773746    18.896606     0.02475368]] [Dz loss: [1.8033931  0.69822335 0.09178597 0.1013384 ]] [G loss: [-19.200874   -19.647778    -0.10454664   0.05514491]]\n",
            "Epoch: 30/35, [Dx loss: [ -0.99326956 -17.591896    16.403164     0.01954641]] [Dz loss: [1.9112034  0.6049893  0.21629839 0.1089916 ]] [G loss: [-15.311746   -15.670936    -0.19138022   0.05505707]]\n",
            "Epoch: 31/35, [Dx loss: [-2.5970635e-01 -1.4200653e+01  1.3808563e+01  1.3238290e-02]] [Dz loss: [1.8491697  0.59028053 0.26181096 0.09970782]] [G loss: [-13.280308   -13.463806    -0.22746646   0.04109658]]\n",
            "Epoch: 32/35, [Dx loss: [-0.47185844  0.9967774  -1.7632418   0.02946061]] [Dz loss: [ 1.7314193   0.6185354  -0.01235371  0.11252373]] [G loss: [4.0796633  3.585636   0.02271565 0.04713115]]\n",
            "Epoch: 33/35, [Dx loss: [-9.9808615e-01  1.3077475e+01 -1.4198450e+01  1.2288876e-02]] [Dz loss: [ 0.8442419   0.72162485 -0.5720417   0.06946586]] [G loss: [15.391037   14.1932335   0.7059917   0.04918106]]\n",
            "Epoch: 34/35, [Dx loss: [-3.8975947e-02  9.6895866e+00 -9.8209467e+00  9.2386473e-03]] [Dz loss: [ 1.1044995   0.77598065 -0.4833575   0.08118764]] [G loss: [10.286423    9.287536    0.541825    0.04570629]]\n",
            "Epoch: 35/35, [Dx loss: [-0.58026755  2.577732   -3.4929264   0.03349271]] [Dz loss: [1.8778578  0.7312309  0.01208713 0.11345394]] [G loss: [3.2029865  2.8266978  0.00947847 0.03668102]]\n",
            "precision nan Signal D-4\n",
            "recall 0.0 Signal D-4\n",
            "Accuracy 0.6167374848261731 Signal D-4\n",
            "F1 nan Signal D-4\n",
            "Epoch: 1/35, [Dx loss: [-0.34624603 -3.0575752   0.4172298   0.22940993]] [Dz loss: [ 1.1496425  -0.36513284  0.6328811   0.08818942]] [G loss: [ 1.9564818  -0.4682319  -0.65561026  0.30803242]]\n",
            "Epoch: 2/35, [Dx loss: [-2.7615273  -5.568087    2.5310125   0.02755466]] [Dz loss: [ 5.2059855  -0.31998     4.617551    0.09084149]] [G loss: [-4.4267616  -2.5842814  -4.1572723   0.23147921]]\n",
            "Epoch: 3/35, [Dx loss: [ 0.28948092 -5.5064816   5.406875    0.03890884]] [Dz loss: [12.809054    0.21599719 10.149632    0.2443424 ]] [G loss: [-6.2759748 -5.1652937 -6.4105787  0.5299898]]\n",
            "Epoch: 4/35, [Dx loss: [-2.8444889 -9.72719    6.48149    0.0401212]] [Dz loss: [-13.496964     0.29940614 -16.033436     0.22370629]] [G loss: [19.306349   -6.455452   21.834303    0.39274976]]\n",
            "Epoch: 5/35, [Dx loss: [-0.90170485 -9.3899975   8.293137    0.01951546]] [Dz loss: [-13.979697     0.53616345 -15.49361      0.09777491]] [G loss: [14.874427   -7.8377104  19.652266    0.30598718]]\n",
            "Epoch: 6/35, [Dx loss: [-1.9077078  -5.6453056   3.510133    0.02274641]] [Dz loss: [-14.910718     1.0815201  -17.205547     0.12133095]] [G loss: [22.048523   -3.6599221  22.699297    0.30091476]]\n",
            "Epoch: 7/35, [Dx loss: [-0.59031963 -8.089639    7.393075    0.01062439]] [Dz loss: [-26.502483     1.537141   -29.788086     0.17484611]] [G loss: [28.400656  -7.4991145 32.798103   0.3101665]]\n",
            "Epoch: 8/35, [Dx loss: [-1.4805595  -7.98773     6.2534003   0.02537717]] [Dz loss: [-26.376019     1.9669144  -31.697523     0.33545914]] [G loss: [31.430986   -5.77279    34.4984      0.27053782]]\n",
            "Epoch: 9/35, [Dx loss: [-1.144469   -6.470764    5.174098    0.01521972]] [Dz loss: [-16.116682     2.1920226  -19.70965      0.14009473]] [G loss: [19.229483   -5.2489653  22.008892    0.24695536]]\n",
            "Epoch: 10/35, [Dx loss: [-1.0746312  -5.260112    4.035793    0.01496864]] [Dz loss: [-11.568092     2.3718257  -15.459132     0.15192176]] [G loss: [16.35158    -3.651565   17.242628    0.27605164]]\n",
            "Epoch: 11/35, [Dx loss: [-1.1496783  -4.0295362   2.7267475   0.01531102]] [Dz loss: [-11.319444     2.4337637  -15.80554      0.20523298]] [G loss: [15.986394   -2.954966   16.670263    0.22710966]]\n",
            "Epoch: 12/35, [Dx loss: [-1.0118684  -5.853795    4.6987553   0.01431716]] [Dz loss: [ -8.412107     2.4986885  -12.97332      0.20625223]] [G loss: [10.781831   -4.789515   13.8487625   0.17225823]]\n",
            "Epoch: 13/35, [Dx loss: [-0.89795077 -6.5177174   5.475337    0.01444295]] [Dz loss: [-3.5691755   2.4789002  -8.434487    0.23864134]] [G loss: [ 5.1293845 -4.989663   8.774544   0.1344505]]\n",
            "Epoch: 14/35, [Dx loss: [-1.2209271  -4.1565814   2.8069327   0.01287211]] [Dz loss: [-0.8252647   2.4097776  -5.0124965   0.17774543]] [G loss: [ 2.8861337  -3.220568    5.0037155   0.11029864]]\n",
            "Epoch: 15/35, [Dx loss: [-0.9141009  -6.9278874   5.872096    0.01416907]] [Dz loss: [ 1.3470353   2.2940094  -2.6095214   0.16625476]] [G loss: [-2.1701553 -6.047624   2.5001698  0.1377299]]\n",
            "Epoch: 16/35, [Dx loss: [ -0.9091356  -10.043639     9.001357     0.01331481]] [Dz loss: [ 1.8703121   2.1642656  -1.773789    0.14798363]] [G loss: [-5.9167404  -8.75059     1.7423848   0.10914648]]\n",
            "Epoch: 17/35, [Dx loss: [-1.0338418  -1.9638785   0.80394393  0.01260927]] [Dz loss: [ 1.6747528   2.1149035  -1.4378464   0.09976959]] [G loss: [ 1.9356862  -0.28562507  1.4319001   0.07894112]]\n",
            "Epoch: 18/35, [Dx loss: [-0.98240304 -3.0914671   1.9994336   0.01096307]] [Dz loss: [ 1.8283187   1.9874041  -1.047057    0.08879715]] [G loss: [-0.4399522  -2.311172    1.0597758   0.08114439]]\n",
            "Epoch: 19/35, [Dx loss: [-0.88412803 -5.77667     4.771052    0.01214898]] [Dz loss: [ 2.0521362  1.9052132 -0.7169409  0.0863864]] [G loss: [-3.1815026  -4.7202806   0.72878873  0.08099893]]\n",
            "Epoch: 20/35, [Dx loss: [-0.88966143 -6.549202    5.533659    0.01258819]] [Dz loss: [ 2.194637   1.8297738 -0.4398252  0.0804688]] [G loss: [-4.2374043  -5.474316    0.45944765  0.07774641]]\n",
            "Epoch: 21/35, [Dx loss: [-0.88017493 -4.6841607   3.6879818   0.01160036]] [Dz loss: [ 2.3504493   1.7416973  -0.2668195   0.08755711]] [G loss: [-2.851341   -3.860634    0.2742744   0.07350185]]\n",
            "Epoch: 22/35, [Dx loss: [-0.7439702  -8.8923025   8.029361    0.01189718]] [Dz loss: [ 2.3977916   1.5907159  -0.14990425  0.09569798]] [G loss: [-7.235051   -8.264663    0.13530941  0.08943015]]\n",
            "Epoch: 23/35, [Dx loss: [-8.853380e-01 -9.292965e+00  8.315186e+00  9.244060e-03]] [Dz loss: [ 2.4792707   1.4823127  -0.06407579  0.10610341]] [G loss: [-7.209003   -8.042396    0.06025257  0.07731394]]\n",
            "Epoch: 24/35, [Dx loss: [-0.9542961  -5.2083426   4.1378384   0.01162074]] [Dz loss: [ 2.665704    1.3833517  -0.00864763  0.12910002]] [G loss: [-3.0678754  -3.7688146   0.00965951  0.06912797]]\n",
            "Epoch: 25/35, [Dx loss: [-1.1953328  -1.6377133   0.30665037  0.013573  ]] [Dz loss: [2.8325748  1.2544522  0.02592907 0.15521936]] [G loss: [ 0.45389944 -0.18945907 -0.02685601  0.06702145]]\n",
            "Epoch: 26/35, [Dx loss: [-0.7384043 -4.80128    3.9334733  0.0129403]] [Dz loss: [3.1345055  1.1897355  0.05723141 0.18875384]] [G loss: [-3.5137503  -4.31768    -0.05034119  0.08542708]]\n",
            "Epoch: 27/35, [Dx loss: [-0.8966185  -5.6056337   4.5848565   0.01241587]] [Dz loss: [3.3791265  1.0494254  0.10992674 0.22197744]] [G loss: [-3.233841   -3.911833   -0.11085878  0.07888512]]\n",
            "Epoch: 28/35, [Dx loss: [-0.94176495 -2.3149297   1.2641497   0.01090151]] [Dz loss: [3.5082583  0.95514405 0.16034116 0.23927732]] [G loss: [-1.2647398  -1.8321639  -0.16401175  0.07314359]]\n",
            "Epoch: 29/35, [Dx loss: [-1.0314461  -7.288597    6.1641974   0.00929536]] [Dz loss: [3.5135956  0.8749156  0.20168258 0.24369979]] [G loss: [-5.207893   -5.6042633  -0.19960757  0.05959772]]\n",
            "Epoch: 30/35, [Dx loss: [-1.0812942   5.1152515  -6.33566     0.01391142]] [Dz loss: [3.5612009  0.82358515 0.26235256 0.2475263 ]] [G loss: [ 7.011201    6.660596   -0.26597133  0.0616577 ]]\n",
            "Epoch: 31/35, [Dx loss: [-0.91339463 -2.293449    1.2754498   0.01046045]] [Dz loss: [3.487357   0.7189849  0.32228315 0.24460891]] [G loss: [-1.5979663  -1.9034574  -0.32536596  0.06308571]]\n",
            "Epoch: 32/35, [Dx loss: [-0.74062735 -6.293894    5.456379    0.00968874]] [Dz loss: [3.350994   0.6653916  0.43070248 0.22548996]] [G loss: [-5.286393   -5.513611   -0.4372167   0.06644345]]\n",
            "Epoch: 33/35, [Dx loss: [-0.8914114  -8.701582    7.705726    0.01044444]] [Dz loss: [3.2173455  0.64213115 0.5712079  0.20040055]] [G loss: [-7.568721  -7.6567435 -0.5707831  0.0658806]]\n",
            "Epoch: 34/35, [Dx loss: [-0.9147084 -2.655447   1.6107827  0.0129956]] [Dz loss: [3.0820127  0.61232084 0.6890726  0.17806195]] [G loss: [-0.6695424  -0.68802106 -0.68596345  0.07044424]]\n",
            "Epoch: 35/35, [Dx loss: [-0.83828735 -1.4802154   0.5450718   0.00968565]] [Dz loss: [3.2123604  0.6009352  0.7082453  0.19031794]] [G loss: [-1.5576395  -1.5500041  -0.69034     0.06827043]]\n",
            "precision 0.3494810170828473 Signal A-2\n",
            "recall 0.9181818526170654 Signal A-2\n",
            "Accuracy 0.9751042529639459 Signal A-2\n",
            "F1 0.5062657199947601 Signal A-2\n",
            "Epoch: 1/35, [Dx loss: [-0.7318922  -3.2827535   0.46460217  0.20862587]] [Dz loss: [1.7278359  0.54546916 0.16968213 0.10126849]] [G loss: [ 1.4536488  -0.48952505 -0.15743941  0.21006134]]\n",
            "Epoch: 2/35, [Dx loss: [-1.0993068  -4.354048    3.0335877   0.02211537]] [Dz loss: [6.0117726  0.32115722 4.6616826  0.10289334]] [G loss: [-4.941611   -2.878848   -4.2564926   0.21937299]]\n",
            "Epoch: 3/35, [Dx loss: [-1.2612633  -0.6069402  -1.2352867   0.05809641]] [Dz loss: [ -9.380336     0.6897247  -11.271218     0.12011582]] [G loss: [27.388508   2.3038745 21.35316    0.3731471]]\n",
            "Epoch: 4/35, [Dx loss: [-1.1183136  -0.2307276  -1.1014937   0.02139072]] [Dz loss: [-50.39515      1.2898954  -52.717        0.10319512]] [G loss: [64.2613      0.39943445 60.447475    0.34143847]]\n",
            "Epoch: 5/35, [Dx loss: [-2.0842826  -5.6232247   3.2998714   0.02390701]] [Dz loss: [-21.234436     1.8654234  -24.883        0.17831305]] [G loss: [27.241755   -3.1453598  27.858934    0.25281802]]\n",
            "Epoch: 6/35, [Dx loss: [-1.5737518  -6.4309297   4.7246714   0.01325081]] [Dz loss: [-11.573808     2.1174216  -15.126806     0.14355782]] [G loss: [15.913843  -4.6942186 18.198692   0.240937 ]]\n",
            "Epoch: 7/35, [Dx loss: [-0.48919645 -2.3907876   1.7362549   0.01653361]] [Dz loss: [-37.679344     2.4283793  -42.75645      0.26487267]] [G loss: [48.13676    -0.49956    46.271523    0.23648012]]\n",
            "Epoch: 8/35, [Dx loss: [-1.3069532   6.758113   -8.269965    0.02048976]] [Dz loss: [-46.569813     2.9407446  -54.99818      0.54876244]] [G loss: [70.827705    7.851799   61.092907    0.18829957]]\n",
            "Epoch: 9/35, [Dx loss: [-0.91732997 -0.9043293  -0.14781812  0.01348172]] [Dz loss: [ -7.7966833    3.1985717  -16.702013     0.57067597]] [G loss: [19.436867   -0.33198422 17.258577    0.2510274 ]]\n",
            "Epoch: 10/35, [Dx loss: [-1.2883581  -3.0861902   1.6979011   0.00999309]] [Dz loss: [ 3.2634258  2.9687953 -3.0677965  0.3362426]] [G loss: [ 3.2098093 -1.6651361  3.0744712  0.1800474]]\n",
            "Epoch: 11/35, [Dx loss: [-0.8247286  -1.7144257   0.77509385  0.01146036]] [Dz loss: [ 2.6887324  2.7385569 -1.7397093  0.1689885]] [G loss: [ 2.5465727  -0.7204706   1.8501704   0.14168729]]\n",
            "Epoch: 12/35, [Dx loss: [-0.8658067   3.703191   -4.704972    0.01359737]] [Dz loss: [ 2.173451    2.5902743  -1.8646504   0.14478272]] [G loss: [8.138407   5.2949963  1.9694886  0.08739211]]\n",
            "Epoch: 13/35, [Dx loss: [-0.7307504  -1.2335033   0.3632862   0.01394662]] [Dz loss: [ 1.9809068   2.4694104  -1.7343264   0.12458225]] [G loss: [ 1.2604704  -1.2234814   1.7558414   0.07281103]]\n",
            "Epoch: 14/35, [Dx loss: [-0.78551316 -3.8479767   2.9693813   0.00930811]] [Dz loss: [ 2.3752477   2.3336327  -1.1820865   0.12237014]] [G loss: [-0.7911123  -2.752402    1.189584    0.07717057]]\n",
            "Epoch: 15/35, [Dx loss: [-0.6588416   1.8161767  -2.5802207   0.01052026]] [Dz loss: [ 2.7980309   2.2215314  -0.6480042   0.12245031]] [G loss: [4.471911   3.0824406  0.629126   0.07603444]]\n",
            "Epoch: 16/35, [Dx loss: [-0.76198477  1.9222124  -2.7646239   0.00804259]] [Dz loss: [ 2.9267762   2.0202203  -0.25299644  0.11595521]] [G loss: [3.0046961  2.169101   0.23943785 0.05961575]]\n",
            "Epoch: 17/35, [Dx loss: [-0.7277491  -3.3525422   2.5491614   0.00756309]] [Dz loss: [ 2.987596    1.8444722  -0.09582476  0.12389489]] [G loss: [-1.5495902  -2.1791124   0.1060157   0.05235068]]\n",
            "Epoch: 18/35, [Dx loss: [-0.7030353   4.0405917  -4.8423357   0.00987087]] [Dz loss: [3.1058114e+00 1.6465750e+00 1.1119510e-03 1.4581244e-01]] [G loss: [ 5.637465    5.123534   -0.0122303   0.05261608]]\n",
            "Epoch: 19/35, [Dx loss: [-0.69113135 -2.6623235   1.8605397   0.01106523]] [Dz loss: [3.092215   1.4796339  0.0495958  0.15629855]] [G loss: [-2.262226   -2.6978827  -0.06116562  0.04968224]]\n",
            "Epoch: 20/35, [Dx loss: [-0.64450157 -4.881652    4.1446257   0.00925237]] [Dz loss: [3.127667   1.3631127  0.09800611 0.16665478]] [G loss: [-3.2851942  -3.6849067  -0.09431571  0.04940281]]\n",
            "Epoch: 21/35, [Dx loss: [-0.74066496  1.5486327  -2.3994992   0.01102017]] [Dz loss: [3.393439   1.2610115  0.12520157 0.20072262]] [G loss: [ 2.9167838   2.6171684  -0.12836397  0.04279795]]\n",
            "Epoch: 22/35, [Dx loss: [-0.60106325 -1.575195    0.8767759   0.00973559]] [Dz loss: [3.4716897  1.0929476  0.14966953 0.22290723]] [G loss: [-1.1063856  -1.3769553  -0.15432054  0.04248901]]\n",
            "Epoch: 23/35, [Dx loss: [-7.2824180e-01 -8.5853300e+00  7.7734413e+00  8.3645135e-03]] [Dz loss: [3.3125916  1.08343    0.15926863 0.20698924]] [G loss: [-7.6404476  -7.877803   -0.15816744  0.03955229]]\n",
            "Epoch: 24/35, [Dx loss: [-0.60547817 -2.9606843   2.2659945   0.00892124]] [Dz loss: [3.498426   0.99530536 0.19537342 0.23077472]] [G loss: [-1.039861   -1.3112016  -0.19495893  0.04662995]]\n",
            "Epoch: 25/35, [Dx loss: [-0.68018645  0.6892736  -1.4582129   0.00887531]] [Dz loss: [3.6099732  0.92916745 0.22096512 0.24598405]] [G loss: [ 1.2792174   1.0600342  -0.2193573   0.04385404]]\n",
            "Epoch: 26/35, [Dx loss: [-0.7532459  -5.3126836   4.4795995   0.00798387]] [Dz loss: [3.533376   0.85982    0.25752315 0.2416033 ]] [G loss: [-4.48322    -4.6487613  -0.25484648  0.04203875]]\n",
            "Epoch: 27/35, [Dx loss: [-0.701898   -4.0383883   3.2474701   0.00890202]] [Dz loss: [3.5128322  0.7842447  0.3093142  0.24192739]] [G loss: [-2.9630797  -3.0679216  -0.31616405  0.04210056]]\n",
            "Epoch: 28/35, [Dx loss: [-0.7146827  -4.6718073   3.8711064   0.00860177]] [Dz loss: [3.4651604  0.72602844 0.3810159  0.23581164]] [G loss: [-3.9273212  -3.9562848  -0.3734576   0.04024214]]\n",
            "Epoch: 29/35, [Dx loss: [-0.75241286 -4.41804     3.579261    0.00863661]] [Dz loss: [3.4597328  0.66761637 0.48528093 0.23068349]] [G loss: [-3.7225432  -3.6066186  -0.50265104  0.03867264]]\n",
            "Epoch: 30/35, [Dx loss: [-0.7048935 -5.4034357  4.6103597  0.0088183]] [Dz loss: [3.371743   0.60680956 0.60402787 0.2160906 ]] [G loss: [-5.014225   -4.7963915  -0.62415683  0.04063233]]\n",
            "Epoch: 31/35, [Dx loss: [-0.6003286  -4.7759485   4.077879    0.00977419]] [Dz loss: [3.4635887  0.5437311  0.74884224 0.21710157]] [G loss: [-4.023311   -3.6876013  -0.7223792   0.03866697]]\n",
            "Epoch: 32/35, [Dx loss: [-0.56968224 -4.2733083   3.6176639   0.00859624]] [Dz loss: [3.4109082  0.4217043  0.91674596 0.20724574]] [G loss: [-4.389697   -3.8664992  -0.94226855  0.04190703]]\n",
            "Epoch: 33/35, [Dx loss: [-0.57912827 -5.468779    4.7991753   0.00904752]] [Dz loss: [3.4725804  0.40506965 1.102809   0.19647023]] [G loss: [-5.2254844  -4.531472   -1.1133746   0.04193619]]\n",
            "Epoch: 34/35, [Dx loss: [-0.4975903  -4.0048614   3.3915944   0.01156777]] [Dz loss: [3.6093235  0.39430436 1.2783654  0.19366536]] [G loss: [-4.6335173  -3.74993    -1.3063029   0.04227159]]\n",
            "Epoch: 35/35, [Dx loss: [-6.107068e-01 -9.834123e+00  9.137377e+00  8.603885e-03]] [Dz loss: [3.6729665  0.36063927 1.369778   0.1942549 ]] [G loss: [-9.941881   -9.002101   -1.3833423   0.04435623]]\n",
            "precision 0.5849802060532111 Signal A-3\n",
            "recall 0.8000000500500375 Signal A-3\n",
            "Accuracy 0.9826913644202466 Signal A-3\n",
            "F1 0.6757990838621204 Signal A-3\n",
            "Epoch: 1/35, [Dx loss: [ 0.9769605  -1.6718833   0.60158867  0.2047255 ]] [Dz loss: [1.8073504  0.04092824 0.37037623 0.13960458]] [G loss: [ 0.10634324 -0.6038661  -0.36625957  0.1076469 ]]\n",
            "Epoch: 2/35, [Dx loss: [-0.15353666 -3.8647003   3.5414212   0.01697431]] [Dz loss: [12.260094   -0.09437601 11.220028    0.11344431]] [G loss: [-10.487297   -3.6488738  -9.768088    0.2929665]]\n",
            "Epoch: 3/35, [Dx loss: [-1.2242491  -7.8821616   6.4659944   0.01919174]] [Dz loss: [ 2.8123562  -0.05864     0.4001487   0.24708474]] [G loss: [ 7.3887215  -6.461686   10.863459    0.29869482]]\n",
            "Epoch: 4/35, [Dx loss: [-1.1798683  -5.69737     4.352683    0.01648187]] [Dz loss: [-28.591501    -0.11527556 -31.082596     0.26063752]] [G loss: [38.485317   -4.2282324  41.156765    0.15567859]]\n",
            "Epoch: 5/35, [Dx loss: [-0.80613375 -8.142213    7.2005806   0.01354991]] [Dz loss: [-96.675644     0.26800805 -98.65053      0.17068852]] [G loss: [103.7652     -7.5332894 109.92845     0.1370031]]\n",
            "Epoch: 6/35, [Dx loss: [ -1.2026811  -11.909952    10.556444     0.01508265]] [Dz loss: [-87.30742      1.0856419  -91.16754      0.27744764]] [G loss: [ 99.21877   -10.619064  108.50424     0.1333596]]\n",
            "Epoch: 7/35, [Dx loss: [ -0.8424013  -10.133093     9.178706     0.01119874]] [Dz loss: [-150.04404       1.9055964  -155.70331       0.37536985]] [G loss: [ 1.79287140e+02 -8.74189281e+00  1.86801086e+02  1.22795716e-01]]\n",
            "Epoch: 8/35, [Dx loss: [-1.2132492 -7.4118223  6.0939817  0.0104592]] [Dz loss: [-174.79306      2.992469  -196.87857      1.9093046]] [G loss: [ 2.1410991e+02 -6.2266078e+00  2.1906351e+02  1.2730001e-01]]\n",
            "Epoch: 9/35, [Dx loss: [-0.89659214 -9.621706    8.601647    0.01234647]] [Dz loss: [-50.742012    3.4109936 -65.45332     1.1300323]] [G loss: [57.318172   -8.827898   64.78579     0.13602819]]\n",
            "Epoch: 10/35, [Dx loss: [ -1.0715929  -10.909247     9.7178135    0.01198417]] [Dz loss: [-63.63775      3.392671   -74.06748      0.70370543]] [G loss: [76.72327   -9.711457  85.11056    0.1324166]]\n",
            "Epoch: 11/35, [Dx loss: [-1.0173599  -9.2836075   8.161448    0.01047984]] [Dz loss: [-144.79657      3.778789  -176.8291       2.8253715]] [G loss: [ 1.8735362e+02 -7.8915558e+00  1.9388103e+02  1.3641402e-01]]\n",
            "Epoch: 12/35, [Dx loss: [-1.1485186  -8.812551    7.5477858   0.01162462]] [Dz loss: [-74.27637     4.191397  -94.02019     1.5552413]] [G loss: [ 99.161934    -7.581272   105.45137      0.12918295]]\n",
            "Epoch: 13/35, [Dx loss: [-1.1079811  -9.3855505   8.17005     0.01075184]] [Dz loss: [-39.341705   4.223456 -52.88029    0.931513]] [G loss: [53.189568   -8.207723   60.078373    0.13189137]]\n",
            "Epoch: 14/35, [Dx loss: [-1.0551375 -9.887063   8.722757   0.0109167]] [Dz loss: [-41.47637     4.1753707 -60.65312     1.5001392]] [G loss: [65.02446    -8.761553   72.4868      0.12992111]]\n",
            "Epoch: 15/35, [Dx loss: [-1.0163462e+00 -9.7830868e+00  8.6695614e+00  9.7179972e-03]] [Dz loss: [-65.9558      4.1791534 -98.6831      2.8548138]] [G loss: [104.98205     -8.688524   112.37996      0.12906119]]\n",
            "Epoch: 16/35, [Dx loss: [-0.96247023 -8.802579    7.7324286   0.01076807]] [Dz loss: [-45.486946    4.402368  -84.34448     3.4455159]] [G loss: [80.331184   -7.612458   86.646515    0.12971224]]\n",
            "Epoch: 17/35, [Dx loss: [-0.9573302  -8.693094    7.628717    0.01070482]] [Dz loss: [  0.950688   4.456256 -26.298512   2.279295]] [G loss: [21.36091   -7.685421  27.764645   0.1281688]]\n",
            "Epoch: 18/35, [Dx loss: [-0.88839513 -8.677023    7.691223    0.00974052]] [Dz loss: [  8.767905    4.1141157 -12.599232    1.7253021]] [G loss: [10.351393   -7.6935167  16.76641     0.12784992]]\n",
            "Epoch: 19/35, [Dx loss: [-0.8409235  -8.736673    7.78818     0.01075701]] [Dz loss: [-52.561676    3.8962474 -76.263824    1.9805908]] [G loss: [78.97304    -7.825892   85.52203     0.12769017]]\n",
            "Epoch: 20/35, [Dx loss: [-0.8240733  -8.7178955   7.778511    0.01153116]] [Dz loss: [-43.3686      4.25021   -78.76677     3.1147964]] [G loss: [74.78098    -7.663151   81.1216      0.13225394]]\n",
            "Epoch: 21/35, [Dx loss: [-0.7654536  -9.235019    8.35256     0.01170057]] [Dz loss: [ -7.7278304   4.212674  -23.611225    1.1670719]] [G loss: [16.87266    -8.318273   23.91501     0.12759222]]\n",
            "Epoch: 22/35, [Dx loss: [-0.84114885 -8.036826    7.072811    0.01228663]] [Dz loss: [ -7.5596323   3.9938831 -18.769676    0.7216159]] [G loss: [13.409331  -6.873557  18.971542   0.1311346]]\n",
            "Epoch: 23/35, [Dx loss: [-1.1040707  -6.0163755   4.7734485   0.01388569]] [Dz loss: [ -2.823904   3.763332 -13.976886   0.738965]] [G loss: [11.136784   -4.858043   14.762267    0.12325603]]\n",
            "Epoch: 24/35, [Dx loss: [-0.8232582  -9.700151    8.732928    0.01439645]] [Dz loss: [ 4.0552483  3.5629354 -7.733828   0.8226141]] [G loss: [ 0.57516706 -8.853432    8.112735    0.13158637]]\n",
            "Epoch: 25/35, [Dx loss: [ -0.887665   -11.297939    10.269094     0.01411795]] [Dz loss: [ 7.8561807  3.3578353 -3.8708382  0.8369185]] [G loss: [ -4.9775214 -10.121692    4.0846562   0.1059514]]\n",
            "Epoch: 26/35, [Dx loss: [-0.99251384 -8.852797    7.729346    0.01309361]] [Dz loss: [ 9.093253    3.187757   -1.7270396   0.76325357]] [G loss: [-4.584627   -7.55965     1.8483955   0.11266275]]\n",
            "Epoch: 27/35, [Dx loss: [-0.8041151  -9.230337    8.299997    0.01262248]] [Dz loss: [ 6.9437127  2.9919565 -1.1242105  0.5075967]] [G loss: [-6.0340543  -8.389111    1.1868454   0.11682111]]\n",
            "Epoch: 28/35, [Dx loss: [-0.96488696 -9.89987     8.810411    0.01245706]] [Dz loss: [ 5.913625   2.8176198 -0.8705705  0.3966574]] [G loss: [-6.855155   -8.708097    0.9004446   0.09524979]]\n",
            "Epoch: 29/35, [Dx loss: [-0.8575347  -8.713185    7.728607    0.01270428]] [Dz loss: [ 5.3536325   2.7220454  -0.8800043   0.35115916]] [G loss: [-5.844657  -7.664216   1.0456126  0.0773946]]\n",
            "Epoch: 30/35, [Dx loss: [ -0.76639766 -12.128745    11.227932     0.01344151]] [Dz loss: [ 4.2390976  2.6152787 -1.2710181  0.2894836]] [G loss: [ -9.502279   -11.587198     1.39624      0.06886787]]\n",
            "Epoch: 31/35, [Dx loss: [-8.1566161e-01 -1.4300654e+01  1.3369240e+01  1.1575403e-02]] [Dz loss: [ 3.4290779   2.547291   -1.671764    0.25535503]] [G loss: [-10.916012   -13.392182     1.8586742    0.06174953]]\n",
            "Epoch: 32/35, [Dx loss: [-9.20890212e-01 -1.33498812e+01  1.22983608e+01  1.30627155e-02]] [Dz loss: [ 2.534455   2.4932559 -2.2406268  0.2281826]] [G loss: [ -9.149319   -12.118242     2.3978393    0.05710828]]\n",
            "Epoch: 33/35, [Dx loss: [ -0.7481329 -10.06227     9.184717    0.0129419]] [Dz loss: [ 1.620682    2.408426   -2.840527    0.20527832]] [G loss: [-5.3411546 -8.888887   2.9895215  0.0558211]]\n",
            "Epoch: 34/35, [Dx loss: [-0.934893   -9.6630125   8.627849    0.01002718]] [Dz loss: [ 1.2905157   2.4089036  -2.9929225   0.18745343]] [G loss: [-5.121995   -8.676421    3.040229    0.05141974]]\n",
            "Epoch: 35/35, [Dx loss: [ -0.89312    -11.337836    10.308145     0.01365706]] [Dz loss: [ 1.383586   2.4264255 -2.693557   0.1650718]] [G loss: [ -7.0685186 -10.394436    2.7276874   0.0598229]]\n",
            "precision 0.2173913162819074 Signal A-4\n",
            "recall 1.0 Signal A-4\n",
            "Accuracy 0.950984015485965 Signal A-4\n",
            "F1 0.3571428732477779 Signal A-4\n",
            "Epoch: 1/35, [Dx loss: [ 0.16120346 -2.5046718   0.41778487  0.22480898]] [Dz loss: [ 1.5373347  -0.05636322  0.6527604   0.09409375]] [G loss: [ 1.182769   -0.42768657 -0.6086294   0.22190848]]\n",
            "Epoch: 2/35, [Dx loss: [-1.4069064  -4.698559    3.130454    0.01611984]] [Dz loss: [14.085233   -0.21509941 12.985945    0.13143861]] [G loss: [-10.298977    -3.1276948  -10.394032     0.32227495]]\n",
            "Epoch: 3/35, [Dx loss: [-0.9191225  -1.333529    0.12904891  0.02853576]] [Dz loss: [-11.802935    -0.11313881 -13.714437     0.20246384]] [G loss: [33.047565    0.43526086 28.713268    0.38990384]]\n",
            "Epoch: 4/35, [Dx loss: [-1.111862   -4.560427    3.2283924   0.02201731]] [Dz loss: [-56.316395    0.3213952 -57.37101     0.0733225]] [G loss: [68.92995    -3.8619015  69.81536     0.29764813]]\n",
            "Epoch: 5/35, [Dx loss: [-1.6866267  -9.418792    7.560504    0.01716625]] [Dz loss: [-89.350845    1.0917834 -91.92366     0.1481005]] [G loss: [103.00268     -7.5532064  107.73828      0.28176016]]\n",
            "Epoch: 6/35, [Dx loss: [-1.1611795  -7.782611    6.4582186   0.01632137]] [Dz loss: [-77.94939      1.9129841  -83.54402      0.36816457]] [G loss: [91.269745   -6.000247   94.49424     0.27757475]]\n",
            "Epoch: 7/35, [Dx loss: [-1.0775862  -2.4057877   1.131393    0.01968086]] [Dz loss: [-15.053881    2.2879207 -25.000248    0.7658448]] [G loss: [28.23548   -1.5867779 26.223677   0.359858 ]]\n",
            "Epoch: 8/35, [Dx loss: [ -2.427342   -10.431636     7.6955285    0.03087639]] [Dz loss: [ 2.7864442  2.2395577 -5.3959455  0.5942833]] [G loss: [-0.17760605 -7.6578918   5.371745    0.21085404]]\n",
            "Epoch: 9/35, [Dx loss: [-1.172013   -8.566845    7.2642455   0.01305862]] [Dz loss: [ 3.2820644   2.0863705  -1.9586427   0.31543365]] [G loss: [-2.39742   -7.2761965  2.0725393  0.2806237]]\n",
            "Epoch: 10/35, [Dx loss: [-0.8131312  -3.7225468   2.7738833   0.01355321]] [Dz loss: [ 3.2564273   1.9717596  -0.7005136   0.19851817]] [G loss: [ 0.46371835 -2.3177793   0.7405965   0.20409012]]\n",
            "Epoch: 11/35, [Dx loss: [-0.8881818  -7.5757165   6.578208    0.01093272]] [Dz loss: [ 3.173101    1.8402894  -0.25105777  0.15838698]] [G loss: [-5.460914   -6.9513535   0.19934332  0.12910962]]\n",
            "Epoch: 12/35, [Dx loss: [-0.8422526  -5.436517    4.492566    0.01016987]] [Dz loss: [3.1128106  1.6823822  0.00798235 0.14224458]] [G loss: [-2.8272717  -3.9397967   0.01532974  0.10971951]]\n",
            "Epoch: 13/35, [Dx loss: [-0.9109068 -4.6094046  3.5893817  0.0109116]] [Dz loss: [3.0054326  1.5650723  0.1323357  0.13080241]] [G loss: [-3.347984   -4.079587   -0.06543355  0.07970364]]\n",
            "Epoch: 14/35, [Dx loss: [-0.8907668  -7.689489    6.702446    0.00962752]] [Dz loss: [2.92428    1.4273777  0.24573192 0.12511703]] [G loss: [-5.8640594  -6.3762455  -0.2756555   0.07878417]]\n",
            "Epoch: 15/35, [Dx loss: [-1.0067874  -1.8813967   0.7689477   0.01056613]] [Dz loss: [2.8119042  1.3860724  0.22658308 0.11992487]] [G loss: [-0.1580505  -0.70891213 -0.21163581  0.07624975]]\n",
            "Epoch: 16/35, [Dx loss: [-0.94044656 -6.9841843   5.9374948   0.0106243 ]] [Dz loss: [2.7396724  1.3093822  0.13549666 0.12947938]] [G loss: [-5.7614455  -6.349352   -0.10563061  0.06935373]]\n",
            "Epoch: 17/35, [Dx loss: [-0.8702482  -8.229766    7.260961    0.00985564]] [Dz loss: [ 2.470802    1.2187401  -0.03006791  0.12821297]] [G loss: [-6.0789638  -6.805275    0.07471543  0.06515952]]\n",
            "Epoch: 18/35, [Dx loss: [-1.0131471  -1.9651903   0.84988785  0.01021554]] [Dz loss: [ 2.386935    1.1549524  -0.09075651  0.13227388]] [G loss: [-0.2696445  -0.9368733   0.06372888  0.06034999]]\n",
            "Epoch: 19/35, [Dx loss: [-0.92496574 -7.205516    6.179512    0.01010387]] [Dz loss: [ 2.3011985   1.0648036  -0.07706021  0.13134551]] [G loss: [-5.9378533  -6.658213    0.08410653  0.06362537]]\n",
            "Epoch: 20/35, [Dx loss: [-9.311514e-01 -1.095022e+01  9.938395e+00  8.067360e-03]] [Dz loss: [ 2.2419496   1.0041578  -0.02695193  0.1264744 ]] [G loss: [-9.147493   -9.713173    0.0324202   0.05332602]]\n",
            "Epoch: 21/35, [Dx loss: [-0.94371796 -2.079185    1.035077    0.01003903]] [Dz loss: [2.237674   0.9722756  0.06976347 0.11956345]] [G loss: [-0.03165983 -0.52244735 -0.06615587  0.05569435]]\n",
            "Epoch: 22/35, [Dx loss: [-0.8828106  -4.590596    3.6187356   0.00890496]] [Dz loss: [2.401549   0.9395031  0.18788211 0.12741636]] [G loss: [-3.7275455  -4.130579   -0.17547882  0.05785124]]\n",
            "Epoch: 23/35, [Dx loss: [-9.221878e-01 -1.094279e+01  9.921282e+00  9.932197e-03]] [Dz loss: [2.5695019  0.8972489  0.22686455 0.14453882]] [G loss: [-9.62987    -9.950031   -0.22774369  0.05479039]]\n",
            "Epoch: 24/35, [Dx loss: [-0.9054662  -5.6321135   4.640643    0.00860055]] [Dz loss: [2.6234217  0.86468965 0.23435068 0.1524382 ]] [G loss: [-3.3683856  -3.6937199  -0.21120413  0.05365382]]\n",
            "Epoch: 25/35, [Dx loss: [-0.91924447 -1.5661299   0.5533898   0.00934955]] [Dz loss: [2.6238656  0.8167407  0.28643018 0.15206948]] [G loss: [-0.91949856 -1.1868293  -0.27582443  0.05431552]]\n",
            "Epoch: 26/35, [Dx loss: [-9.1103441e-01 -1.0192869e+01  9.1864262e+00  9.5410384e-03]] [Dz loss: [2.710603   0.79179347 0.3150932  0.16037162]] [G loss: [-9.4098     -9.674465   -0.3061592   0.05708257]]\n",
            "Epoch: 27/35, [Dx loss: [-8.4372693e-01 -1.0476343e+01  9.5357609e+00  9.6855611e-03]] [Dz loss: [2.771052   0.7449142  0.3050957  0.17210421]] [G loss: [-8.653662   -8.87617    -0.30338934  0.05258971]]\n",
            "Epoch: 28/35, [Dx loss: [-0.93823403 -0.32389814 -0.7233322   0.01089964]] [Dz loss: [2.9084744  0.720572   0.35012895 0.18377736]] [G loss: [ 0.98405707  0.8024619  -0.33805853  0.05196537]]\n",
            "Epoch: 29/35, [Dx loss: [-0.81418276 -6.147727    5.241497    0.00920475]] [Dz loss: [3.0365474  0.65928996 0.40356892 0.19736888]] [G loss: [-5.527888   -5.693297   -0.3839556   0.05493645]]\n",
            "Epoch: 30/35, [Dx loss: [-8.6842060e-01 -8.8702583e+00  7.9146791e+00  8.7157255e-03]] [Dz loss: [3.107882   0.6706022  0.43244004 0.200484  ]] [G loss: [-7.7110605  -7.817942   -0.42603958  0.05329207]]\n",
            "Epoch: 31/35, [Dx loss: [-0.9287488  -3.7334473   2.707536    0.00971622]] [Dz loss: [3.3400116  0.6256441  0.4804534  0.22339137]] [G loss: [-2.117295   -2.191986   -0.46047217  0.05351634]]\n",
            "Epoch: 32/35, [Dx loss: [-0.9100466  -5.148761    4.140765    0.00979488]] [Dz loss: [3.4408402  0.6063679  0.52249444 0.23119779]] [G loss: [-4.795334   -4.799873   -0.52573425  0.05302733]]\n",
            "Epoch: 33/35, [Dx loss: [-8.4550303e-01 -1.4406077e+01  1.3460838e+01  9.9737411e-03]] [Dz loss: [3.5156848  0.55685174 0.5449327  0.24139006]] [G loss: [-13.724186  -13.742978   -0.5275792   0.0546372]]\n",
            "Epoch: 34/35, [Dx loss: [-0.7018596  -9.893797    9.090021    0.01019152]] [Dz loss: [3.402565   0.5672464  0.54870075 0.22866175]] [G loss: [-8.305897  -8.3219385 -0.5359995  0.0552042]]\n",
            "Epoch: 35/35, [Dx loss: [-0.87508506 -2.1511676   1.1467772   0.01293056]] [Dz loss: [3.4095874  0.5479937  0.54417264 0.23174214]] [G loss: [-1.2604719  -1.234636   -0.5572653   0.05314293]]\n",
            "precision 0.0 Signal G-1\n",
            "recall 0.0 Signal G-1\n",
            "Accuracy 0.9525271446753792 Signal G-1\n",
            "F1 nan Signal G-1\n",
            "Epoch: 1/35, [Dx loss: [-3.3052719  -7.337473    0.26101935  0.37711814]] [Dz loss: [4.28897    0.2410917  3.1111507  0.09367285]] [G loss: [ 5.4925966  -0.19239095 -2.780985    0.84659725]]\n",
            "Epoch: 2/35, [Dx loss: [ -6.2101836 -11.893916    4.5764413   0.1107292]] [Dz loss: [3.3077924  0.10541395 1.326743   0.18756346]] [G loss: [ 1.6760184  -4.593167    5.7671585   0.05020264]]\n",
            "Epoch: 3/35, [Dx loss: [-1.4892091e-01 -9.9813299e+00  9.7931547e+00  3.9254832e-03]] [Dz loss: [-36.188118     0.19468665 -37.586624     0.12038124]] [G loss: [ 3.6666096e+01 -9.7830791e+00  4.6448536e+01  6.3365907e-05]]\n",
            "Epoch: 4/35, [Dx loss: [-3.2264505e-02 -1.0134389e+01  1.0071403e+01  3.0722357e-03]] [Dz loss: [ 0.53066933  0.24708353 -2.6173732   0.29009598]] [G loss: [-5.9081521e+00 -1.0099605e+01  4.1914520e+00  1.0496499e-09]]\n"
          ]
        }
      ],
      "source": [
        "F1=[]\n",
        "Accuracy=[]\n",
        "Recall=[]\n",
        "Precision=[]\n",
        "for name in SMAP: \n",
        "    train = load_signal(name+append_train)\n",
        "    test = load_signal(name+append_test)\n",
        "    #orion.fit(train_data)\n",
        "    known_anomalies = load_anomalies(name)\n",
        "    pipeline = 'tadgan'\n",
        "    anomalies = analyze(pipeline, train, test)\n",
        "    Accuracy1=contextual_accuracy(known_anomalies, anomalies, test)\n",
        "    F11=contextual_f1_score(known_anomalies, anomalies, test)\n",
        "    Accuracy.append(Accuracy1)\n",
        "    F1.append(F11)\n",
        "    Recall1=contextual_recall(known_anomalies, anomalies, test)\n",
        "    Precision1=contextual_precision(known_anomalies, anomalies, test)\n",
        "    Recall.append(Recall1)\n",
        "    Precision.append(Precision1)\n",
        "    print('precision', Precision1, 'Signal', name)\n",
        "    print('recall', Recall1, 'Signal', name)\n",
        "    print('Accuracy', Accuracy1, 'Signal', name)\n",
        "    print('F1', F11, 'Signal', name)\n",
        "\n",
        "F1_final=mean(F1)\n",
        "Accuracy_final=mean(Accuracy)\n",
        "Precision_final=mean(Precision)\n",
        "Recall_final=mean(Recall)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m8sRKdRJ1LG"
      },
      "outputs": [],
      "source": [
        "from orion import Orion\n",
        "from orion.analysis import analyze\n",
        "\n",
        "\n",
        "orion = Orion(pipeline='arima')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RI4d3-NFKMco",
        "outputId": "d472cf49-3a1e-4034-a61d-b0478745fd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.0 Signal P-1\n",
            "recall 0.0 Signal P-1\n",
            "Accuracy 0.9040451334448277 Signal P-1\n",
            "F1 nan Signal P-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 1.0 Signal S-1\n",
            "recall 0.3131991762781531 Signal S-1\n",
            "Accuracy 0.9581173260572988 Signal S-1\n",
            "F1 0.4770017860745495 Signal S-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision nan Signal E-1\n",
            "recall 0.0 Signal E-1\n",
            "Accuracy 0.9405754442052152 Signal E-1\n",
            "F1 nan Signal E-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision nan Signal E-2\n",
            "recall 0.0 Signal E-2\n",
            "Accuracy 0.8362442801199981 Signal E-2\n",
            "F1 nan Signal E-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "ERROR:mlblocks.mlpipeline:Exception caught producing MLBlock statsmodels.tsa.arima_model.Arima#1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlblocks/mlpipeline.py\", line 565, in _produce_block\n",
            "    block_outputs = block.produce(**produce_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlblocks/mlblock.py\", line 322, in produce\n",
            "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlprimitives/adapters/statsmodels.py\", line 49, in predict\n",
            "    arima_fit = arima.fit(disp=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\", line 938, in fit\n",
            "    start_ar_lags)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\", line 554, in _fit_start_params\n",
            "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\", line 533, in _fit_start_params_hr\n",
            "    raise ValueError(\"The computed initial AR coefficients are not \"\n",
            "ValueError: The computed initial AR coefficients are not stationary\n",
            "You should induce stationarity, choose a different model order, or you can\n",
            "pass your own start_params.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5b6b302b37ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#orion.fit(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mknown_anomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0manomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mAccuracy1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontextual_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mF11\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontextual_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/orion/analysis.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(pipeline, train, test, hyperparams)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_events_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/orion/analysis.py\u001b[0m in \u001b[0;36m_run_pipeline\u001b[0;34m(pipeline, train, test)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting the pipeline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finding events\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlpipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, output_, start_, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_block_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_produce_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;31m# We already captured the output from this block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlpipeline.py\u001b[0m in \u001b[0;36m_produce_block\u001b[0;34m(self, block, block_name, context, output_variables, outputs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mproduce_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mblock_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mproduce_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0moutputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlblock.py\u001b[0m in \u001b[0;36mproduce\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mproduce_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduce_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mproduce_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mproduce_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlprimitives/adapters/statsmodels.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0marima\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marima_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0marima_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0marima_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marima_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, start_ar_lags, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate starting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             start_params = self._fit_start_params((k_ar, k_ma, k), method,\n\u001b[0;32m--> 938\u001b[0;31m                                                   start_ar_lags)\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# transform initial parameters to ensure invertibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params\u001b[0;34m(self, order, method, start_ar_lags)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m#start_params = [.1]*(k_ar+k_ma+k_exog) # different one for k?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ar_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invtransparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params_hr\u001b[0;34m(self, order, start_ar_lags)\u001b[0m\n\u001b[1;32m    531\u001b[0m         if p and not np.all(np.abs(np.roots(np.r_[1, -start_params[k:k + p]]\n\u001b[1;32m    532\u001b[0m                                             )) < 1):\n\u001b[0;32m--> 533\u001b[0;31m             raise ValueError(\"The computed initial AR coefficients are not \"\n\u001b[0m\u001b[1;32m    534\u001b[0m                              \u001b[0;34m\"stationary\\nYou should induce stationarity, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                              \u001b[0;34m\"choose a different model order, or you can\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The computed initial AR coefficients are not stationary\nYou should induce stationarity, choose a different model order, or you can\npass your own start_params."
          ]
        }
      ],
      "source": [
        "F1=[]\n",
        "Accuracy=[]\n",
        "Recall=[]\n",
        "Precision=[]\n",
        "pipeline = 'arima'\n",
        "for name in SMAP: \n",
        "    train = load_signal(name+append_train)\n",
        "    test = load_signal(name+append_test)\n",
        "    #orion.fit(train_data)\n",
        "    known_anomalies = load_anomalies(name)\n",
        "    anomalies = analyze(pipeline, train, test)\n",
        "    Accuracy1=contextual_accuracy(known_anomalies, anomalies, test)\n",
        "    F11=contextual_f1_score(known_anomalies, anomalies, test)\n",
        "    Accuracy.append(Accuracy1)\n",
        "    F1.append(F11)\n",
        "    Recall1=contextual_recall(known_anomalies, anomalies, test)\n",
        "    Precision1=contextual_precision(known_anomalies, anomalies, test)\n",
        "    Recall.append(Recall1)\n",
        "    Precision.append(Precision1)\n",
        "    print('precision', Precision1, 'Signal', name)\n",
        "    print('recall', Recall1, 'Signal', name)\n",
        "    print('Accuracy', Accuracy1, 'Signal', name)\n",
        "    print('F1', F11, 'Signal', name)\n",
        "\n",
        "F1_final_arima=mean(F1)\n",
        "Accuracy_final_arima=mean(Accuracy)\n",
        "Precision_final_arima=mean(Precision)\n",
        "Recall_final_arima=mean(Recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj4llyIILjpX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6HX7183vLsEj",
        "outputId": "be45297e-1b72-4ba2-cefb-d03514d3c7cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bdd1f9d9-c432-4c29-a916-44255e63341b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1222819200</td>\n",
              "      <td>-0.366359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1222840800</td>\n",
              "      <td>-0.394108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1222862400</td>\n",
              "      <td>0.403625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1222884000</td>\n",
              "      <td>-0.362759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1222905600</td>\n",
              "      <td>-0.370746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdd1f9d9-c432-4c29-a916-44255e63341b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdd1f9d9-c432-4c29-a916-44255e63341b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdd1f9d9-c432-4c29-a916-44255e63341b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    timestamp     value\n",
              "0  1222819200 -0.366359\n",
              "1  1222840800 -0.394108\n",
              "2  1222862400  0.403625\n",
              "3  1222884000 -0.362759\n",
              "4  1222905600 -0.370746"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJT5B1J0MCWt",
        "outputId": "13b59ac5-7272-4409-ed0b-57f792d980dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/35, [Dx loss: [-2.9638696  -6.397364    0.49629322  0.29372007]] [Dz loss: [ 3.5509484  -0.18653958  2.8906138   0.08468749]] [G loss: [ 3.60247   -0.3927072 -2.7070603  0.6702238]]\n",
            "Epoch: 2/35, [Dx loss: [-5.9714656  -8.868856    1.7032197   0.11941723]] [Dz loss: [-1.128403   -0.08384136 -2.2211533   0.11765907]] [G loss: [14.2838125 -1.4932142 10.489235   0.5287792]]\n",
            "Epoch: 3/35, [Dx loss: [ -6.337001   -10.633345     3.2220616    0.10742812]] [Dz loss: [-13.655597     0.04534527 -15.139908     0.143896  ]] [G loss: [21.345234   -3.4108863  20.07707     0.46790472]]\n",
            "Epoch: 4/35, [Dx loss: [ -5.5937285  -11.141763     4.6503706    0.08976635]] [Dz loss: [ 5.0560127e+01 -1.2970110e-02  4.8805614e+01  1.7674755e-01]] [G loss: [-40.804718   -4.509242  -40.738216    0.4442739]]\n",
            "Epoch: 5/35, [Dx loss: [ -5.6947756  -10.264794     3.6473975    0.09226196]] [Dz loss: [-47.118767     0.05103675 -48.717567     0.15477656]] [G loss: [83.08174    -3.6249306  82.351326    0.43553448]]\n",
            "Epoch: 6/35, [Dx loss: [ -6.127639   -12.370411     5.2528086    0.09899613]] [Dz loss: [-1.7311484e+02  6.0196877e-02 -1.7693156e+02  3.7565476e-01]] [G loss: [195.76544    -5.265214  196.7337      0.4296958]]\n",
            "Epoch: 7/35, [Dx loss: [ -5.86266    -11.448224     4.6765623    0.09090045]] [Dz loss: [32.9867      0.59699726 19.179424    1.3210279 ]] [G loss: [ 6.298232   -4.4937882   6.4638147   0.43282035]]\n",
            "Epoch: 8/35, [Dx loss: [ -5.722529   -10.2021       3.6236362    0.08559339]] [Dz loss: [-59.471626     1.5260259  -64.27774      0.32800987]] [G loss: [94.38499    -3.5807292  93.62417     0.43415636]]\n",
            "Epoch: 9/35, [Dx loss: [-5.654607   -9.61664     3.1046882   0.08573463]] [Dz loss: [-43.827797     2.0778062  -48.29182      0.23862168]] [G loss: [53.655117  -3.0726018 52.38408    0.4343638]]\n",
            "Epoch: 10/35, [Dx loss: [-5.568932  -9.183516   2.7873425  0.0827241]] [Dz loss: [-13.559321     2.164433   -17.459003     0.17352459]] [G loss: [21.212223  -2.7393355 19.67557    0.4275988]]\n",
            "Epoch: 11/35, [Dx loss: [-5.471435   -8.855821    2.5745792   0.08098062]] [Dz loss: [5.391936   2.0658195  1.5554749  0.17706418]] [G loss: [ 2.9608622 -2.5657027  1.3259308  0.4200634]]\n",
            "Epoch: 12/35, [Dx loss: [-5.3571696  -8.580383    2.4322      0.07910144]] [Dz loss: [-1.6353077   1.889177   -5.1419754   0.16174906]] [G loss: [11.241734  -2.4007535  9.487071   0.4155416]]\n",
            "Epoch: 13/35, [Dx loss: [-5.282249   -8.7230215   2.678762    0.07620116]] [Dz loss: [-14.297995     1.7663081  -17.89756      0.18332586]] [G loss: [21.037388   -2.746152   19.436228    0.43473136]]\n",
            "Epoch: 14/35, [Dx loss: [-5.232881   -8.908442    2.9321294   0.07434314]] [Dz loss: [-2.5012574   1.8051573  -6.497317    0.21909027]] [G loss: [ 8.858892   -2.9370625   7.374922    0.44210333]]\n",
            "Epoch: 15/35, [Dx loss: [-5.1908712  -9.198342    3.2702813   0.07371901]] [Dz loss: [ 3.345028    1.7889822  -0.5117394   0.20677844]] [G loss: [ 2.5583596  -3.258282    1.5543048   0.42623368]]\n",
            "Epoch: 16/35, [Dx loss: [-4.976823   -7.821313    2.1583564   0.06861334]] [Dz loss: [ -9.30697      1.9002892  -13.573749     0.23664904]] [G loss: [18.065264  -2.0653872 15.907663   0.4222988]]\n",
            "Epoch: 17/35, [Dx loss: [-4.8225594  -8.235006    2.7287252   0.06837219]] [Dz loss: [-12.385295     2.0750031  -16.678848     0.22185476]] [G loss: [19.05457  -2.642415 17.446066  0.425092]]\n",
            "Epoch: 18/35, [Dx loss: [-4.6701016  -7.0953054   1.7751834   0.06500211]] [Dz loss: [5.2048616  2.0343103  1.3776174  0.17929341]] [G loss: [ 1.422471   -1.877605   -0.8916291   0.41917053]]\n",
            "Epoch: 19/35, [Dx loss: [-4.6025457  -7.75764     2.5332963   0.06217984]] [Dz loss: [6.531868   1.9287951  2.7728243  0.18302485]] [G loss: [-0.48389187 -2.4274256  -2.231135    0.41746688]]\n",
            "Epoch: 20/35, [Dx loss: [-4.4573736  -7.719387    2.6552515   0.06067622]] [Dz loss: [ 0.06752102  1.7845306  -3.2017388   0.14847288]] [G loss: [ 5.939744  -2.7259803  4.4756923  0.4190032]]\n",
            "Epoch: 21/35, [Dx loss: [-4.3451023 -7.077981   2.1693866  0.0563493]] [Dz loss: [-5.9614162  1.7614956 -9.735638   0.2012727]] [G loss: [12.734249   -2.0283294  10.389984    0.43725953]]\n",
            "Epoch: 22/35, [Dx loss: [-4.231994   -6.9662476   2.1790383   0.05552157]] [Dz loss: [ 2.4808707  1.770767  -1.005146   0.171525 ]] [G loss: [ 3.3738277 -2.2250679  1.3291355  0.426976 ]]\n",
            "Epoch: 23/35, [Dx loss: [-3.9372356  -5.8823123   1.4607787   0.04842968]] [Dz loss: [4.049928   1.8028129  0.7813157  0.14658007]] [G loss: [ 2.4973793  -1.4226526  -0.2663857   0.41864175]]\n",
            "Epoch: 24/35, [Dx loss: [-3.2851937  -6.935074    3.2968063   0.03530726]] [Dz loss: [-4.381021    1.751304   -7.685224    0.15528992]] [G loss: [10.633781  -2.9327207  9.283219   0.4283284]]\n",
            "Epoch: 25/35, [Dx loss: [-2.9686224  -6.431337    3.1361334   0.03265816]] [Dz loss: [ -8.924825     1.902186   -13.377794     0.25507858]] [G loss: [15.462676   -3.4179153  14.658366    0.42222244]]\n",
            "Epoch: 26/35, [Dx loss: [ -3.0563874  -10.490544     7.092241     0.03419163]] [Dz loss: [-1.8061445   1.9246317  -4.772867    0.10420909]] [G loss: [ 2.4756808  -7.1955376   5.468755    0.42024633]]\n",
            "Epoch: 27/35, [Dx loss: [-3.108365   -8.784189    5.313885    0.03619387]] [Dz loss: [-4.080144    1.8382372  -7.071251    0.11528707]] [G loss: [ 7.6276054 -4.945793   8.362628   0.421077 ]]\n",
            "Epoch: 28/35, [Dx loss: [-3.2542605  -6.535753    2.8613136   0.04201801]] [Dz loss: [-3.1038995   1.8621438  -6.4396334   0.14735892]] [G loss: [ 8.359387  -2.8415174  6.9608827  0.4240022]]\n",
            "Epoch: 29/35, [Dx loss: [-3.160943   -6.3898873   2.8762765   0.03526687]] [Dz loss: [-4.279771    1.8175962  -7.1823907   0.10850219]] [G loss: [ 8.832614   -2.8654814   7.469217    0.42288783]]\n",
            "Epoch: 30/35, [Dx loss: [-2.97584    -6.487362    3.1958323   0.03156901]] [Dz loss: [-2.897742    1.8063084  -6.0377903   0.13337396]] [G loss: [ 7.234371   -3.232358    6.2124143   0.42543143]]\n",
            "Epoch: 31/35, [Dx loss: [-3.0277133  -7.1997576   3.8327622   0.03392824]] [Dz loss: [-0.91862535  1.8467343  -4.2888527   0.15234926]] [G loss: [ 4.7428203 -3.8886144  4.39156    0.4239874]]\n",
            "Epoch: 32/35, [Dx loss: [-2.785446   -7.340991    4.247284    0.03082626]] [Dz loss: [ 1.6434586   1.8105698  -1.9017456   0.17346343]] [G loss: [ 2.2079685  -4.1711226   2.0541258   0.43249655]]\n",
            "Epoch: 33/35, [Dx loss: [-2.4606988  -6.725442    4.003168    0.02615749]] [Dz loss: [-0.7991618  1.8414103 -4.0076275  0.1367055]] [G loss: [ 4.9818854  -3.7865891   4.586151    0.41823232]]\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuQd54CCL6Ig"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH9KNdL8LWx4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3_KEk5RsBL",
        "outputId": "8bc4a4d6-9a53-4a66-f0b9-cfbc411c4b80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.41083531612236746"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H27L98cwLXWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "f2b855ca-2057-4b6e-ab04-b424b069863f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.0 Signal P-1\n",
            "recall 0.0 Signal P-1\n",
            "Accuracy 0.9040451334448277 Signal P-1\n",
            "F1 nan Signal P-1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3c10add9dfde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#orion.fit(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mknown_anomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0manomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mAccuracy1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontextual_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mF11\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontextual_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/orion/analysis.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(pipeline, train, test, hyperparams)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_events_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/orion/analysis.py\u001b[0m in \u001b[0;36m_run_pipeline\u001b[0;34m(pipeline, train, test)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finding events\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s events found\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlpipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_, start_, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_produce_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;31m# We already captured the output from this block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlpipeline.py\u001b[0m in \u001b[0;36m_produce_block\u001b[0;34m(self, block, block_name, context, output_variables, outputs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mproduce_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mblock_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mproduce_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0moutputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlblocks/mlblock.py\u001b[0m in \u001b[0;36mproduce\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mproduce_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mproduce_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlprimitives/custom/timeseries_preprocessing.py\u001b[0m in \u001b[0;36mtime_segments_aggregate\u001b[0;34m(X, interval, time_column, method)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstart_ts\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_ts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mend_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_ts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_ts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_ts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         aggregated = [\n\u001b[1;32m    195\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1537\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, obj, axis, kind)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[1;32m   3160\u001b[0m         \"\"\"\n\u001b[1;32m   3161\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3162\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3163\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mnew_blklocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mnew_blknos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from orion import Orion\n",
        "from orion.analysis import analyze\n",
        "from orion.data import load_anomalies\n",
        "from orion.data import load_signal\n",
        "import logging\n",
        "import warnings\n",
        "import statistics\n",
        "from orion.evaluation import contextual_accuracy, contextual_f1_score,contextual_recall,contextual_precision\n",
        "from orion.analysis import analyze\n",
        "pipeline = 'lstm_AE'\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "logging.getLogger().setLevel(level=logging.ERROR)\n",
        "warnings.simplefilter(\"ignore\")\n",
        "orion = Orion(pipeline='lstm_dynamic_threshold')\n",
        "F1=[]\n",
        "Accuracy=[]\n",
        "Recall=[]\n",
        "Precision=[]\n",
        "pipeline = 'arima'\n",
        "for name in SMAP: \n",
        "    train = load_signal(name+append_train)\n",
        "    test = load_signal(name+append_test)\n",
        "    #orion.fit(train_data)\n",
        "    known_anomalies = load_anomalies(name)\n",
        "    anomalies = analyze(pipeline, train, test)\n",
        "    Accuracy1=contextual_accuracy(known_anomalies, anomalies, test)\n",
        "    F11=contextual_f1_score(known_anomalies, anomalies, test)\n",
        "    Accuracy.append(Accuracy1)\n",
        "    F1.append(F11)\n",
        "    Recall1=contextual_recall(known_anomalies, anomalies, test)\n",
        "    Precision1=contextual_precision(known_anomalies, anomalies, test)\n",
        "    Recall.append(Recall1)\n",
        "    Precision.append(Precision1)\n",
        "    print('precision', Precision1, 'Signal', name)\n",
        "    print('recall', Recall1, 'Signal', name)\n",
        "    print('Accuracy', Accuracy1, 'Signal', name)\n",
        "    print('F1', F11, 'Signal', name)\n",
        "\n",
        "F1_final_arima=mean(F1)\n",
        "Accuracy_final_arima=mean(Accuracy)\n",
        "Precision_final_arima=mean(Precision)\n",
        "Recall_final_arima=mean(Recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ig49pfLLOqx"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TADGAN,ARIMA,LSTM_AE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}