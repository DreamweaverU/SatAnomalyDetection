{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MCD_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+crRj22k3hcMK+d5Yz4d8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DreamweaverU/SatAnomalyDetection/blob/main/MCD_VAE_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0CrQoilFKlaS"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, batch_size,sequence_length,n_features):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size_1 = 64  # number of encoder cells (from paper)\n",
        "    self.hidden_size_2 = 32  # number of decoder cells (from paper)\n",
        "    self.stacked_layers = 1  # number of (stacked) LSTM layers for each stage\n",
        "    self.dropout_probability = 0.5  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "    self.seq_len, self.n_features = sequence_length, n_features\n",
        "    self.embedding_dim, self.hidden_dim = batch_size,  batch_size\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=n_features,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=self.hidden_dim,\n",
        "      hidden_size=batch_size,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "  def forward(self, x):\n",
        "   # pdb.set_trace()\n",
        "    #x = x.reshape((self.embedding_dim, self.seq_len,self.n_features))\n",
        "\n",
        "    hidden = self.init_hidden1(self.hidden_size_1)\n",
        "\n",
        "\n",
        "    x, (hidenlstm1, a) = self.rnn1(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    x, (hidden_n, _) = self.rnn2(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return   x[:,-1,:]\n",
        "\n",
        "  def init_hidden1(self, batch_size):\n",
        "      hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "      cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "      return hidden_state, cell_state\n",
        "\n",
        "  def init_hidden2(self, batch_size):\n",
        "      hidden_state = Variable(torch.zeros(1, batch_size, self.hidden_size_2))\n",
        "      cell_state = Variable(torch.zeros(1, batch_size, self.hidden_size_2))\n",
        "      return hidden_state, cell_state\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,  input_dim,sequence_length, n_features):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.seq_len, self.input_dim = sequence_length, input_dim\n",
        "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=input_dim,\n",
        "      num_layers=1,\n",
        "        batch_first=True\n",
        "    )\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "        batch_first=True\n",
        "    )\n",
        "    self.output_layer = nn.Linear(self.hidden_dim, 1)\n",
        "  def forward(self, x):\n",
        "    #x = x.repeat(self.seq_len, self.n_features)\n",
        "\n",
        "    #x = x.reshape((self.input_dim, self.seq_len, self.n_features))\n",
        "    x = x.reshape(-1, 1, self.input_dim).repeat(1, self.seq_len, 1)\n",
        "\n",
        "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
        "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
        "    #x = x.reshape((self.seq_len, self.hidden_dim))\n",
        "\n",
        "    x = x[:, -1, :]  # take the last decoder cell's outputs\n",
        "\n",
        "    return self.output_layer(x)\n",
        "\n",
        "class RecurrentAutoencoder(nn.Module):\n",
        "  def __init__(self,embedding_dim , seq_len, n_features):\n",
        "    super(RecurrentAutoencoder, self).__init__()\n",
        "    #pdb.set_trace()\n",
        "    self.encoder = Encoder(embedding_dim,seq_len, n_features).to(device)\n",
        "    self.decoder = Decoder(embedding_dim,  seq_len,n_features).to(device)\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    x = self.encoder(x)\n",
        "    #pdb.set_trace()\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Zn9gqUqyLv9r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, X_train, X_val,y_val, n_epochs):\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "  criterion = torch.nn.MSELoss().to(device)\n",
        "  history = dict(train=[], val=[])\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 10000.0\n",
        "\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "     model = model.train()\n",
        "     train_losses = []\n",
        "\n",
        "     trun_X=len(X_train)%batch_size\n",
        "     len_X_train=len(X_train)-trun_X\n",
        "     trun_X_eval = len(X_val) % batch_size\n",
        "     len_X_eval = len(X_val) - trun_X_eval\n",
        "\n",
        "\n",
        "     for b in range(0, len_X_train, batch_size):\n",
        "        features = X_train[b:b + batch_size, :, :]\n",
        "        target = y_train[b:b + batch_size]\n",
        "     \n",
        "        X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "        y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        X_batch = X_batch.reshape((batch_size,sequence_length, n_features))\n",
        "        #print(X_batch.shape)\n",
        "        output1 = model(X_batch)\n",
        "        loss = criterion(output1.view(-1), y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "     val_losses = []\n",
        "     model = model.eval()\n",
        "\n",
        "\n",
        "     with torch.no_grad():\n",
        "        for bb in range(0,  len_X_eval, batch_size):\n",
        "                features = X_val[bb:bb + batch_size, :, :]\n",
        "                target = y_val[bb:bb + batch_size]\n",
        "\n",
        "\n",
        "                X_vall = torch.tensor(features, dtype=torch.float32)\n",
        "                y_vall = torch.tensor(target, dtype=torch.float32)\n",
        "              #  pdb.set_trace()\n",
        "                seq_true = torch.tensor(y_vall).to(device)\n",
        "                seq_pred = model(X_vall)\n",
        "                loss = criterion(seq_pred.view(-1), seq_true)\n",
        "                val_losses.append(loss.item())\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model.eval(), history\n",
        "\n"
      ],
      "metadata": {
        "id": "jjfXYieSKw3f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UTg3WEVBLDa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataset,y_val):\n",
        "  predictions, losses = [], []\n",
        "  criterion = torch.nn.MSELoss().to(device)\n",
        "  with torch.no_grad():\n",
        "    model = model.eval()\n",
        "    trun_dataset = len(dataset) % batch_size\n",
        "    len_X_train = len(dataset) -trun_dataset\n",
        "    for bb in range(0, len_X_train, 64):\n",
        "          features = dataset[bb:bb + batch_size, :, :]\n",
        "          target = y_val[bb:bb + batch_size]\n",
        "          X_test = torch.tensor(features, dtype=torch.float32)\n",
        "          y_test = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "          seq_true = torch.tensor(X_test).to(device)\n",
        "\n",
        "          seq_pred = model(seq_true)\n",
        "\n",
        "\n",
        "          loss = criterion(seq_pred.squeeze(-1), y_test)\n",
        "\n",
        "          predictions.append(seq_pred.cpu().numpy().flatten())\n",
        "\n",
        "          losses.append(loss.item())\n",
        "         \n",
        "    return predictions, losses"
      ],
      "metadata": {
        "id": "Sf359DAdK8DP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_df(data, start=0):\n",
        "#\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))    \n"
      ],
      "metadata": {
        "id": "jIuMvYfqN3Gq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv' #labels\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')     \n",
        "os.makedirs('csv', exist_ok=True)  \n"
      ],
      "metadata": {
        "id": "-PwwjAkpM_6U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cJC7XGNnNiTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['index','date', 'name', 'hour_of_day', 'value']\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "SMAP=['P-1']\n",
        "\n",
        "avg=[]\n",
        "train_signals=SMAP\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "for name in SMAP:\n",
        "\n",
        "        label_row=df_label[df_label.chan_id==name]\n",
        "\n",
        "        labels= label_row['anomaly_sequences'][label_row['anomaly_sequences'].index]\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "\n",
        "\n",
        "        labels= eval(labels[im])\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            anom=labels[i]\n",
        "            start=anom[0]\n",
        "            end=anom[1]\n",
        "\n",
        "            index = np.array(range(start, end))\n",
        "\n",
        "            timestamp = index * 86400 + 1022819200\n",
        "\n",
        "            anomalies=pd.DataFrame({'timestamp': timestamp.astype(int), 'value': 1, 'index':index})\n",
        "            appended_data.append(anomalies)\n",
        "\n",
        "        label_data = pd.concat(appended_data)\n",
        "\n",
        "        label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data ['name'] = name\n",
        "        label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index', 'date', 'name', 'hour_of_day']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "        plot_length = 1000000\n",
        "        plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index', 'hour_of_day', 'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)\n",
        "\n",
        "\n",
        "       "
      ],
      "metadata": {
        "id": "LJEQZOdyMroG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = scaled_array.shape[-1]\n",
        "sequence_length = 10\n",
        "output_length = 1\n",
        "batch_size = 64\n",
        "n_epochs = 10\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "g7FVIkZrMbED"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentAutoencoder( batch_size,sequence_length, n_features)\n",
        "model = model.to(device)\n",
        "\n",
        "model, history = train_model(model, X_train, X_val,y_val, n_epochs)\n",
        "\n",
        "_, losses = predict(model, X_test,y_test)\n",
        "\n",
        "sns.distplot(losses, bins=50, kde=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7qjec72sLFRx",
        "outputId": "edda1522-cf69-4ceb-b0a4-15e49864e036"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss 0.04209147474135865 val loss 0.04321235604584217\n",
            "0\n",
            "64\n",
            "128\n",
            "192\n",
            "256\n",
            "320\n",
            "384\n",
            "448\n",
            "512\n",
            "576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "640\n",
            "704\n",
            "768\n",
            "832\n",
            "896\n",
            "960\n",
            "1024\n",
            "1088\n",
            "1152\n",
            "1216\n",
            "1280\n",
            "1344\n",
            "1408\n",
            "1472\n",
            "1536\n",
            "1600\n",
            "1664\n",
            "1728\n",
            "1792\n",
            "1856\n",
            "1920\n",
            "1984\n",
            "2048\n",
            "2112\n",
            "2176\n",
            "2240\n",
            "2304\n",
            "2368\n",
            "2432\n",
            "2496\n",
            "2560\n",
            "2624\n",
            "2688\n",
            "2752\n",
            "2816\n",
            "2880\n",
            "2944\n",
            "3008\n",
            "3072\n",
            "3136\n",
            "3200\n",
            "3264\n",
            "3328\n",
            "3392\n",
            "3456\n",
            "3520\n",
            "3584\n",
            "3648\n",
            "3712\n",
            "3776\n",
            "3840\n",
            "3904\n",
            "3968\n",
            "4032\n",
            "4096\n",
            "4160\n",
            "4224\n",
            "4288\n",
            "4352\n",
            "4416\n",
            "4480\n",
            "4544\n",
            "4608\n",
            "4672\n",
            "4736\n",
            "4800\n",
            "4864\n",
            "4928\n",
            "4992\n",
            "5056\n",
            "5120\n",
            "5184\n",
            "5248\n",
            "5312\n",
            "5376\n",
            "5440\n",
            "5504\n",
            "5568\n",
            "5632\n",
            "5696\n",
            "5760\n",
            "5824\n",
            "5888\n",
            "5952\n",
            "6016\n",
            "6080\n",
            "6144\n",
            "6208\n",
            "6272\n",
            "6336\n",
            "6400\n",
            "6464\n",
            "6528\n",
            "6592\n",
            "6656\n",
            "6720\n",
            "6784\n",
            "6848\n",
            "6912\n",
            "6976\n",
            "7040\n",
            "7104\n",
            "7168\n",
            "7232\n",
            "7296\n",
            "7360\n",
            "7424\n",
            "7488\n",
            "7552\n",
            "7616\n",
            "7680\n",
            "7744\n",
            "7808\n",
            "7872\n",
            "7936\n",
            "8000\n",
            "8064\n",
            "8128\n",
            "8192\n",
            "8256\n",
            "8320\n",
            "8384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8852649dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}