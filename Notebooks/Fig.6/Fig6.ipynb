{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fig6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBgkOs08ft5GakODs8vYqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DreamweaverU/SatAnomalyDetection/blob/main/Benchmarks/Fig6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ctEk96ECubxr",
        "outputId": "0e021bed-9c88-4d51-fed3-196bb1942bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      P-1\n",
            "1      S-1\n",
            "2      E-1\n",
            "3      E-2\n",
            "4      E-3\n",
            "5      E-4\n",
            "6      E-5\n",
            "7      E-6\n",
            "8      E-7\n",
            "9      E-8\n",
            "10     E-9\n",
            "11    E-10\n",
            "12    E-11\n",
            "13    E-12\n",
            "14    E-13\n",
            "15     A-1\n",
            "16     D-1\n",
            "17     P-2\n",
            "18     P-3\n",
            "19     D-2\n",
            "20     D-3\n",
            "21     D-4\n",
            "22     A-2\n",
            "23     A-3\n",
            "24     A-4\n",
            "25     G-1\n",
            "26     G-2\n",
            "27     D-5\n",
            "28     D-6\n",
            "29     D-7\n",
            "30     F-1\n",
            "31     P-4\n",
            "32     G-3\n",
            "33     T-1\n",
            "34     T-2\n",
            "35     D-8\n",
            "36     D-9\n",
            "37     F-2\n",
            "38     G-4\n",
            "39     T-3\n",
            "40    D-11\n",
            "41    D-12\n",
            "42     B-1\n",
            "43     G-6\n",
            "44     G-7\n",
            "45     P-7\n",
            "46     R-1\n",
            "47     A-5\n",
            "48     A-6\n",
            "49     A-7\n",
            "50    D-13\n",
            "51     P-2\n",
            "52     A-8\n",
            "53     A-9\n",
            "54     F-3\n",
            "Name: chan_id, dtype: object\n",
            "      index                date name  hour_of_day     value\n",
            "0         0 2002-05-31 04:26:40  P-1            4 -0.523155\n",
            "1         1 2002-06-01 04:26:40  P-1            4 -0.688857\n",
            "2         2 2002-06-02 04:26:40  P-1            4 -0.554993\n",
            "3         3 2002-06-03 04:26:40  P-1            4 -0.531114\n",
            "4         4 2002-06-04 04:26:40  P-1            4 -0.589001\n",
            "...     ...                 ...  ...          ...       ...\n",
            "2867   2867 2010-04-06 04:26:40  P-1            4 -0.691751\n",
            "2868   2868 2010-04-07 04:26:40  P-1            4 -0.704052\n",
            "2869   2869 2010-04-08 04:26:40  P-1            4 -0.725760\n",
            "2870   2870 2010-04-09 04:26:40  P-1            4 -0.689580\n",
            "2871   2871 2010-04-10 04:26:40  P-1            4 -0.709841\n",
            "\n",
            "[2872 rows x 5 columns]\n",
            "Number of trainable parameters 229409\n",
            "epoch 10 loss:  0.009478866122663021\n",
            "epoch 20 loss:  0.009337038733065128\n",
            "epoch 30 loss:  0.007160022389143705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:386: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 332, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7012360211889347\n",
            "> <ipython-input-2-55397523733a>(468)<module>()\n",
            "-> realanomaly = label_data['index']\n",
            "(Pdb) c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 343, in set_continue\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.8719609040928528 Signal P-1 N_max 2\n",
            "recall 0.9641988651715753 Signal P-1 N_max 2\n",
            "Accuracy 0.8452030606238964 Signal P-1 N_max 2\n",
            "F1 0.9157631359466221 Signal P-1 N_max 2\n",
            "rho 5867 Signal P-1 N_max 2\n",
            "precision 0.9323152107513745 Signal P-1 N_max 3\n",
            "recall 0.9643624415518767 Signal P-1 N_max 3\n",
            "Accuracy 0.9013537374926427 Signal P-1 N_max 3\n",
            "F1 0.948068082991676 Signal P-1 N_max 3\n",
            "rho 6821 Signal P-1 N_max 3\n",
            "precision 0.9604153940134392 Signal P-1 N_max 4\n",
            "recall 0.9643032384690874 Signal P-1 N_max 4\n",
            "Accuracy 0.9273690406121248 Signal P-1 N_max 4\n",
            "F1 0.9623553896064149 Signal P-1 N_max 4\n",
            "rho 7263 Signal P-1 N_max 4\n",
            "precision 0.9756872327428222 Signal P-1 N_max 5\n",
            "recall 0.9640270400772574 Signal P-1 N_max 5\n",
            "Accuracy 0.9412595644496763 Signal P-1 N_max 5\n",
            "F1 0.969822089987249 Signal P-1 N_max 5\n",
            "rho 7499 Signal P-1 N_max 5\n",
            "precision 0.9844838118509468 Signal P-1 N_max 6\n",
            "recall 0.9638755980861244 Signal P-1 N_max 6\n",
            "Accuracy 0.9492642731018246 Signal P-1 N_max 6\n",
            "F1 0.9740707162284679 Signal P-1 N_max 6\n",
            "rho 7635 Signal P-1 N_max 6\n",
            "precision 0.9907147220525351 Signal P-1 N_max 7\n",
            "recall 0.9637508913715237 Signal P-1 N_max 7\n",
            "Accuracy 0.9549146556798117 Signal P-1 N_max 7\n",
            "F1 0.9770468100487981 Signal P-1 N_max 7\n",
            "rho 7731 Signal P-1 N_max 7\n",
            "precision 0.998045204642639 Signal P-1 N_max 9\n",
            "recall 0.9636663914120561 Signal P-1 N_max 9\n",
            "Accuracy 0.9616244849911713 Signal P-1 N_max 9\n",
            "F1 0.9805545552754771 Signal P-1 N_max 9\n",
            "rho 7845 Signal P-1 N_max 9\n",
            "precision 0.9995113011606598 Signal P-1 N_max 10\n",
            "recall 0.96371775238544 Signal P-1 N_max 10\n",
            "Accuracy 0.9630370806356681 Signal P-1 N_max 10\n",
            "F1 0.981288233177402 Signal P-1 N_max 10\n",
            "rho 7869 Signal P-1 N_max 10\n",
            "precision 0.9998778252901649 Signal P-1 N_max 11\n",
            "recall 0.9637305699481865 Signal P-1 N_max 11\n",
            "Accuracy 0.9633902295467922 Signal P-1 N_max 11\n",
            "F1 0.9814714876776397 Signal P-1 N_max 11\n",
            "rho 7875 Signal P-1 N_max 11\n",
            "precision 1.0 Signal P-1 N_max 12\n",
            "recall 0.9637348404568468 Signal P-1 N_max 12\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 12\n",
            "F1 0.9815325578606546 Signal P-1 N_max 12\n",
            "rho 7877 Signal P-1 N_max 12\n",
            "precision 1.0 Signal P-1 N_max 13\n",
            "recall 0.9637348404568468 Signal P-1 N_max 13\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 13\n",
            "F1 0.9815325578606546 Signal P-1 N_max 13\n",
            "rho 7877 Signal P-1 N_max 13\n",
            "precision 1.0 Signal P-1 N_max 14\n",
            "recall 0.9637348404568468 Signal P-1 N_max 14\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 14\n",
            "F1 0.9815325578606546 Signal P-1 N_max 14\n",
            "rho 7877 Signal P-1 N_max 14\n",
            "precision 1.0 Signal P-1 N_max 15\n",
            "recall 0.9637348404568468 Signal P-1 N_max 15\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 15\n",
            "F1 0.9815325578606546 Signal P-1 N_max 15\n",
            "rho 7877 Signal P-1 N_max 15\n",
            "precision 1.0 Signal P-1 N_max 16\n",
            "recall 0.9637348404568468 Signal P-1 N_max 16\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 16\n",
            "F1 0.9815325578606546 Signal P-1 N_max 16\n",
            "rho 7877 Signal P-1 N_max 16\n",
            "precision 1.0 Signal P-1 N_max 17\n",
            "recall 0.9637348404568468 Signal P-1 N_max 17\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 17\n",
            "F1 0.9815325578606546 Signal P-1 N_max 17\n",
            "rho 7877 Signal P-1 N_max 17\n",
            "precision 1.0 Signal P-1 N_max 18\n",
            "recall 0.9637348404568468 Signal P-1 N_max 18\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 18\n",
            "F1 0.9815325578606546 Signal P-1 N_max 18\n",
            "rho 7877 Signal P-1 N_max 18\n",
            "precision 1.0 Signal P-1 N_max 19\n",
            "recall 0.9637348404568468 Signal P-1 N_max 19\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 19\n",
            "F1 0.9815325578606546 Signal P-1 N_max 19\n",
            "rho 7877 Signal P-1 N_max 19\n",
            "precision 1.0 Signal P-1 N_max 20\n",
            "recall 0.9637348404568468 Signal P-1 N_max 20\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 20\n",
            "F1 0.9815325578606546 Signal P-1 N_max 20\n",
            "rho 7877 Signal P-1 N_max 20\n",
            "precision 1.0 Signal P-1 N_max 21\n",
            "recall 0.9637348404568468 Signal P-1 N_max 21\n",
            "Accuracy 0.9635079458505003 Signal P-1 N_max 21\n",
            "F1 0.9815325578606546 Signal P-1 N_max 21\n",
            "rho 7877 Signal P-1 N_max 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      index                date name  hour_of_day     value\n",
            "0         0 2002-05-31 04:26:40  S-1            4 -0.366359\n",
            "1         1 2002-06-01 04:26:40  S-1            4 -0.394108\n",
            "2         2 2002-06-02 04:26:40  S-1            4  0.403625\n",
            "3         3 2002-06-03 04:26:40  S-1            4 -0.362759\n",
            "4         4 2002-06-04 04:26:40  S-1            4 -0.370746\n",
            "...     ...                 ...  ...          ...       ...\n",
            "2813   2813 2010-02-11 04:26:40  S-1            4 -0.365308\n",
            "2814   2814 2010-02-12 04:26:40  S-1            4  1.000000\n",
            "2815   2815 2010-02-13 04:26:40  S-1            4 -0.341357\n",
            "2816   2816 2010-02-14 04:26:40  S-1            4 -0.392546\n",
            "2817   2817 2010-02-15 04:26:40  S-1            4  1.000000\n",
            "\n",
            "[2818 rows x 5 columns]\n",
            "Number of trainable parameters 229409\n",
            "epoch 10 loss:  0.048991069197654724\n",
            "epoch 20 loss:  0.04166669771075249\n",
            "epoch 30 loss:  0.04769526794552803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:468: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.3270045075809316\n",
            "> <ipython-input-2-55397523733a>(466)<module>()\n",
            "-> pdb.set_trace()\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "import statistics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "def build_df(data, start=0):\n",
        "#    pdb.set_trace()\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
        "class BayesianLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, output_length, batch_size):\n",
        "        super(BayesianLSTM, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size  # user-defined\n",
        "\n",
        "        self.hidden_size_1 = 128  # number of encoder cells (from paper)\n",
        "        self.hidden_size_2 = 32  # number of decoder cells (from paper)\n",
        "        self.stacked_layers = 2  # number of (stacked) LSTM layers for each stage\n",
        "        self.dropout_probability = 0.5  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(n_features,\n",
        "                             self.hidden_size_1,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
        "                             self.hidden_size_2,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_size_2, output_length)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        hidden = self.init_hidden1(batch_size)\n",
        "        output, _ = self.lstm1(x, hidden)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        state = self.init_hidden2(batch_size)\n",
        "        output, state = self.lstm2(output, state)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        output = output[:, -1, :]  # take the last decoder cell's outputs\n",
        "        y_pred = self.fc(output)\n",
        "        return y_pred\n",
        "\n",
        "    def init_hidden1(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def loss(self, pred, truth):\n",
        "        return self.loss_fn(pred, truth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n",
        "\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index','date', 'name', 'hour_of_day', 'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "print(SMAP)\n",
        "\n",
        "avg=[]\n",
        "train_signals=SMAP\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "rho=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "\n",
        "for name in SMAP:\n",
        "\n",
        "        label_row = df_label[df_label.chan_id == name]\n",
        "\n",
        "        labels = label_row['anomaly_sequences'][label_row['anomaly_sequences'].index]\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "        labels = eval(labels[im])\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            anom = labels[i]\n",
        "            start = anom[0]\n",
        "            end = anom[1]\n",
        "\n",
        "            index = np.array(range(start, end))\n",
        "\n",
        "            timestamp = index * 86400 + 1022819200\n",
        "\n",
        "            anomalies = pd.DataFrame({'timestamp': timestamp.astype(int), 'value': 1, 'index': index})\n",
        "            appended_data.append(anomalies)\n",
        "\n",
        "        label_data = pd.concat(appended_data)\n",
        "\n",
        "        label_data['date'] = pd.to_datetime(label_data['timestamp'], unit='s')\n",
        "        label_data['month'] = label_data['date'].dt.month.astype(int)\n",
        "        label_data['name'] = name\n",
        "        label_data['day_of_week'] = label_data['date'].dt.dayofweek.astype(int)\n",
        "        label_data['hour_of_day'] = label_data['date'].dt.hour.astype(int)\n",
        "        label_data = label_data[selected_columns]\n",
        "        # label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "        signal = name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index', 'date', 'name', 'hour_of_day']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        print(resample_df)\n",
        "\n",
        "        plot_length = 1000000\n",
        "        plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index', 'hour_of_day', 'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "\n",
        "        n_features = scaled_array.shape[-1]\n",
        "        sequence_length = 10\n",
        "        output_length = 1\n",
        "\n",
        "        batch_size = 128\n",
        "        n_epochs = 30\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        bayesian_lstm = BayesianLSTM(n_features=n_features,\n",
        "                                     output_length=output_length,\n",
        "                                     batch_size=batch_size)\n",
        "\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)\n",
        "        bayesian_lstm.train()\n",
        "        num_trainable=sum(dict((p.data_ptr(), p.numel()) for p in  bayesian_lstm.parameters()).values())\n",
        "        print('Number of trainable parameters', num_trainable)\n",
        "\n",
        "        for e in range(1, n_epochs + 1):\n",
        "            for b in range(0, len(X_train), batch_size):\n",
        "                features = X_train[b:b + batch_size, :, :]\n",
        "                target = y_train[b:b + batch_size]\n",
        "\n",
        "                X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "                y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "                output = bayesian_lstm(X_batch)\n",
        "                loss = criterion(output.view(-1), y_batch)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print('epoch', e, 'loss: ', loss.item())\n",
        "                offset = sequence_length\n",
        "\n",
        "        training_df = pd.DataFrame()\n",
        "        training_df['date'] = resample_df['date'].iloc[offset:n_train + offset:1]\n",
        "        training_df['index'] = resample_df['index'].iloc[offset:n_train + offset:1]\n",
        "        training_predictions = bayesian_lstm.predict(X_train)\n",
        "\n",
        "        training_df['value'] = inverse_transform(training_predictions)\n",
        "        training_df['source'] = 'Training Prediction'\n",
        "\n",
        "        training_truth_df['date'] = training_df['date']\n",
        "        training_truth_df['index'] = training_df['index']\n",
        "        training_truth_df['value'] = resample_df['value'].iloc[\n",
        "                                     offset:n_train + offset:1]\n",
        "        training_truth_df['source'] = 'True Values'\n",
        "\n",
        "        testing_df = pd.DataFrame()\n",
        "        testing_df['date'] = resample_df_test['date'].iloc[offset:n_test + offset:1]\n",
        "        testing_df['index'] = resample_df_test['index'].iloc[offset:n_test + offset:1]\n",
        "\n",
        "        testing_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "        testing_df['value'] = inverse_transform(testing_predictions)\n",
        "        testing_df['source'] = 'Test Prediction'\n",
        "\n",
        "        testing_truth_df = pd.DataFrame()\n",
        "        testing_truth_df['date'] = testing_df['date']\n",
        "        testing_truth_df['index'] = testing_df['index']\n",
        "\n",
        "        testing_truth_df['value'] = resample_df_test['value'].iloc[offset:n_test + offset:1]\n",
        "        testing_truth_df['source'] = 'True Values'\n",
        "\n",
        "        evaluation = pd.concat([training_df,\n",
        "                                testing_df,\n",
        "                                training_truth_df,\n",
        "                                testing_truth_df\n",
        "                                ], axis=0)\n",
        "\n",
        "        #fig = px.line(evaluation,\n",
        "         #             x=\"index\",\n",
        "          #            y=\"value\",\n",
        "           #           color=\"source\")\n",
        "        #fig.show()\n",
        "\n",
        "        n_experiments = 2\n",
        "        test_uncertainty_df = pd.DataFrame()\n",
        "        test_uncertainty_df['date'] = testing_df['date']\n",
        "        test_uncertainty_df['index'] = testing_df['index']\n",
        "\n",
        "        for i in range(n_experiments):\n",
        "            experiment_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "            test_uncertainty_df['value_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
        "\n",
        "        log_energy_consumption_df = test_uncertainty_df.filter(like='value', axis=1)\n",
        "        test_uncertainty_df['value_mean'] = log_energy_consumption_df.mean(axis=1)\n",
        "        test_uncertainty_df['value_std'] = log_energy_consumption_df.std(axis=1)\n",
        "\n",
        "        test_uncertainty1 = test_uncertainty_df['value_mean']\n",
        "\n",
        "        #########################Adaptive Smoothing\n",
        "\n",
        "        #   pdb.set_trace()\n",
        "        Threshold = 10\n",
        "        gamma = 0.1\n",
        "        betta = 0.1\n",
        "        test_uncertainty2 = []\n",
        "        ###########\n",
        "        for jj in range(len(test_uncertainty1) - 2):\n",
        "            test_uncertaintyy = (1 / (1 + gamma + betta)) * (\n",
        "                    test_uncertainty1.iloc[jj] + gamma * test_uncertainty1.iloc[jj + 1] + betta *\n",
        "                    test_uncertainty1.iloc[jj + 2])\n",
        "            test_uncertainty2.append(test_uncertaintyy)\n",
        "        test_uncertainty2 = pd.DataFrame(test_uncertainty2)\n",
        "\n",
        "        test_uncertainty2.columns = [\"value_mean\"]\n",
        "\n",
        "        test_uncertainty_df[\"value_mean\"] = test_uncertainty2[\"value_mean\"]\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "        test_uncertainty_df = test_uncertainty_df[['index', 'date', 'value_mean', 'value_std']]\n",
        "        test_uncertainty_df['lower_bound'] = test_uncertainty_df['value_mean'] - 15 * test_uncertainty_df['value_std']\n",
        "        test_uncertainty_df['upper_bound'] = test_uncertainty_df['value_mean'] + 15 * test_uncertainty_df['value_std']\n",
        "        import plotly.graph_objects as go\n",
        "\n",
        "        test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
        "        # test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
        "        # truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_truth_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        '''\n",
        "\n",
        "        upper_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "            y=test_uncertainty_plot_df['upper_bound'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='99% Upper Confidence Bound'\n",
        "        )\n",
        "        lower_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "            y=test_uncertainty_plot_df['lower_bound'],\n",
        "            mode='lines',\n",
        "            fill='tonexty',\n",
        "            name='99% Lower Confidence Bound',\n",
        "            fillcolor='rgba(255, 211, 0, 0.1)',\n",
        "        )\n",
        "        real_trace = go.Scatter(\n",
        "            x=truth_uncertainty_plot_df['index'],\n",
        "            y=truth_uncertainty_plot_df['value'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='Real Values'\n",
        "        )\n",
        "\n",
        "        labels = go.Scatter(\n",
        "            x=label_data['index'],\n",
        "            y=label_data['value'],\n",
        "            mode='lines',\n",
        "            fill='tonexty',\n",
        "            name='labels'\n",
        "        )\n",
        "        data = [upper_trace, lower_trace, real_trace]\n",
        "\n",
        "        fig = go.Figure(data=data)\n",
        "        fig.update_layout(title='Uncertainty MCDropout Test Data',\n",
        "                          xaxis_title='index',\n",
        "                          yaxis_title='value',\n",
        "                          legend_font_size=14,\n",
        "                          )\n",
        "        fig.show()\n",
        "        '''\n",
        "        bounds_df = pd.DataFrame()\n",
        "\n",
        "        # Using 99% confidence bounds\n",
        "        bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
        "        bounds_df['prediction'] = test_uncertainty_plot_df['value_mean']\n",
        "        bounds_df['real_value'] = truth_uncertainty_plot_df['value']\n",
        "        bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
        "\n",
        "        bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
        "                                  (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
        "\n",
        "        print(\"Proportion of points contained within 99% confidence interval:\",\n",
        "              bounds_df['contained'].mean())\n",
        "        predictedanomaly = bounds_df.index[~bounds_df['contained']]\n",
        "        rho1=[]\n",
        "        rrr=[]\n",
        "\n",
        "\n",
        "        predictedanomaly = sorted(predictedanomaly)\n",
        "\n",
        "\n",
        "\n",
        "        for N in range(2,22):\n",
        "            newarr = []\n",
        "\n",
        "            if N == 2:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1]):\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = sorted(list(set(newarr)))\n",
        "                pdb.set_trace()\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                                a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                                a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                            if i in realanomaly:\n",
        "                                a2.iloc[i, 1] = 1\n",
        "                            else:\n",
        "                                a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                        #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                        #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                        # fp = len(predicteddanomaly) - tp\n",
        "                        # fn = 0\n",
        "                        # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1= tp + tn - fp - fn\n",
        "\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max',N)\n",
        "                print('recall', recall1, 'Signal', name,'N_max',N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name,'N_max',N)\n",
        "                print('F1', F11, 'Signal', name,'N_max',N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 3:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2]):\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                            if i in predicteddanomaly:\n",
        "                                a1.iloc[i, 1] = 1\n",
        "                            else:\n",
        "                                a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                            if i in realanomaly:\n",
        "                                a2.iloc[i, 1] = 1\n",
        "                            else:\n",
        "                                a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                        #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                        #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                        # fp = len(predicteddanomaly) - tp\n",
        "                        # fn = 0\n",
        "                        # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 4:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3]):\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "\n",
        "            elif N == 5:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "\n",
        "                ''' and predictedanomaly[i+3]+1==predictedanomaly[i+4] and predictedanomaly[i+4]+1==predictedanomaly[i+5]\n",
        "                and  predictedanomaly[i+5]+1==predictedanomaly[i+6] and predictedanomaly[i+6]+1==predictedanomaly[i+7]\n",
        "                and predictedanomaly[i+7]+1==predictedanomaly[i+8]\n",
        "                and predictedanomaly[i+8]+1==predictedanomaly[i+9]\n",
        "                and predictedanomaly[i+9]+1==predictedanomaly[i+10]\n",
        "                and predictedanomaly[i+10]+1==predictedanomaly[i+11]\n",
        "                and predictedanomaly[i+11]+1==predictedanomaly[i+12]\n",
        "                and predictedanomaly[i + 12] + 1 == predictedanomaly[i + 13]\n",
        "                and predictedanomaly[i + 13] + 1 == predictedanomaly[i + 14]\n",
        "                and predictedanomaly[i + 14] + 1 == predictedanomaly[i + 15]):'''\n",
        "\n",
        "        #        newarr.append(predictedanomaly[i + 1])\n",
        "        #       newarr.append(predictedanomaly[i + 2])\n",
        "            elif N == 6:\n",
        "               for i in range(len(predictedanomaly) - N):\n",
        "                   if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                    predictedanomaly[\n",
        "                        i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                    predictedanomaly[\n",
        "                        i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                    predictedanomaly[\n",
        "                        i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                    predictedanomaly[\n",
        "                        i + 5]):\n",
        "                      newarr.append(predictedanomaly[i])\n",
        "               predicteddanomaly = list(set(newarr))\n",
        "\n",
        "               realanomaly = label_data['index']\n",
        "\n",
        "               predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "               a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "               a1.columns = ['index', 'value']\n",
        "\n",
        "               a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "               a2.columns = ['index', 'value']\n",
        "\n",
        "               for i in range(len(predicter)):\n",
        "                  if i in predicteddanomaly:\n",
        "                       a1.iloc[i, 1] = 1\n",
        "                  else:\n",
        "                       a1.iloc[i, 1] = 0\n",
        "\n",
        "               for i in range(len(predicter)):\n",
        "                   if i in realanomaly:\n",
        "                         a2.iloc[i, 1] = 1\n",
        "                   else:\n",
        "                         a2.iloc[i, 1] = 0\n",
        "\n",
        "               y_real = a2.value\n",
        "               y_real = y_real.astype(int)\n",
        "               y_predi = a1.value\n",
        "               y_predi = y_predi.astype(int)\n",
        "\n",
        "               cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "        #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "        #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "        # fp = len(predicteddanomaly) - tp\n",
        "        # fn = 0\n",
        "        # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "               tp = cm[0][0]\n",
        "               fp = cm[0][1]\n",
        "               fn = cm[1][0]\n",
        "               tn = cm[1][1]\n",
        "\n",
        "               rho1 = tp + tn - fp - fn\n",
        "\n",
        "               precision1 = tp / (tp + fp)\n",
        "               recall1 = tp / (tp + fn)\n",
        "               Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "               F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "               print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "               print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "               print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "               print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "               print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "               precision.append(precision1)\n",
        "               F1.append(F11)\n",
        "               Accuracy.append(Accuracy1)\n",
        "               recall.append(recall1)\n",
        "               rho.append(rho1)\n",
        "\n",
        "            elif N == 7:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 9:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "\n",
        "            elif N == 10:\n",
        "                 for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                 predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                 realanomaly = label_data['index']\n",
        "\n",
        "                 predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                 a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                 a1.columns = ['index', 'value']\n",
        "\n",
        "                 a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                 a2.columns = ['index', 'value']\n",
        "\n",
        "                 for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                 for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                 y_real = a2.value\n",
        "                 y_real = y_real.astype(int)\n",
        "                 y_predi = a1.value\n",
        "                 y_predi = y_predi.astype(int)\n",
        "\n",
        "                 cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                 tp = cm[0][0]\n",
        "                 fp = cm[0][1]\n",
        "                 fn = cm[1][0]\n",
        "                 tn = cm[1][1]\n",
        "\n",
        "                 rho1 = tp + tn - fp - fn\n",
        "\n",
        "                 precision1 = tp / (tp + fp)\n",
        "                 recall1 = tp / (tp + fn)\n",
        "                 Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                 F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                 print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                 print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                 print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                 print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                 print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                 precision.append(precision1)\n",
        "                 F1.append(F11)\n",
        "                 Accuracy.append(Accuracy1)\n",
        "                 recall.append(recall1)\n",
        "                 rho.append(rho1)\n",
        "            elif N == 11:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 12:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 13:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 14:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 15:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 16:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "\n",
        "            elif N == 17:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 16] ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 18:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 16] and predictedanomaly[i + 16] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 17]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 19:\n",
        "                newarr=[]\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 12]and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 16] and predictedanomaly[i + 16] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 17] and predictedanomaly[i + 17] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 18]  ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 20:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and\n",
        "                           predictedanomaly[i + 11] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 16] and predictedanomaly[i + 16] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 17] and predictedanomaly[i + 17] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 18] and predictedanomaly[i + 18] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                            i + 19]\n",
        "                    ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 21:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11]  and predictedanomaly[i+11] + 1 == predictedanomaly[i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 16]and predictedanomaly[i + 16] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 17] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 18] and predictedanomaly[i + 18] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 19] and predictedanomaly[i + 19] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 20] ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "            elif N == 22:\n",
        "                for i in range(len(predictedanomaly) - N):\n",
        "                    if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 2] and predictedanomaly[i + 2] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 3] and predictedanomaly[i + 3] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 4] and predictedanomaly[i + 4] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 5]and predictedanomaly[i + 5] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 6] and predictedanomaly[i + 6] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 7] and predictedanomaly[i + 7] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 8] and predictedanomaly[i + 8] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 9] and predictedanomaly[i + 9] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 10] and predictedanomaly[i + 10] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 11] and\n",
        "                            predictedanomaly[i+11] + 1 == predictedanomaly[i + 12] and predictedanomaly[i + 12] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 13] and predictedanomaly[i + 13] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 14] and predictedanomaly[i + 14] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 15] and predictedanomaly[i + 15] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 16] and predictedanomaly[i + 16] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 17] and predictedanomaly[i + 17] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 18] and predictedanomaly[i + 18] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 19] and predictedanomaly[i + 19] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 20] and predictedanomaly[i + 20] + 1 ==\n",
        "                            predictedanomaly[\n",
        "                                i + 21]\n",
        "                    ) :\n",
        "                        newarr.append(predictedanomaly[i])\n",
        "                predicteddanomaly = list(set(newarr))\n",
        "\n",
        "                realanomaly = label_data['index']\n",
        "                pdb.set_trace()\n",
        "\n",
        "                predicter = list(range(len(test_uncertainty2)))\n",
        "\n",
        "                a1 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a1.columns = ['index', 'value']\n",
        "\n",
        "                a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "                a2.columns = ['index', 'value']\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in predicteddanomaly:\n",
        "                            a1.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a1.iloc[i, 1] = 0\n",
        "\n",
        "                for i in range(len(predicter)):\n",
        "                        if i in realanomaly:\n",
        "                            a2.iloc[i, 1] = 1\n",
        "                        else:\n",
        "                            a2.iloc[i, 1] = 0\n",
        "\n",
        "                y_real = a2.value\n",
        "                y_real = y_real.astype(int)\n",
        "                y_predi = a1.value\n",
        "                y_predi = y_predi.astype(int)\n",
        "\n",
        "                cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "                    #       cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "                    #        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "                    # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "                    # fp = len(predicteddanomaly) - tp\n",
        "                    # fn = 0\n",
        "                    # tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "                tp = cm[0][0]\n",
        "                fp = cm[0][1]\n",
        "                fn = cm[1][0]\n",
        "                tn = cm[1][1]\n",
        "\n",
        "                rho1 = tp + tn - fp - fn\n",
        "\n",
        "                precision1 = tp / (tp + fp)\n",
        "                recall1 = tp / (tp + fn)\n",
        "                Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "                F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "                print('precision', precision1, 'Signal', name, 'N_max', N)\n",
        "                print('recall', recall1, 'Signal', name, 'N_max', N)\n",
        "                print('Accuracy', Accuracy1, 'Signal', name, 'N_max', N)\n",
        "                print('F1', F11, 'Signal', name, 'N_max', N)\n",
        "                print('rho', rho1, 'Signal', name, 'N_max', N)\n",
        "                precision.append(precision1)\n",
        "                F1.append(F11)\n",
        "                Accuracy.append(Accuracy1)\n",
        "                recall.append(recall1)\n",
        "                rho.append(rho1)\n",
        "        rho_new=(rho)/ max(rho)\n",
        "        plt.plot(range(2,21),rho_new, label=r'$\\rho $',linewidth=3.5 )\n",
        "        plt.plot(range(2, 21), F1, label='F1',linewidth=3.5)\n",
        "        plt.plot(range(2, 21), Accuracy, label='Accuracy',linewidth=3.5)\n",
        "        plt.plot(range(2, 21), precision, label='Precision',linewidth=3.5)\n",
        "        plt.grid()\n",
        "        plt.xlabel('$N_{max}$', fontsize=25)\n",
        "        plt.ylabel('Normalized Different Measurement Metrics ', fontsize=25)\n",
        "\n",
        "        plt.rc('font', size=20)  # controls default text sizes\n",
        "        plt.rc('axes', titlesize=20)  # fontsize of the axes title\n",
        "        plt.rc('axes', labelsize=20)  # fontsize of the x and y labels\n",
        "        plt.rc('xtick', labelsize=40)  # fontsize of the tick labels\n",
        "        plt.rc('ytick', labelsize=40)  # fontsize of the tick labels\n",
        "        plt.rc('legend', fontsize=20)  # legend fontsize\n",
        "        plt.rc('figure', titlesize=20)  # fontsize of the figure title\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        im = im + 1\n",
        "\n",
        "\n",
        "        # matched_indices = list(i_anom_predicted & true_indices_flat)\n",
        "\n",
        "recall_final = mean(recall)\n",
        "precision_final = mean(precision)\n",
        "F1_final = mean(F1)\n",
        "Accuracy_final = mean(Accuracy)\n",
        "#cm = confusion_matrix(y_true=test_labels, y_pred=predicteddanomaly)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L5XL-G_yunOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}