{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tev4Sbjie7lO"
      },
      "source": [
        "##Results for SMAP Signals (Tabel II and IV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGrXwazbzLzh",
        "outputId": "bd198d8d-a012-4a04-c9f6-752369d7ed24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 loss:  0.009106989949941635\n",
            "Training time: 3.108823299407959 Signal P-1\n",
            " Number Of Trainable Parameters 228897 Signal P-1\n",
            " Testing Time 0.26203978061676025 Signal P-1\n",
            "[0.0015538817810600044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.368452030606239\n",
            "precision 0.9908292430896409 Signal P-1\n",
            "recall 0.9124539074580706 Signal P-1\n",
            "Accuracy 0.9047675103001765 Signal P-1\n",
            "F1 0.9500278655025078 Signal P-1\n",
            "epoch 10 loss:  0.0853353887796402\n",
            "Training time: 1.793726348876953 Signal S-1\n",
            " Number Of Trainable Parameters 228897 Signal S-1\n",
            " Testing Time 0.15091581344604493 Signal S-1\n",
            "[0.0015538817810600044, 1.504294963669963e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.18289851113235897\n",
            "precision 0.9318876437199826 Signal S-1\n",
            "recall 0.9391317101789382 Signal S-1\n",
            "Accuracy 0.8791148750170742 Signal S-1\n",
            "F1 0.9354956534443714 Signal S-1\n",
            "epoch 10 loss:  0.05176026374101639\n",
            "Training time: 1.7407019138336182 Signal E-1\n",
            " Number Of Trainable Parameters 228897 Signal E-1\n",
            " Testing Time 0.18792994022369386 Signal E-1\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4675523160122267\n",
            "precision 0.9684842421210605 Signal E-1\n",
            "recall 0.9384391662627242 Signal E-1\n",
            "Accuracy 0.9104161768163649 Signal E-1\n",
            "F1 0.9532250123092071 Signal E-1\n",
            "epoch 10 loss:  0.015011102892458439\n",
            "Training time: 1.8691192626953126 Signal E-2\n",
            " Number Of Trainable Parameters 228897 Signal E-2\n",
            " Testing Time 0.17324318885803222 Signal E-2\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4318235156066651\n",
            "precision 0.9786576804268464 Signal E-2\n",
            "recall 0.8329349904397706 Signal E-2\n",
            "Accuracy 0.8178831260267543 Signal E-2\n",
            "F1 0.8999354422207877 Signal E-2\n",
            "epoch 10 loss:  0.05269346386194229\n",
            "Training time: 1.7731947660446168 Signal E-5\n",
            " Number Of Trainable Parameters 228897 Signal E-5\n",
            " Testing Time 0.17474231719970704 Signal E-5\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5173829068083051\n",
            "precision 0.9904534606205251 Signal E-5\n",
            "recall 0.9608822812576164 Signal E-5\n",
            "Accuracy 0.9518348623853211 Signal E-5\n",
            "F1 0.9754438052823654 Signal E-5\n",
            "epoch 10 loss:  0.05034223571419716\n",
            "Training time: 1.7867580652236938 Signal E-6\n",
            " Number Of Trainable Parameters 228897 Signal E-6\n",
            " Testing Time 0.1883082389831543 Signal E-6\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.07828709288299156\n",
            "precision 0.6830454877158842 Signal E-6\n",
            "recall 0.9894291754756871 Signal E-6\n",
            "Accuracy 0.6781664656212304 Signal E-6\n",
            "F1 0.8081738379622968 Signal E-6\n",
            "epoch 10 loss:  0.022037357091903687\n",
            "Training time: 1.7117814779281617 Signal E-7\n",
            " Number Of Trainable Parameters 228897 Signal E-7\n",
            " Testing Time 0.1751168489456177 Signal E-7\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.12457831325301205\n",
            "precision 0.8425845079206685 Signal E-7\n",
            "recall 0.9619766448305326 Signal E-7\n",
            "Accuracy 0.8155421686746988 Signal E-7\n",
            "F1 0.8983310060509343 Signal E-7\n",
            "epoch 10 loss:  0.06521639227867126\n",
            "Training time: 1.8475955486297608 Signal E-8\n",
            " Number Of Trainable Parameters 228897 Signal E-8\n",
            " Testing Time 0.20997881889343262 Signal E-8\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.05691152311663929\n",
            "precision 0.35367861213118906 Signal E-8\n",
            "recall 0.9163385826771654 Signal E-8\n",
            "Accuracy 0.37092231870452946 Signal E-8\n",
            "F1 0.5103700319780722 Signal E-8\n",
            "epoch 10 loss:  0.03359962999820709\n",
            "Training time: 1.8382893085479737 Signal E-9\n",
            " Number Of Trainable Parameters 228897 Signal E-9\n",
            " Testing Time 0.18971679210662842 Signal E-9\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4331886155330439\n",
            "precision 0.8766847209976067 Signal E-9\n",
            "recall 0.952250649883705 Signal E-9\n",
            "Accuracy 0.8396044380125423 Signal E-9\n",
            "F1 0.912906610703043 Signal E-9\n",
            "epoch 10 loss:  0.2617347836494446\n",
            "Training time: 1.8395156621932984 Signal E-10\n",
            " Number Of Trainable Parameters 228897 Signal E-10\n",
            " Testing Time 0.20278010368347169 Signal E-10\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n",
            "precision 0.00036715212336311344 Signal E-10\n",
            "recall 0.23076923076923078 Signal E-10\n",
            "Accuracy 0.03708063566804003 Signal E-10\n",
            "F1 0.0007331378299120234 Signal E-10\n",
            "epoch 10 loss:  0.05412599816918373\n",
            "Training time: 1.77609543800354 Signal E-11\n",
            " Number Of Trainable Parameters 228897 Signal E-11\n",
            " Testing Time 0.20350949764251708 Signal E-11\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.37582314205079964\n",
            "precision 0.9913488485439259 Signal E-11\n",
            "recall 0.9650100818408255 Signal E-11\n",
            "Accuracy 0.9567262464722484 Signal E-11\n",
            "F1 0.9780021637216011 Signal E-11\n",
            "epoch 10 loss:  0.048917751759290695\n",
            "Training time: 1.89550461769104 Signal E-12\n",
            " Number Of Trainable Parameters 228897 Signal E-12\n",
            " Testing Time 0.19205315113067628 Signal E-12\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.35838626205598684\n",
            "precision 0.9800429455601869 Signal E-12\n",
            "recall 0.9303357314148681 Signal E-12\n",
            "Accuracy 0.9128440366972477 Signal E-12\n",
            "F1 0.9545426585470875 Signal E-12\n",
            "epoch 10 loss:  0.015507660806179047\n",
            "Training time: 1.8374133110046387 Signal E-13\n",
            " Number Of Trainable Parameters 228897 Signal E-13\n",
            " Testing Time 0.19587771892547606 Signal E-13\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4681344148319815\n",
            "precision 0.9538498326159732 Signal E-13\n",
            "recall 0.9686741136474016 Signal E-13\n",
            "Accuracy 0.9251448435689456 Signal E-13\n",
            "F1 0.9612048192771084 Signal E-13\n",
            "epoch 10 loss:  0.017156867310404778\n",
            "Training time: 1.7957072734832764 Signal P-3\n",
            " Number Of Trainable Parameters 228897 Signal P-3\n",
            " Testing Time 0.18740217685699462 Signal P-3\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8122126606153484\n",
            "precision 1.0 Signal P-3\n",
            "recall 0.8424714066737413 Signal P-3\n",
            "Accuracy 0.8422727808558294 Signal P-3\n",
            "F1 0.9145014719057981 Signal P-3\n",
            "epoch 10 loss:  0.004265621304512024\n",
            "Training time: 1.6402806758880615 Signal A-2\n",
            " Number Of Trainable Parameters 228897 Signal A-2\n",
            " Testing Time 0.1794137477874756 Signal A-2\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.39663461538461536\n",
            "precision 0.9843409061737902 Signal A-2\n",
            "recall 0.9867472979927946 Signal A-2\n",
            "Accuracy 0.9712803643724697 Signal A-2\n",
            "F1 0.9855426331684123 Signal A-2\n",
            "epoch 10 loss:  0.005855462048202753\n",
            "Training time: 1.7712773084640503 Signal A-4\n",
            " Number Of Trainable Parameters 228897 Signal A-4\n",
            " Testing Time 0.18470394611358643 Signal A-4\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.6232961586121437\n",
            "precision 1.0 Signal A-4\n",
            "recall 0.9862419434804165 Signal A-4\n",
            "Accuracy 0.985997521685254 Signal A-4\n",
            "F1 0.9930733229329174 Signal A-4\n",
            "epoch 10 loss:  5.53431709704455e-06\n",
            "Training time: 1.6112614870071411 Signal G-2\n",
            " Number Of Trainable Parameters 228897 Signal G-2\n",
            " Testing Time 0.15978653430938722 Signal G-2\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8517208543055367\n",
            "precision 1.0 Signal G-2\n",
            "recall 0.9944210096611784 Signal G-2\n",
            "Accuracy 0.9941504557203101 Signal G-2\n",
            "F1 0.9972027017807191 Signal G-2\n",
            "epoch 10 loss:  1.5842470020288602e-06\n",
            "Training time: 1.6175832748413086 Signal D-7\n",
            " Number Of Trainable Parameters 228897 Signal D-7\n",
            " Testing Time 0.17001943588256835 Signal D-7\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5922431865828093\n",
            "precision 0.4746347402597403 Signal D-7\n",
            "recall 0.46399523903987305 Signal D-7\n",
            "Accuracy 0.3064727463312369 Signal D-7\n",
            "F1 0.4692546895375664 Signal D-7\n",
            "epoch 10 loss:  0.029908770695328712\n",
            "Training time: 1.8278223276138306 Signal F-1\n",
            " Number Of Trainable Parameters 228897 Signal F-1\n",
            " Testing Time 0.19430325031280518 Signal F-1\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.165383718217868\n",
            "precision 0.90839334199032 Signal F-1\n",
            "recall 0.9874246118311305 Signal F-1\n",
            "Accuracy 0.8978306508047585 Signal F-1\n",
            "F1 0.9462616822429908 Signal F-1\n",
            "epoch 10 loss:  3.2996158552123234e-06\n",
            "Training time: 1.6484541177749634 Signal P-4\n",
            " Number Of Trainable Parameters 228897 Signal P-4\n",
            " Testing Time 0.181563138961792 Signal P-4\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8584844976199666\n",
            "precision 1.0 Signal P-4\n",
            "recall 0.9429931797709432 Signal P-4\n",
            "Accuracy 0.942750546764441 Signal P-4\n",
            "F1 0.9706603086297105 Signal P-4\n",
            "epoch 10 loss:  0.004395037889480591\n",
            "Training time: 1.6529557704925537 Signal G-3\n",
            " Number Of Trainable Parameters 228897 Signal G-3\n",
            " Testing Time 0.1700563907623291 Signal G-3\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8799544130682537\n",
            "precision 1.0 Signal G-3\n",
            "recall 0.9935402153261558 Signal G-3\n",
            "Accuracy 0.9932885906040269 Signal G-3\n",
            "F1 0.9967596416544887 Signal G-3\n",
            "epoch 10 loss:  0.15877467393875122\n",
            "Training time: 1.8383955717086793 Signal T-1\n",
            " Number Of Trainable Parameters 228897 Signal T-1\n",
            " Testing Time 0.20496163368225098 Signal T-1\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5551034643106254\n",
            "precision 0.9742355605889015 Signal T-1\n",
            "recall 0.8217313432835821 Signal T-1\n",
            "Accuracy 0.8050453382934202 Signal T-1\n",
            "F1 0.8915085173910225 Signal T-1\n",
            "epoch 10 loss:  0.041701558977365494\n",
            "Training time: 1.8830815076828002 Signal T-2\n",
            " Number Of Trainable Parameters 228897 Signal T-2\n",
            " Testing Time 0.19556427001953125 Signal T-2\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.6065002901915264\n",
            "precision 0.9906268306971294 Signal T-2\n",
            "recall 0.7927801218940459 Signal T-2\n",
            "Accuracy 0.7871154962275102 Signal T-2\n",
            "F1 0.8807291666666667 Signal T-2\n",
            "epoch 10 loss:  4.5277101889951155e-06\n",
            "Training time: 1.7039592266082764 Signal D-8\n",
            " Number Of Trainable Parameters 228897 Signal D-8\n",
            " Testing Time 0.20332329273223876 Signal D-8\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.9154374364191251\n",
            "precision 1.0 Signal D-8\n",
            "recall 0.993513100992114 Signal D-8\n",
            "Accuracy 0.9932604272634792 Signal D-8\n",
            "F1 0.9967459962993683 Signal D-8\n",
            "epoch 10 loss:  1.26484383144998e-06\n",
            "Training time: 1.8187597751617433 Signal D-9\n",
            " Number Of Trainable Parameters 228897 Signal D-9\n",
            " Testing Time 0.19774014949798585 Signal D-9\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7479718766901028\n",
            "precision 0.8557229881372235 Signal D-9\n",
            "recall 0.8219895287958116 Signal D-9\n",
            "Accuracy 0.7217414818820984 Signal D-9\n",
            "F1 0.8385171222117499 Signal D-9\n",
            "epoch 10 loss:  0.35609936714172363\n",
            "Training time: 1.7028612613677978 Signal G-4\n",
            " Number Of Trainable Parameters 228897 Signal G-4\n",
            " Testing Time 0.19979918003082275 Signal G-4\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.284570978745736\n",
            "precision 0.9003821320332059 Signal G-4\n",
            "recall 0.995483682983683 Signal G-4\n",
            "Accuracy 0.8964838625032799 Signal G-4\n",
            "F1 0.9455476371687538 Signal G-4\n",
            "epoch 10 loss:  0.00257422449067235\n",
            "Training time: 2.098252534866333 Signal T-3\n",
            " Number Of Trainable Parameters 228897 Signal T-3\n",
            " Testing Time 0.2298349618911743 Signal T-3\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.44462597736025206\n",
            "precision 0.887749015865442 Signal T-3\n",
            "recall 0.9766404199475066 Signal T-3\n",
            "Accuracy 0.8691796008869179 Signal T-3\n",
            "F1 0.9300756108229707 Signal T-3\n",
            "epoch 10 loss:  6.335820216918364e-05\n",
            "Training time: 0.2795742034912109 Signal D-12\n",
            " Number Of Trainable Parameters 228897 Signal D-12\n",
            " Testing Time 0.2571354627609253 Signal D-12\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5810571573090542\n",
            "precision 0.5120015485869145 Signal D-12\n",
            "recall 0.4911792014856082 Signal D-12\n",
            "Accuracy 0.3344714213454729 Signal D-12\n",
            "F1 0.5013742773196853 Signal D-12\n",
            "epoch 10 loss:  2.8727276912832167e-06\n",
            "Training time: 1.8177580118179322 Signal B-1\n",
            " Number Of Trainable Parameters 228897 Signal B-1\n",
            " Testing Time 0.2126819372177124 Signal B-1\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5713218820014937\n",
            "precision 0.6291923125235523 Signal B-1\n",
            "recall 0.9860236220472441 Signal B-1\n",
            "Accuracy 0.6234752302713468 Signal B-1\n",
            "F1 0.7681926232650871 Signal B-1\n",
            "epoch 10 loss:  0.00432059820741415\n",
            "Training time: 1.7765619516372682 Signal G-7\n",
            " Number Of Trainable Parameters 228897 Signal G-7\n",
            " Testing Time 0.20833377838134765 Signal G-7\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8741738371368001\n",
            "precision 0.9998709510904633 Signal G-7\n",
            "recall 0.966566866267465 Signal G-7\n",
            "Accuracy 0.9662052625015588 Signal G-7\n",
            "F1 0.9829368855058673 Signal G-7\n",
            "epoch 10 loss:  0.003647296689450741\n",
            "Training time: 2.0909746408462526 Signal P-7\n",
            " Number Of Trainable Parameters 228897 Signal P-7\n",
            " Testing Time 0.2069873332977295 Signal P-7\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625, 1.6769816576037038e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5489393375511723\n",
            "precision 0.9982833957553059 Signal P-7\n",
            "recall 0.7968360737419034 Signal P-7\n",
            "Accuracy 0.7960550800148865 Signal P-7\n",
            "F1 0.8862565807702965 Signal P-7\n",
            "epoch 10 loss:  0.035060640424489975\n",
            "Training time: 0.50134117603302 Signal A-5\n",
            " Number Of Trainable Parameters 228897 Signal A-5\n",
            " Testing Time 0.1464090347290039 Signal A-5\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625, 1.6769816576037038e-05, 0.38174642679713083]\n",
            "Proportion of points contained within 99% confidence interval: 0.02626521460602178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.26652267818574515 Signal A-5\n",
            "recall 0.9801429706115965 Signal A-5\n",
            "Accuracy 0.26905829596412556 Signal A-5\n",
            "F1 0.4190864323314655 Signal A-5\n",
            "epoch 10 loss:  0.0018013848457485437\n",
            "Training time: 2.1783922910690308 Signal A-7\n",
            " Number Of Trainable Parameters 228897 Signal A-7\n",
            " Testing Time 0.2209339141845703 Signal A-7\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625, 1.6769816576037038e-05, 0.38174642679713083, 0.006490248117078575]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.43892819858485094\n",
            "precision 0.9921196526214217 Signal A-7\n",
            "recall 0.7205933886228244 Signal A-7\n",
            "Accuracy 0.7166222016007424 Signal A-7\n",
            "F1 0.8348332092834426 Signal A-7\n",
            "epoch 10 loss:  7.584533818771888e-07\n",
            "Training time: 1.1250499963760376 Signal D-13\n",
            " Number Of Trainable Parameters 228897 Signal D-13\n",
            " Testing Time 0.20531878471374512 Signal D-13\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625, 1.6769816576037038e-05, 0.38174642679713083, 0.006490248117078575, 0.43780371679927077]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5924474062459166\n",
            "precision 0.6587449933244326 Signal D-13\n",
            "recall 0.9684003925417075 Signal D-13\n",
            "Accuracy 0.6447144910492617 Signal D-13\n",
            "F1 0.7841080651569329 Signal D-13\n",
            "epoch 10 loss:  0.13549070060253143\n",
            "Training time: 0.5870443344116211 Signal A-9\n",
            " Number Of Trainable Parameters 228897 Signal A-9\n",
            " Testing Time 0.20117402076721191 Signal A-9\n",
            "[0.0015538817810600044, 1.504294963669963e-06, 0.016425899428125414, 0.36716248826688885, 0.012948204705798947, 8.87386111541333e-07, 0.00022666060227981947, 0.001966362049421288, 0.018527862588044577, 0.002562994389914008, 0.008975656751227901, 0.0004982309522393031, 0.0026710833156142343, 0.00011056170489142075, 0.000802129676171351, 0.000540648551107249, 2.879360355240949e-06, 0.13767257564384233, 0.0016691551050781548, 7.339762376678778e-06, 0.00624595326957781, 0.004479406223211265, 0.004224960270734571, 7.107736771674856e-08, 0.06165363303235661, 2.0952070683687907e-07, 4.478216524838401e-05, 0.0945032134111248, 0.5442450914885785, 0.002018203416848625, 1.6769816576037038e-05, 0.38174642679713083, 0.006490248117078575, 0.43780371679927077, 0.5949497790619531]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:506: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4567901234567901\n",
            "precision 0.9918806232170287 Signal A-9\n",
            "recall 0.5390578413834228 Signal A-9\n",
            "Accuracy 0.5365622032288699 Signal A-9\n",
            "F1 0.698501004481533 Signal A-9\n",
            "precision_final 0.8447604585324991\n",
            "recall_final 0.872782849271751\n",
            "Accuracy_final 0.7684023358324705\n",
            "F1_final 0.8391446178673354\n",
            "MSE_final 0.07750712773666504\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "#from fitter import Fitter, get_common_distributions, get_distributions\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "seed=42\n",
        "torch.backends.cudnn.determinestic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "def build_df(data, start=0):\n",
        "#\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "Calculations = pd.DataFrame()\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
        "class BayesianLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, output_length, batch_size):\n",
        "        super(BayesianLSTM, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size  # user-defined\n",
        "\n",
        "        self.hidden_size_1 = 128\n",
        "        self.hidden_size_2 = 32\n",
        "        self.stacked_layers = 2\n",
        "        self.dropout_probability = 0.2  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(n_features,\n",
        "                             self.hidden_size_1,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True, dropout=self.dropout_probability)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
        "                             self.hidden_size_2,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True,dropout=self.dropout_probability)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_size_2, output_length)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        hidden = self.init_hidden1(batch_size)\n",
        "\n",
        "        output, _ = self.lstm1(x, hidden)\n",
        "\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        state = self.init_hidden2(batch_size)\n",
        "        output, state = self.lstm2(output, state)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        output = output[:, -1, :]  # take the last decoder cell's outputs\n",
        "        y_pred = self.fc(output)\n",
        "        return y_pred\n",
        "\n",
        "    def init_hidden1(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def loss(self, pred, truth):\n",
        "        return self.loss_fn(pred, truth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n",
        "\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "SMAP=[  'P-1', 'S-1', 'E-1', 'E-2','E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13',   'P-3',\n",
        "     'A-2', 'A-4', 'G-2',\n",
        "    'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'G-4', 'T-3',  'D-12', 'B-1',  'G-7', 'P-7',\n",
        "     'A-5', 'A-7', 'D-13',  'A-9']\n",
        "\n",
        "MSL=[\n",
        "    'M-1', 'S-2',  'T-4', 'T-5', 'F-7',  'M-4',\n",
        "    'M-5',  'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9',  'T-8',  'D-15', 'M-7', 'F-8']\n",
        "\n",
        "#SMAP=pd.Series(SMAP)\n",
        "#MSL=pd.Series(MSL)\n",
        "\n",
        "\n",
        "avg=[]\n",
        "train_signals=SMAP\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "MSE=[]\n",
        "df_label=df_label[df_label['chan_id'].isin(SMAP)]\n",
        "\n",
        "df_label=df_label.reset_index(drop=True)\n",
        "TrainingTime=[]\n",
        "TestingTime=[]\n",
        "NumberOfParameters=[]\n",
        "for name in SMAP:\n",
        "        label_row=df_label[df_label.chan_id==name]\n",
        "       # pdb.set_trace()\n",
        "     \n",
        "        labels= label_row.anomaly_sequences[im]\n",
        "        labels=eval(labels)\n",
        "      \n",
        "        true_indices_grouped = [list(range(e[0], e[1]+1)) for e in labels]\n",
        "        true_indices_flat = set([i for group in true_indices_grouped for i in group])\n",
        "\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "    \n",
        "        labels= true_indices_flat\n",
        "       \n",
        "\n",
        "       # for i in range(len(labels)):\n",
        "        #    anom=labels[i]\n",
        "            #start=anom[0]\n",
        "            #end=anom[1]\n",
        "\n",
        "        index = list(labels)\n",
        "\n",
        "       # timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "        anomalies=pd.DataFrame({'value': 1, 'index':index})\n",
        "       #     appended_data.append(anomalies)\n",
        "\n",
        "        label_data = anomalies\n",
        "\n",
        "        #label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        #label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data ['name'] = name\n",
        "        #label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        #label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index',  'name']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "       # plot_length = 1000000\n",
        "        #plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        #plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index',  'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)\n",
        "\n",
        "        #sns.displot(data=y_test,  kind=\"hist\", bins=100, aspect=1.5)\n",
        "      #  plt.show()\n",
        "       # pdb.set_trace()\n",
        "\n",
        "        #f = Fitter(y_train,\n",
        "         #          distributions=['gamma',\n",
        "          #                        'lognorm',\n",
        "           #                       \"beta\",\n",
        "            #                      \"burr\",\n",
        "             #                     \"norm\",'cauchy', 'chi2', 'expon', 'exponpow', 'powerlaw', 'rayleigh', 'uniform'])\n",
        "        #f.fit()\n",
        "        #f.summary()\n",
        "        #pdb.set_trace()\n",
        "        n_features = scaled_array.shape[-1]\n",
        "        sequence_length = 10\n",
        "        output_length = 1\n",
        "\n",
        "        batch_size = 64\n",
        "        n_epochs = 10\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        bayesian_lstm = BayesianLSTM(n_features=n_features,\n",
        "                                     output_length=output_length,\n",
        "                                     batch_size=batch_size)\n",
        "        \n",
        "\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)\n",
        "        bayesian_lstm.train()\n",
        "        start=time.time()\n",
        "\n",
        "        for e in range(1, n_epochs + 1):\n",
        "            for b in range(0, len(X_train), batch_size):\n",
        "                features = X_train[b:b + batch_size, :, :]\n",
        "                target = y_train[b:b + batch_size]\n",
        "\n",
        "                X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "                y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "               # pdb.set_trace()\n",
        "\n",
        "                output = bayesian_lstm(X_batch)\n",
        "                loss = criterion(output.view(-1), y_batch)\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print('epoch', e, 'loss: ', loss.item())\n",
        "                offset = sequence_length\n",
        "\n",
        "        training_df = pd.DataFrame()\n",
        "       # training_df['date'] = resample_df['date'].iloc[offset:n_train + offset:1]\n",
        "        training_df['index'] = resample_df['index'].iloc[offset:n_train + offset:1]\n",
        "        training_predictions = bayesian_lstm.predict(X_train)\n",
        "        end=time.time()\n",
        "        NumberOfTrainableParameters=sum(p.numel() for p in bayesian_lstm.parameters() if p.requires_grad)\n",
        "        TrainingingTime=(end-start)/n_epochs\n",
        "        NumberOfParameters.append(NumberOfTrainableParameters)\n",
        "        TrainingTime.append(TrainingingTime)\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "        print(\"Training time:\",(end-start)/n_epochs,'Signal', name)\n",
        "    \n",
        "        print(\" Number Of Trainable Parameters\", NumberOfTrainableParameters,'Signal', name)\n",
        "   \n",
        "\n",
        "\n",
        "        training_df['value'] = inverse_transform(training_predictions)\n",
        "        training_df['source'] = 'Training Prediction'\n",
        "\n",
        "\n",
        "        #training_truth_df['date'] = training_df['date']\n",
        "        training_truth_df['index'] = training_df['index']\n",
        "        training_truth_df['value'] = resample_df['value'].iloc[\n",
        "                                     offset:n_train + offset:1]\n",
        "        training_truth_df['source'] = 'True Values'\n",
        "\n",
        "        testing_df = pd.DataFrame()\n",
        "       # testing_df['date'] = resample_df_test['date'].iloc[offset:n_test + offset:1]\n",
        "        testing_df['index'] = resample_df_test['index'].iloc[offset:n_test + offset:1]\n",
        "        start=time.time()\n",
        "\n",
        "        testing_predictions = bayesian_lstm.predict(X_test)\n",
        "        end=time.time()\n",
        "        TestingingTime=(end-start)/n_epochs\n",
        "        print(\" Testing Time\", (end-start)/n_epochs,'Signal', name)\n",
        "        TestingTime.append(TestingingTime)\n",
        "\n",
        "        #print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "\n",
        "        \n",
        "                     \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        testing_df['value'] = inverse_transform(testing_predictions)\n",
        "        testing_df['source'] = 'Test Prediction'\n",
        "\n",
        "        testing_truth_df = pd.DataFrame()\n",
        "        #testing_truth_df['date'] = testing_df['date']\n",
        "        testing_truth_df['index'] = testing_df['index']\n",
        "\n",
        "        testing_truth_df['value'] = resample_df_test['value'].iloc[offset:n_test + offset:1]\n",
        "        testing_truth_df['source'] = 'True Values'\n",
        "\n",
        "\n",
        "        evaluation = pd.concat([training_df,\n",
        "                                testing_df,\n",
        "                                training_truth_df,\n",
        "                                testing_truth_df\n",
        "                                ], axis=0)\n",
        "\n",
        "        fig = px.line(evaluation,\n",
        "                             x=\"index\",\n",
        "                              y=\"value\",\n",
        "                              color=\"source\")\n",
        "        #fig.show()\n",
        "\n",
        "        n_experiments = 2\n",
        "        test_uncertainty_df = pd.DataFrame()\n",
        "        #test_uncertainty_df['date'] = testing_df['date']\n",
        "        test_uncertainty_df['index'] = testing_df['index']\n",
        "\n",
        "        for i in range(n_experiments):\n",
        "            experiment_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "            test_uncertainty_df['value_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
        "\n",
        "        log_energy_consumption_df = test_uncertainty_df.filter(like='value', axis=1)\n",
        "        test_uncertainty_df['value_mean'] = log_energy_consumption_df.mean(axis=1)\n",
        "        test_uncertainty_df['value_std'] = log_energy_consumption_df.std(axis=1)\n",
        "        MSE.append(mean( testing_truth_df['value']-test_uncertainty_df['value_mean'])**2)\n",
        "        print(MSE)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "        test_uncertainty1 = test_uncertainty_df['value_mean']\n",
        "\n",
        "        #########################Adaptive Smoothing\n",
        "\n",
        "        #   pdb.set_trace()\n",
        "        Threshold = 10\n",
        "        gamma = 0.1\n",
        "        betta = 0.1\n",
        "        test_uncertainty2 = []\n",
        "        ###########\n",
        "        for jj in range(len(test_uncertainty1) - 2):\n",
        "            test_uncertaintyy = (1 / (1 + gamma + betta)) * (\n",
        "                        test_uncertainty1.iloc[jj] + gamma * test_uncertainty1.iloc[jj + 1] + betta *\n",
        "                        test_uncertainty1.iloc[jj + 2])\n",
        "            test_uncertainty2.append(test_uncertaintyy)\n",
        "        test_uncertainty2 = pd.DataFrame(test_uncertainty2)\n",
        "\n",
        "        test_uncertainty2.columns = [\"value_mean\"]\n",
        "\n",
        "\n",
        "        test_uncertainty_df[\"value_mean\"] = test_uncertainty2[\"value_mean\"]\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "\n",
        "        test_uncertainty_df = test_uncertainty_df[['index',  'value_mean', 'value_std']]\n",
        "        test_uncertainty_df['lower_bound'] = test_uncertainty_df['value_mean'] - 5* test_uncertainty_df['value_std']\n",
        "        test_uncertainty_df['upper_bound'] = test_uncertainty_df['value_mean'] + 5 * test_uncertainty_df['value_std']\n",
        "        import plotly.graph_objects as go\n",
        "\n",
        "        test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
        "        # test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
        "        # truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_truth_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "\n",
        "        upper_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['upper_bound'],\n",
        "          mode='lines',\n",
        "         fill=None,\n",
        "         name='99% Upper Confidence Bound'\n",
        "         )\n",
        "        lower_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['lower_bound'],\n",
        "          mode='lines',\n",
        "          fill='tonexty',\n",
        "         name= '99% Lower Confidence Bound',\n",
        "         fillcolor='rgba(255, 211, 0, 0.1)',\n",
        "         )\n",
        "        real_trace = go.Scatter(\n",
        "            x=truth_uncertainty_plot_df['index'],\n",
        "            y=truth_uncertainty_plot_df['value'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='Real Values'\n",
        "        )\n",
        "\n",
        "        labels = go.Scatter(\n",
        "           x=label_data['index'],\n",
        "          y=label_data['value'],\n",
        "         mode='lines',\n",
        "         fill='tonexty' ,\n",
        "         name='labels'\n",
        "         )\n",
        "        data = [upper_trace, lower_trace, real_trace]\n",
        "\n",
        "        fig = go.Figure(data=data)\n",
        "        fig.update_layout(title='Uncertainty MCDropout Test Data',\n",
        "                            xaxis_title='index',\n",
        "                            yaxis_title='value',\n",
        "         legend_font_size=14,\n",
        "                          )\n",
        "        #fig.show()\n",
        "        bounds_df = pd.DataFrame()\n",
        "\n",
        "        # Using 99% confidence bounds\n",
        "        bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
        "        bounds_df['prediction'] = test_uncertainty_plot_df['value_mean']\n",
        "        bounds_df['real_value'] = truth_uncertainty_plot_df['value']\n",
        "        bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
        "\n",
        "        bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
        "                                  (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
        "\n",
        "        print(\"Proportion of points contained within 99% confidence interval:\",\n",
        "              bounds_df['contained'].mean())\n",
        "        predictedanomaly = bounds_df.index[~bounds_df['contained']]\n",
        "\n",
        "        N = 15\n",
        "        newarr = []\n",
        "\n",
        "\n",
        "        for i in range(len(predictedanomaly) - N):\n",
        "            if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 == predictedanomaly[\n",
        "               i + 2] and predictedanomaly[i+3]+1==predictedanomaly[i+4] and predictedanomaly[i+4]+1==predictedanomaly[i+5]\n",
        "                and  predictedanomaly[i+5]+1==predictedanomaly[i+6] and predictedanomaly[i+6]+1==predictedanomaly[i+7]\n",
        "                and predictedanomaly[i+7]+1==predictedanomaly[i+8]\n",
        "                and predictedanomaly[i+8]+1==predictedanomaly[i+9]\n",
        "                and predictedanomaly[i+9]+1==predictedanomaly[i+10]\n",
        "                and predictedanomaly[i+10]+1==predictedanomaly[i+11]\n",
        "                and predictedanomaly[i+11]+1==predictedanomaly[i+12]\n",
        "                and predictedanomaly[i + 12] + 1 == predictedanomaly[i + 13]\n",
        "                and predictedanomaly[i + 13] + 1 == predictedanomaly[i + 14]\n",
        "                and predictedanomaly[i + 14] + 1 == predictedanomaly[i + 15]):\n",
        "\n",
        "                newarr.append(predictedanomaly[i])\n",
        "        #        newarr.append(predictedanomaly[i + 1])\n",
        "         #       newarr.append(predictedanomaly[i + 2])\n",
        "\n",
        "\n",
        "        predicteddanomaly = list(set(newarr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        realanomaly = label_data['index']\n",
        "\n",
        "        predicter=list(range(len(test_uncertainty2)))\n",
        "\n",
        "        a1 = pd.DataFrame(index=range(len(test_uncertainty2)),columns=range(2))\n",
        "        a1.columns=['index','value']\n",
        "\n",
        "        a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "        a2.columns = ['index','value']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in predicteddanomaly:\n",
        "                a1.iloc[i,1]=1\n",
        "            else:\n",
        "                a1.iloc[i,1]=0\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in realanomaly:\n",
        "                a2.iloc[i,1] = 1\n",
        "            else:\n",
        "                a2.iloc[i, 1] = 0\n",
        "\n",
        "\n",
        "\n",
        "        y_real=a2.value\n",
        "        y_real=y_real.astype(int)\n",
        "        y_predi=a1.value\n",
        "        y_predi=y_predi.astype(int)\n",
        "\n",
        "\n",
        "        cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "        cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "        #fp = len(predicteddanomaly) - tp\n",
        "        #fn = 0\n",
        "        #tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "        tp=cm[0][0]\n",
        "        fp=cm[0][1]\n",
        "        fn=cm[1][0]\n",
        "        tn=cm[1][1]\n",
        "\n",
        "        precision1 = tp / (tp + fp)\n",
        "        recall1 = tp / (tp + fn)\n",
        "        Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "        F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "        print('precision', precision1, 'Signal', name)\n",
        "        print('recall', recall1, 'Signal', name)\n",
        "        print('Accuracy', Accuracy1, 'Signal', name)\n",
        "        print('F1', F11, 'Signal', name)\n",
        "        precision.append(precision1)\n",
        "        F1.append(F11)\n",
        "        Accuracy.append(Accuracy1)\n",
        "        recall.append(recall1)\n",
        "\n",
        "        im=im+1\n",
        "\n",
        "\n",
        "\n",
        "        #matched_indices = list(i_anom_predicted & true_indices_flat)\n",
        "\n",
        "Calculations['pipline']='Bayesian_LSTM'\n",
        "Calculations['fit_time']=TrainingTime\n",
        "Calculations['prediction_time']=TestingTime\n",
        "\n",
        "#Calculations.iloc['number_of_parameters']=NumberOfTrainableParameters\n",
        "recall_final=mean(recall)\n",
        "precision_final=mean(precision)\n",
        "F1_final=mean(F1)\n",
        "Accuracy_final=mean(Accuracy)\n",
        "#cm = confusion_matrix(y_true=test_labels, y_pred=predicteddanomaly)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# %%\n",
        "recall_final=mean(recall)\n",
        "precision_final=mean(precision)\n",
        "F1_final=mean(F1)\n",
        "MSE_final=mean(MSE)\n",
        "Accuracy_final=mean(Accuracy)\n",
        "print('precision_final', precision_final)\n",
        "print('recall_final', recall_final)\n",
        "print('Accuracy_final',Accuracy_final)\n",
        "print('F1_final', F1_final)\n",
        "print('MSE_final', MSE_final)\n",
        "## New Test Bayesian LSTM AE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFH-sE3XscTV",
        "outputId": "79d42849-3a11-488e-a120-7a08c266f0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE_final 0.044757840667867706\n"
          ]
        }
      ],
      "source": [
        "Calculations['pipline']='Bayesian_lstm'\n",
        "MSE_final=mean(MSE)\n",
        "print('MSE_final', MSE_final)\n",
        "import os   \n",
        "Calculations.to_csv('Calculations.csv')  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIxXfZEFHZ_2",
        "outputId": "58107692-092d-47fd-a82a-5ff998090909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 loss:  4.817243734578369e-06\n",
            "Training time: 1.9776106357574463 Signal M-6\n",
            " Number Of Trainable Parameters 228897 Signal M-6\n",
            " Testing Time 0.06991562843322754 Signal M-6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4561059342815105\n",
            "[4.817243734578369e-06, nan]\n",
            "precision 0.4482758620689655 Signal M-6\n",
            "recall 0.8213228035538006 Signal M-6\n",
            "Accuracy 0.40804315841098576 Signal M-6\n",
            "F1 0.5799930289299408 Signal M-6\n",
            "epoch 10 loss:  0.0333426371216774\n",
            "Training time: 1.7403138875961304 Signal M-1\n",
            " Number Of Trainable Parameters 228897 Signal M-1\n",
            " Testing Time 0.070931077003479 Signal M-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.026025584472871635\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan]\n",
            "precision 0.19217081850533807 Signal M-1\n",
            "recall 0.9557522123893806 Signal M-1\n",
            "Accuracy 0.5941773268636965 Signal M-1\n",
            "F1 0.32 Signal M-1\n",
            "epoch 10 loss:  0.14085425436496735\n",
            "Training time: 1.9433006525039673 Signal M-2\n",
            " Number Of Trainable Parameters 228897 Signal M-2\n",
            " Testing Time 0.07765352725982666 Signal M-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.017203352448169385\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan]\n",
            "precision 0.0026690391459074734 Signal M-2\n",
            "recall 0.009966777408637873 Signal M-2\n",
            "Accuracy 0.37318041464490515 Signal M-2\n",
            "F1 0.004210526315789474 Signal M-2\n",
            "epoch 10 loss:  6.565194780705497e-05\n",
            "Training time: 0.7448247909545899 Signal S-2\n",
            " Number Of Trainable Parameters 228897 Signal S-2\n",
            " Testing Time 0.05998709201812744 Signal S-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.9014859658778206\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan]\n",
            "precision 1.0 Signal S-2\n",
            "recall 0.9939393939393939 Signal S-2\n",
            "Accuracy 0.9928453494771602 Signal S-2\n",
            "F1 0.9969604863221886 Signal S-2\n",
            "epoch 10 loss:  0.005667318124324083\n",
            "Training time: 3.101324462890625 Signal P-10\n",
            " Number Of Trainable Parameters 228897 Signal P-10\n",
            " Testing Time 0.15502736568450928 Signal P-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4430213464696223\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan]\n",
            "precision 0.7533993620950142 Signal P-10\n",
            "recall 0.9716388828750812 Signal P-10\n",
            "Accuracy 0.7369458128078817 Signal P-10\n",
            "F1 0.848714069591528 Signal P-10\n",
            "epoch 10 loss:  0.2324029803276062\n",
            "Training time: 1.5793813943862915 Signal T-4\n",
            " Number Of Trainable Parameters 228897 Signal T-4\n",
            " Testing Time 0.07916638851165772 Signal T-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.009968282736746714\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan]\n",
            "precision 0.14606741573033707 Signal T-4\n",
            "recall 0.968944099378882 Signal T-4\n",
            "Accuracy 0.16810149524241053 Signal T-4\n",
            "F1 0.2538649308380797 Signal T-4\n",
            "epoch 10 loss:  2.5438855573156616e-06\n",
            "Training time: 1.6155328512191773 Signal T-5\n",
            " Number Of Trainable Parameters 228897 Signal T-5\n",
            " Testing Time 0.06398534774780273 Signal T-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.9144021739130435\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan]\n",
            "precision 1.0 Signal T-5\n",
            "recall 0.9882139619220308 Signal T-5\n",
            "Accuracy 0.9873188405797102 Signal T-5\n",
            "F1 0.9940720474236205 Signal T-5\n",
            "epoch 10 loss:  0.010235900059342384\n",
            "Training time: 1.680398178100586 Signal F-7\n",
            " Number Of Trainable Parameters 228897 Signal F-7\n",
            " Testing Time 0.11738381385803223 Signal F-7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.23850118953211738\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan]\n",
            "precision 0.9636284910153713 Signal F-7\n",
            "recall 0.9156552149763423 Signal F-7\n",
            "Accuracy 0.8850118953211736 Signal F-7\n",
            "F1 0.9390295358649788 Signal F-7\n",
            "epoch 10 loss:  0.04033857211470604\n",
            "Training time: 1.3692716598510741 Signal M-3\n",
            " Number Of Trainable Parameters 228897 Signal M-3\n",
            " Testing Time 0.06376910209655762 Signal M-3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.4407179971658007\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan]\n",
            "precision 0.9087982832618026 Signal M-3\n",
            "recall 0.8709511568123394 Signal M-3\n",
            "Accuracy 0.8001889466225791 Signal M-3\n",
            "F1 0.8894723024415857 Signal M-3\n",
            "epoch 10 loss:  0.06876510381698608\n",
            "Training time: 1.3358916997909547 Signal M-4\n",
            " Number Of Trainable Parameters 228897 Signal M-4\n",
            " Testing Time 0.061275577545166014 Signal M-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.40532544378698226\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan]\n",
            "precision 0.9301408450704225 Signal M-4\n",
            "recall 0.8680336487907466 Signal M-4\n",
            "Accuracy 0.8141025641025641 Signal M-4\n",
            "F1 0.8980146858852326 Signal M-4\n",
            "epoch 10 loss:  0.06498318910598755\n",
            "Training time: 1.2967293500900268 Signal M-5\n",
            " Number Of Trainable Parameters 228897 Signal M-5\n",
            " Testing Time 0.08158435821533203 Signal M-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.1949411251635412\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan]\n",
            "precision 0.8839195979899498 Signal M-5\n",
            "recall 0.8618324350808427 Signal M-5\n",
            "Accuracy 0.7754034016572177 Signal M-5\n",
            "F1 0.8727362937236419 Signal M-5\n",
            "epoch 10 loss:  0.0038100939709693193\n",
            "Training time: 2.625287389755249 Signal P-15\n",
            " Number Of Trainable Parameters 228897 Signal P-15\n",
            " Testing Time 0.09075937271118165 Signal P-15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.11243851018973998\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan]\n",
            "precision 0.2051009564293305 Signal P-15\n",
            "recall 0.965 Signal P-15\n",
            "Accuracy 0.20344342937456078 Signal P-15\n",
            "F1 0.3382997370727432 Signal P-15\n",
            "epoch 10 loss:  0.005871171597391367\n",
            "Training time: 1.6133619546890259 Signal C-1\n",
            " Number Of Trainable Parameters 228897 Signal C-1\n",
            " Testing Time 0.07418234348297119 Signal C-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.1313220940550133\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan]\n",
            "precision 0.45670103092783504 Signal C-1\n",
            "recall 0.8772277227722772 Signal C-1\n",
            "Accuracy 0.4764862466725821 Signal C-1\n",
            "F1 0.6006779661016949 Signal C-1\n",
            "epoch 10 loss:  4.5980195864103734e-05\n",
            "Training time: 0.5197072744369506 Signal C-2\n",
            " Number Of Trainable Parameters 228897 Signal C-2\n",
            " Testing Time 0.0597224235534668 Signal C-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.2356687898089172\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan]\n",
            "precision 0.3874868559411146 Signal C-2\n",
            "recall 0.8432494279176201 Signal C-2\n",
            "Accuracy 0.36109750122488976 Signal C-2\n",
            "F1 0.5309798270893372 Signal C-2\n",
            "epoch 10 loss:  0.16260473430156708\n",
            "Training time: 0.7823635816574097 Signal T-12\n",
            " Number Of Trainable Parameters 228897 Signal T-12\n",
            " Testing Time 0.07796070575714112 Signal T-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.39793388429752063\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan]\n",
            "precision 0.7897257292120157 Signal T-12\n",
            "recall 0.953732912723449 Signal T-12\n",
            "Accuracy 0.7632231404958678 Signal T-12\n",
            "F1 0.86401524172422 Signal T-12\n",
            "epoch 10 loss:  0.14057578146457672\n",
            "Training time: 0.7379604578018188 Signal T-13\n",
            " Number Of Trainable Parameters 228897 Signal T-13\n",
            " Testing Time 0.08204996585845947 Signal T-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.3371900826446281\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan]\n",
            "precision 0.897045244690674 Signal T-13\n",
            "recall 0.9464198733560643 Signal T-13\n",
            "Accuracy 0.8615702479338843 Signal T-13\n",
            "F1 0.9210713439203603 Signal T-13\n",
            "epoch 10 loss:  0.03005399741232395\n",
            "Training time: 1.6505236625671387 Signal F-4\n",
            " Number Of Trainable Parameters 228897 Signal F-4\n",
            " Testing Time 0.0994828224182129 Signal F-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.07297772567409144\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan]\n",
            "precision 0.29230308475591493 Signal F-4\n",
            "recall 0.9494163424124513 Signal F-4\n",
            "Accuracy 0.29161781946072685 Signal F-4\n",
            "F1 0.4469887794824823 Signal F-4\n",
            "epoch 10 loss:  1.4874936823616736e-05\n",
            "Training time: 1.6978123664855957 Signal F-5\n",
            " Number Of Trainable Parameters 228897 Signal F-5\n",
            " Testing Time 0.12530438899993895 Signal F-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0626278118609407\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan]\n",
            "precision 0.2444799148709763 Signal F-5\n",
            "recall 0.9072063178677197 Signal F-5\n",
            "Accuracy 0.24948875255623723 Signal F-5\n",
            "F1 0.38516345347862524 Signal F-5\n",
            "epoch 10 loss:  7.834634629944048e-07\n",
            "Training time: 2.7104742527008057 Signal D-14\n",
            " Number Of Trainable Parameters 228897 Signal D-14\n",
            " Testing Time 0.07331357002258301 Signal D-14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8435946462715105\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan]\n",
            "precision 0.9330823923044751 Signal D-14\n",
            "recall 0.9094985731757033 Signal D-14\n",
            "Accuracy 0.8531548757170172 Signal D-14\n",
            "F1 0.921139554087531 Signal D-14\n",
            "epoch 10 loss:  0.004319627303630114\n",
            "Training time: 0.3362799882888794 Signal T-9\n",
            " Number Of Trainable Parameters 228897 Signal T-9\n",
            " Testing Time 0.02539365291595459 Signal T-9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.49079189686924496\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan]\n",
            "precision 1.0 Signal T-9\n",
            "recall 0.8966789667896679 Signal T-9\n",
            "Accuracy 0.8950276243093923 Signal T-9\n",
            "F1 0.9455252918287939 Signal T-9\n",
            "epoch 10 loss:  0.008534700609743595\n",
            "Training time: 1.9635457754135133 Signal P-14\n",
            " Number Of Trainable Parameters 228897 Signal P-14\n",
            " Testing Time 0.1931998014450073 Signal P-14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan]\n",
            "precision 0.0005078720162519045 Signal P-14\n",
            "recall 0.23076923076923078 Signal P-14\n",
            "Accuracy 0.02857142857142857 Signal P-14\n",
            "F1 0.0010135135135135134 Signal P-14\n",
            "epoch 10 loss:  0.0001280488504562527\n",
            "Training time: 0.5107930898666382 Signal T-8\n",
            " Number Of Trainable Parameters 228897 Signal T-8\n",
            " Testing Time 0.03800647258758545 Signal T-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.856858846918489\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan]\n",
            "precision 1.0 Signal T-8\n",
            "recall 0.9323158593231586 Signal T-8\n",
            "Accuracy 0.9310801855533466 Signal T-8\n",
            "F1 0.9649725274725275 Signal T-8\n",
            "epoch 10 loss:  0.007573776878416538\n",
            "Training time: 2.760431003570557 Signal P-11\n",
            " Number Of Trainable Parameters 228897 Signal P-11\n",
            " Testing Time 0.10511789321899415 Signal P-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5702127659574469\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan, 0.007573776878416538, nan]\n",
            "precision 0.9833080424886191 Signal P-11\n",
            "recall 0.935604966791799 Signal P-11\n",
            "Accuracy 0.9205673758865248 Signal P-11\n",
            "F1 0.9588635691032851 Signal P-11\n",
            "epoch 10 loss:  0.17942987382411957\n",
            "Training time: 1.9967019081115722 Signal D-15\n",
            " Number Of Trainable Parameters 228897 Signal D-15\n",
            " Testing Time 0.09541957378387451 Signal D-15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.6378026070763501\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan, 0.007573776878416538, nan, 0.17942987382411957, nan]\n",
            "precision 1.0 Signal D-15\n",
            "recall 0.701304753028891 Signal D-15\n",
            "Accuracy 0.7006517690875232 Signal D-15\n",
            "F1 0.8244316625582031 Signal D-15\n",
            "epoch 10 loss:  0.03682702034711838\n",
            "Training time: 1.4837051153182983 Signal D-16\n",
            " Number Of Trainable Parameters 228897 Signal D-16\n",
            " Testing Time 0.08676705360412598 Signal D-16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.10408069692801467\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan, 0.007573776878416538, nan, 0.17942987382411957, nan, 0.03682702034711838, nan]\n",
            "precision 0.281413612565445 Signal D-16\n",
            "recall 0.8037383177570093 Signal D-16\n",
            "Accuracy 0.44750114626318205 Signal D-16\n",
            "F1 0.4168686379059621 Signal D-16\n",
            "epoch 10 loss:  0.00015790079487487674\n",
            "Training time: 1.5452480554580688 Signal M-7\n",
            " Number Of Trainable Parameters 228897 Signal M-7\n",
            " Testing Time 0.0870882511138916 Signal M-7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5773532152842498\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan, 0.007573776878416538, nan, 0.17942987382411957, nan, 0.03682702034711838, nan, 0.00015790079487487674, nan]\n",
            "precision 0.9813999021047479 Signal M-7\n",
            "recall 0.9520417853751187 Signal M-7\n",
            "Accuracy 0.9342963653308481 Signal M-7\n",
            "F1 0.9664979513135695 Signal M-7\n",
            "epoch 10 loss:  0.08980521559715271\n",
            "Training time: 3.4363221645355226 Signal F-8\n",
            " Number Of Trainable Parameters 228897 Signal F-8\n",
            " Testing Time 0.12732455730438233 Signal F-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:529: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7242632216390795\n",
            "[4.817243734578369e-06, nan, 0.0333426371216774, nan, 0.14085425436496735, nan, 6.565194780705497e-05, nan, 0.005667318124324083, nan, 0.2324029803276062, nan, 2.5438855573156616e-06, nan, 0.010235900059342384, nan, 0.04033857211470604, nan, 0.06876510381698608, nan, 0.06498318910598755, nan, 0.0038100939709693193, nan, 0.005871171597391367, nan, 4.5980195864103734e-05, nan, 0.16260473430156708, nan, 0.14057578146457672, nan, 0.03005399741232395, nan, 1.4874936823616736e-05, nan, 7.834634629944048e-07, nan, 0.004319627303630114, nan, 0.008534700609743595, nan, 0.0001280488504562527, nan, 0.007573776878416538, nan, 0.17942987382411957, nan, 0.03682702034711838, nan, 0.00015790079487487674, nan, 0.08980521559715271, nan]\n",
            "precision 1.0 Signal F-8\n",
            "recall 0.7830303030303031 Signal F-8\n",
            "Accuracy 0.7823980621719823 Signal F-8\n",
            "F1 0.8783140720598233 Signal F-8\n",
            "F1_final 0.8391446178673354\n",
            "MSE_final nan\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "#from fitter import Fitter, get_common_distributions, get_distributions\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "seed=42\n",
        "torch.backends.cudnn.determinestic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "def build_df(data, start=0):\n",
        "#\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "Calculations = pd.DataFrame()\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
        "class BayesianLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, output_length, batch_size):\n",
        "        super(BayesianLSTM, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size  # user-defined\n",
        "\n",
        "        self.hidden_size_1 = 128\n",
        "        self.hidden_size_2 = 32\n",
        "        self.stacked_layers = 2\n",
        "        self.dropout_probability = 0.2  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(n_features,\n",
        "                             self.hidden_size_1,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True, dropout=self.dropout_probability)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
        "                             self.hidden_size_2,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True,dropout=self.dropout_probability)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_size_2, output_length)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        hidden = self.init_hidden1(batch_size)\n",
        "\n",
        "        output, _ = self.lstm1(x, hidden)\n",
        "\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        state = self.init_hidden2(batch_size)\n",
        "        output, state = self.lstm2(output, state)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        output = output[:, -1, :]  # take the last decoder cell's outputs\n",
        "        y_pred = self.fc(output)\n",
        "        return y_pred\n",
        "\n",
        "    def init_hidden1(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def loss(self, pred, truth):\n",
        "        return self.loss_fn(pred, truth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n",
        "\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "SMAP=[  'P-1', 'S-1', 'E-1', 'E-2','E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13',   'P-3',\n",
        "     'A-2', 'A-4', 'G-2',\n",
        "    'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'G-4', 'T-3',  'D-12', 'B-1',  'G-7', 'P-7',\n",
        "     'A-5', 'A-7', 'D-13',  'A-9']\n",
        "\n",
        "MSL=[\n",
        "    'M-1', 'S-2',  'T-4', 'T-5', 'F-7',  'M-4',\n",
        "    'M-5',  'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9',  'T-8',  'D-15', 'M-7', 'F-8']\n",
        "SIGNALS = [\n",
        "    'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11',  'B-1', 'G-6', 'G-7', 'P-7',\n",
        "    'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3', 'M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8'\n",
        "]\n",
        "SMAP=[  'P-1',  'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'P-4', 'G-3',  'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11',  'G-6', 'G-7',\n",
        "    'R-1', 'A-5', 'A-6',  'D-13', 'A-8', 'F-3']\n",
        "\n",
        "\n",
        "MSL=['M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8']\n",
        "#SMAP=pd.Series(SMAP)\n",
        "#MSL=pd.Series(MSL)\n",
        "\n",
        "\n",
        "avg=[]\n",
        "train_signals=MSL\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "MSE=[]\n",
        "df_label=df_label[df_label['chan_id'].isin(MSL)]\n",
        "\n",
        "df_label=df_label.reset_index(drop=True)\n",
        "TrainingTime=[]\n",
        "TestingTime=[]\n",
        "\n",
        "\n",
        "NumberOfParameters=[]\n",
        "for name in MSL:\n",
        "        label_row=df_label[df_label.chan_id==name]\n",
        "        #pdb.set_trace()\n",
        "     \n",
        "        labels= label_row.anomaly_sequences[im]\n",
        "        labels=eval(labels)\n",
        "      \n",
        "        true_indices_grouped = [list(range(e[0], e[1]+1)) for e in labels]\n",
        "        true_indices_flat = set([i for group in true_indices_grouped for i in group])\n",
        "\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "    \n",
        "        labels= true_indices_flat\n",
        "       \n",
        "\n",
        "       # for i in range(len(labels)):\n",
        "        #    anom=labels[i]\n",
        "            #start=anom[0]\n",
        "            #end=anom[1]\n",
        "\n",
        "        index = list(labels)\n",
        "\n",
        "       # timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "        anomalies=pd.DataFrame({'value': 1, 'index':index})\n",
        "       #     appended_data.append(anomalies)\n",
        "\n",
        "        label_data = anomalies\n",
        "\n",
        "        #label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        #label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data ['name'] = name\n",
        "        #label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        #label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index',  'name']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "       # plot_length = 1000000\n",
        "        #plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        #plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index',  'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)\n",
        "\n",
        "        #sns.displot(data=y_test,  kind=\"hist\", bins=100, aspect=1.5)\n",
        "      #  plt.show()\n",
        "       # pdb.set_trace()\n",
        "\n",
        "        #f = Fitter(y_train,\n",
        "         #          distributions=['gamma',\n",
        "          #                        'lognorm',\n",
        "           #                       \"beta\",\n",
        "            #                      \"burr\",\n",
        "             #                     \"norm\",'cauchy', 'chi2', 'expon', 'exponpow', 'powerlaw', 'rayleigh', 'uniform'])\n",
        "        #f.fit()\n",
        "        #f.summary()\n",
        "        #pdb.set_trace()\n",
        "        n_features = scaled_array.shape[-1]\n",
        "        sequence_length = 10\n",
        "        output_length = 1\n",
        "\n",
        "        batch_size = 64\n",
        "        n_epochs = 10\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        bayesian_lstm = BayesianLSTM(n_features=n_features,\n",
        "                                     output_length=output_length,\n",
        "                                     batch_size=batch_size)\n",
        "        \n",
        "\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)\n",
        "        bayesian_lstm.train()\n",
        "        start=time.time()\n",
        "\n",
        "        for e in range(1, n_epochs + 1):\n",
        "            for b in range(0, len(X_train), batch_size):\n",
        "                features = X_train[b:b + batch_size, :, :]\n",
        "                target = y_train[b:b + batch_size]\n",
        "\n",
        "                X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "                y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "               # pdb.set_trace()\n",
        "\n",
        "                output = bayesian_lstm(X_batch)\n",
        "                loss = criterion(output.view(-1), y_batch)\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print('epoch', e, 'loss: ', loss.item())\n",
        "                offset = sequence_length\n",
        "\n",
        "        training_df = pd.DataFrame()\n",
        "       # training_df['date'] = resample_df['date'].iloc[offset:n_train + offset:1]\n",
        "        training_df['index'] = resample_df['index'].iloc[offset:n_train + offset:1]\n",
        "        training_predictions = bayesian_lstm.predict(X_train)\n",
        "        end=time.time()\n",
        "        NumberOfTrainableParameters=sum(p.numel() for p in bayesian_lstm.parameters() if p.requires_grad)\n",
        "        TrainingingTime=(end-start)/n_epochs\n",
        "        NumberOfParameters.append(NumberOfTrainableParameters)\n",
        "        TrainingTime.append(TrainingingTime)\n",
        "        MSE.append(loss.item())\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "        print(\"Training time:\",(end-start)/n_epochs,'Signal', name)\n",
        "    \n",
        "        print(\" Number Of Trainable Parameters\", NumberOfTrainableParameters,'Signal', name)\n",
        "   \n",
        "\n",
        "\n",
        "        training_df['value'] = inverse_transform(training_predictions)\n",
        "        training_df['source'] = 'Training Prediction'\n",
        "\n",
        "\n",
        "        #training_truth_df['date'] = training_df['date']\n",
        "        training_truth_df['index'] = training_df['index']\n",
        "        training_truth_df['value'] = resample_df['value'].iloc[\n",
        "                                     offset:n_train + offset:1]\n",
        "        training_truth_df['source'] = 'True Values'\n",
        "\n",
        "        testing_df = pd.DataFrame()\n",
        "       # testing_df['date'] = resample_df_test['date'].iloc[offset:n_test + offset:1]\n",
        "        testing_df['index'] = resample_df_test['index'].iloc[offset:n_test + offset:1]\n",
        "        start=time.time()\n",
        "\n",
        "        testing_predictions = bayesian_lstm.predict(X_test)\n",
        "        end=time.time()\n",
        "        TestingingTime=(end-start)/n_epochs\n",
        "        print(\" Testing Time\", (end-start)/n_epochs,'Signal', name)\n",
        "        TestingTime.append(TestingingTime)\n",
        "\n",
        "        #print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "\n",
        "        \n",
        "                     \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        testing_df['value'] = inverse_transform(testing_predictions)\n",
        "        testing_df['source'] = 'Test Prediction'\n",
        "\n",
        "        testing_truth_df = pd.DataFrame()\n",
        "        #testing_truth_df['date'] = testing_df['date']\n",
        "        testing_truth_df['index'] = testing_df['index']\n",
        "\n",
        "        testing_truth_df['value'] = resample_df_test['value'].iloc[offset:n_test + offset:1]\n",
        "        testing_truth_df['source'] = 'True Values'\n",
        "\n",
        "\n",
        "        evaluation = pd.concat([training_df,\n",
        "                                testing_df,\n",
        "                                training_truth_df,\n",
        "                                testing_truth_df\n",
        "                                ], axis=0)\n",
        "\n",
        "        fig = px.line(evaluation,\n",
        "                             x=\"index\",\n",
        "                              y=\"value\",\n",
        "                              color=\"source\")\n",
        "        #fig.show()\n",
        "\n",
        "        n_experiments = 2\n",
        "        test_uncertainty_df = pd.DataFrame()\n",
        "        #test_uncertainty_df['date'] = testing_df['date']\n",
        "        test_uncertainty_df['index'] = testing_df['index']\n",
        "\n",
        "        for i in range(n_experiments):\n",
        "            experiment_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "            test_uncertainty_df['value_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
        "\n",
        "        log_energy_consumption_df = test_uncertainty_df.filter(like='value', axis=1)\n",
        "        test_uncertainty_df['value_mean'] = log_energy_consumption_df.mean(axis=1)\n",
        "        test_uncertainty_df['value_std'] = log_energy_consumption_df.std(axis=1)\n",
        "\n",
        "\n",
        "        test_uncertainty1 = test_uncertainty_df['value_mean']\n",
        "\n",
        "        #########################Adaptive Smoothing\n",
        "\n",
        "        #   pdb.set_trace()\n",
        "        Threshold = 10\n",
        "        gamma = 0.1\n",
        "        betta = 0.1\n",
        "        test_uncertainty2 = []\n",
        "        ###########\n",
        "        for jj in range(len(test_uncertainty1) - 2):\n",
        "            test_uncertaintyy = (1 / (1 + gamma + betta)) * (\n",
        "                        test_uncertainty1.iloc[jj] + gamma * test_uncertainty1.iloc[jj + 1] + betta *\n",
        "                        test_uncertainty1.iloc[jj + 2])\n",
        "            test_uncertainty2.append(test_uncertaintyy)\n",
        "        test_uncertainty2 = pd.DataFrame(test_uncertainty2)\n",
        "\n",
        "        test_uncertainty2.columns = [\"value_mean\"]\n",
        "\n",
        "\n",
        "        test_uncertainty_df[\"value_mean\"] = test_uncertainty2[\"value_mean\"]\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "\n",
        "        test_uncertainty_df = test_uncertainty_df[['index',  'value_mean', 'value_std']]\n",
        "        test_uncertainty_df['lower_bound'] = test_uncertainty_df['value_mean'] - 5* test_uncertainty_df['value_std']\n",
        "        test_uncertainty_df['upper_bound'] = test_uncertainty_df['value_mean'] + 5 * test_uncertainty_df['value_std']\n",
        "        import plotly.graph_objects as go\n",
        "\n",
        "        test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
        "        # test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
        "        # truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_truth_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "\n",
        "        upper_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['upper_bound'],\n",
        "          mode='lines',\n",
        "         fill=None,\n",
        "         name='99% Upper Confidence Bound'\n",
        "         )\n",
        "        lower_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['lower_bound'],\n",
        "          mode='lines',\n",
        "          fill='tonexty',\n",
        "         name= '99% Lower Confidence Bound',\n",
        "         fillcolor='rgba(255, 211, 0, 0.1)',\n",
        "         )\n",
        "        real_trace = go.Scatter(\n",
        "            x=truth_uncertainty_plot_df['index'],\n",
        "            y=truth_uncertainty_plot_df['value'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='Real Values'\n",
        "        )\n",
        "\n",
        "        labels = go.Scatter(\n",
        "           x=label_data['index'],\n",
        "          y=label_data['value'],\n",
        "         mode='lines',\n",
        "         fill='tonexty' ,\n",
        "         name='labels'\n",
        "         )\n",
        "        data = [upper_trace, lower_trace, real_trace]\n",
        "\n",
        "        fig = go.Figure(data=data)\n",
        "        fig.update_layout(title='Uncertainty MCDropout Test Data',\n",
        "                            xaxis_title='index',\n",
        "                            yaxis_title='value',\n",
        "         legend_font_size=14,\n",
        "                          )\n",
        "        #fig.show()\n",
        "        bounds_df = pd.DataFrame()\n",
        "\n",
        "        # Using 99% confidence bounds\n",
        "        bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
        "        bounds_df['prediction'] = test_uncertainty_plot_df['value_mean']\n",
        "        bounds_df['real_value'] = truth_uncertainty_plot_df['value']\n",
        "        bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
        "\n",
        "        bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
        "                                  (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
        "\n",
        "        print(\"Proportion of points contained within 99% confidence interval:\",\n",
        "              bounds_df['contained'].mean())\n",
        "        predictedanomaly = bounds_df.index[~bounds_df['contained']]\n",
        "\n",
        "        N = 15\n",
        "        newarr = []\n",
        "\n",
        "\n",
        "        for i in range(len(predictedanomaly) - N):\n",
        "            if (predictedanomaly[i] + 1 == predictedanomaly[i + 1] and predictedanomaly[i + 1] + 1 == predictedanomaly[\n",
        "               i + 2] and predictedanomaly[i+3]+1==predictedanomaly[i+4] and predictedanomaly[i+4]+1==predictedanomaly[i+5]\n",
        "                and  predictedanomaly[i+5]+1==predictedanomaly[i+6] and predictedanomaly[i+6]+1==predictedanomaly[i+7]\n",
        "                and predictedanomaly[i+7]+1==predictedanomaly[i+8]\n",
        "                and predictedanomaly[i+8]+1==predictedanomaly[i+9]\n",
        "                and predictedanomaly[i+9]+1==predictedanomaly[i+10]\n",
        "                and predictedanomaly[i+10]+1==predictedanomaly[i+11]\n",
        "                and predictedanomaly[i+11]+1==predictedanomaly[i+12]\n",
        "                and predictedanomaly[i + 12] + 1 == predictedanomaly[i + 13]\n",
        "                and predictedanomaly[i + 13] + 1 == predictedanomaly[i + 14]\n",
        "                and predictedanomaly[i + 14] + 1 == predictedanomaly[i + 15]):\n",
        "\n",
        "                newarr.append(predictedanomaly[i])\n",
        "        #        newarr.append(predictedanomaly[i + 1])\n",
        "         #       newarr.append(predictedanomaly[i + 2])\n",
        "\n",
        "\n",
        "        predicteddanomaly = list(set(newarr))\n",
        "        MSE.append(mean( testing_truth_df['value']-test_uncertainty_df['value_mean'])**2)\n",
        "        print(MSE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        realanomaly = label_data['index']\n",
        "\n",
        "        predicter=list(range(len(test_uncertainty2)))\n",
        "\n",
        "        a1 = pd.DataFrame(index=range(len(test_uncertainty2)),columns=range(2))\n",
        "        a1.columns=['index','value']\n",
        "\n",
        "        a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "        a2.columns = ['index','value']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in predicteddanomaly:\n",
        "                a1.iloc[i,1]=1\n",
        "            else:\n",
        "                a1.iloc[i,1]=0\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in realanomaly:\n",
        "                a2.iloc[i,1] = 1\n",
        "            else:\n",
        "                a2.iloc[i, 1] = 0\n",
        "\n",
        "\n",
        "\n",
        "        y_real=a2.value\n",
        "        y_real=y_real.astype(int)\n",
        "        y_predi=a1.value\n",
        "        y_predi=y_predi.astype(int)\n",
        "\n",
        "\n",
        "        cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "        cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "        #fp = len(predicteddanomaly) - tp\n",
        "        #fn = 0\n",
        "        #tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "        tp=cm[0][0]\n",
        "        fp=cm[0][1]\n",
        "        fn=cm[1][0]\n",
        "        tn=cm[1][1]\n",
        "\n",
        "        precision1 = tp / (tp + fp)\n",
        "        recall1 = tp / (tp + fn)\n",
        "        Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "        F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "        print('precision', precision1, 'Signal', name)\n",
        "        print('recall', recall1, 'Signal', name)\n",
        "        print('Accuracy', Accuracy1, 'Signal', name)\n",
        "        print('F1', F11, 'Signal', name)\n",
        "        precision.append(precision1)\n",
        "        F1.append(F11)\n",
        "        Accuracy.append(Accuracy1)\n",
        "        recall.append(recall1)\n",
        "\n",
        "        im=im+1\n",
        "\n",
        "\n",
        "\n",
        "        #matched_indices = list(i_anom_predicted & true_indices_flat)\n",
        "\n",
        "Calculations['pipline']='Bayesian_LSTM'\n",
        "Calculations['fit_time']=TrainingTime\n",
        "Calculations['prediction_time']=TestingTime\n",
        "\n",
        "#Calculations.iloc['number_of_parameters']=NumberOfTrainableParameters\n",
        "#recall_final=mean(recall)\n",
        "#precision_final=mean(precision)\n",
        "#F1_final=mean(F1)\n",
        "#Accuracy_final=mean(Accuracy)\n",
        "#cm = confusion_matrix(y_true=test_labels, y_pred=predicteddanomaly)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# %%\n",
        "#recall_final=mean(recall)\n",
        "#precision_final=mean(precision)\n",
        "#F1_final=mean(F1)\n",
        "MSE_final=mean(MSE)\n",
        "#Accuracy_final=mean(Accuracy)\n",
        "#print('precision_final', precision_final)\n",
        "#print('recall_final', recall_final)\n",
        "#print('Accuracy_final',Accuracy_final)\n",
        "print('F1_final', F1_final)\n",
        "print('MSE_final', MSE_final)\n",
        "## New Test Bayesian LSTM AE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE1=MSE.copy() \n",
        "import math\n",
        "from math import sqrt\n",
        "newlist = [x for x in MSE1 if math.isnan(x) == False]\n",
        "MSE_final=sqrt(mean(newlist))\n",
        "MSE_final\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLKXZvciLGi6",
        "outputId": "e1a198e3-079c-47a1-fdd9-9f5271e25e4c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21657404427612753"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsMgpb-uGqaJ",
        "outputId": "7e45558a-0b68-4f57-c42f-bb16d370c101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6UxZmkplACZ",
        "outputId": "4fc03112-5844-48fe-c189-0a3b66377f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE_final 0.046904316654118046\n"
          ]
        }
      ],
      "source": [
        "Calculations['pipline']='Bayesian_lstm'\n",
        "MSE_final=mean(MSE)\n",
        "print('MSE_final', MSE_final)\n",
        "import os   \n",
        "Calculations.to_csv('Calculations2.csv')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm1hYBP2qvWA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-npPboAZsJ8o",
        "outputId": "1bfd49a3-1904-4c0d-8c97-5ac6b6e521d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 1.7132806587219238 signal P-1\n",
            "prediction_time 0.003330793380737305 signal P-1\n",
            "Test RMSE: 0.276 signal P-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 3.3255919933319094 signal S-1\n",
            "prediction_time 0.0043089199066162105 signal S-1\n",
            "Test RMSE: 0.379 signal S-1\n",
            "fit_time 1.2583719062805176 signal E-1\n",
            "prediction_time 0.00346003532409668 signal E-1\n",
            "Test RMSE: 0.055 signal E-1\n",
            "fit_time 0.5033388710021973 signal E-2\n",
            "prediction_time 0.001546649932861328 signal E-2\n",
            "Test RMSE: 0.022 signal E-2\n",
            "fit_time 0.9497098541259765 signal E-3\n",
            "prediction_time 0.003185291290283203 signal E-3\n",
            "Test RMSE: 0.154 signal E-3\n",
            "fit_time 2.1476333332061768 signal E-4\n",
            "prediction_time 0.00412419319152832 signal E-4\n",
            "Test RMSE: 0.066 signal E-4\n",
            "fit_time 1.243541316986084 signal E-5\n",
            "prediction_time 0.0032325077056884768 signal E-5\n",
            "Test RMSE: 0.060 signal E-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 1.9264053630828857 signal E-6\n",
            "prediction_time 0.004890375137329102 signal E-6\n",
            "Test RMSE: 0.000 signal E-6\n",
            "fit_time 0.6229221534729004 signal E-7\n",
            "prediction_time 0.0015096664428710938 signal E-7\n",
            "Test RMSE: 0.040 signal E-7\n",
            "fit_time 0.7938701629638671 signal E-8\n",
            "prediction_time 0.0021731376647949217 signal E-8\n",
            "Test RMSE: 0.118 signal E-8\n",
            "fit_time 1.1007671737670899 signal E-9\n",
            "prediction_time 0.0034842300415039063 signal E-9\n",
            "Test RMSE: 0.128 signal E-9\n",
            "fit_time 1.5434263134002686 signal E-10\n",
            "prediction_time 0.003950128555297852 signal E-10\n",
            "Test RMSE: 0.037 signal E-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 1.549003167585893 signal E-11\n",
            "prediction_time 0.003720998764038086 signal E-11\n",
            "Error signal E-11\n",
            "fit_time 1.2363767051696777 signal E-12\n",
            "prediction_time 0.003208494186401367 signal E-12\n",
            "Test RMSE: 0.060 signal E-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 2.9508839225769044 signal E-13\n",
            "prediction_time 0.0040369129180908205 signal E-13\n",
            "Test RMSE: 0.057 signal E-13\n",
            "Error signal A-1\n",
            "fit_time 0.7523034954071045 signal D-1\n",
            "prediction_time 0.0016355609893798828 signal D-1\n",
            "Test RMSE: 0.013 signal D-1\n",
            "fit_time 1.2980569648742675 signal P-2\n",
            "prediction_time 0.0021266937255859375 signal P-2\n",
            "Test RMSE: 0.026 signal P-2\n",
            "fit_time 0.9698953914642334 signal P-3\n",
            "prediction_time 0.0036688327789306642 signal P-3\n",
            "Test RMSE: 0.056 signal P-3\n",
            "Error signal D-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 0.5656251907348633 signal D-3\n",
            "prediction_time 0.002118825912475586 signal D-3\n",
            "Error signal D-3\n",
            "Error signal D-4\n",
            "fit_time 0.8301662158966064 signal A-2\n",
            "prediction_time 0.0034768009185791016 signal A-2\n",
            "Test RMSE: 0.104 signal A-2\n",
            "fit_time 0.8890503406524658 signal A-3\n",
            "prediction_time 0.0032950878143310548 signal A-3\n",
            "Test RMSE: 0.149 signal A-3\n",
            "fit_time 0.8481697368621827 signal A-4\n",
            "prediction_time 0.003493518829345703 signal A-4\n",
            "Test RMSE: 0.154 signal A-4\n",
            "fit_time 0.8733025741577148 signal G-1\n",
            "prediction_time 0.0035264110565185547 signal G-1\n",
            "Test RMSE: 0.305 signal G-1\n",
            "Error signal G-2\n",
            "fit_time 0.538679838180542 signal D-5\n",
            "prediction_time 0.0014812946319580078 signal D-5\n",
            "Error signal D-5\n",
            "fit_time 0.8706652641296386 signal D-6\n",
            "prediction_time 0.002792024612426758 signal D-6\n",
            "Test RMSE: 0.274 signal D-6\n",
            "Error signal D-7\n",
            "fit_time 3.372709560394287 signal F-1\n",
            "prediction_time 0.003978309631347657 signal F-1\n",
            "Test RMSE: 0.224 signal F-1\n",
            "Error signal P-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 0.3610544204711914 signal G-3\n",
            "prediction_time 0.001738290786743164 signal G-3\n",
            "Test RMSE: 0.000 signal G-3\n",
            "fit_time 0.6258530330657959 signal T-1\n",
            "prediction_time 0.0016065597534179687 signal T-1\n",
            "Test RMSE: 0.031 signal T-1\n",
            "fit_time 0.6755908584594726 signal T-2\n",
            "prediction_time 0.00155670166015625 signal T-2\n",
            "Test RMSE: 0.034 signal T-2\n",
            "Error signal D-8\n",
            "Error signal D-9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 2.728899507522583 signal F-2\n",
            "prediction_time 0.003965206146240234 signal F-2\n",
            "Test RMSE: 0.055 signal F-2\n",
            "fit_time 1.2704098987579346 signal G-4\n",
            "prediction_time 0.002498922348022461 signal G-4\n",
            "Test RMSE: 0.001 signal G-4\n",
            "fit_time 1.618425121307373 signal T-3\n",
            "prediction_time 0.004546709060668945 signal T-3\n",
            "Test RMSE: 0.001 signal T-3\n",
            "Error signal D-11\n",
            "Error signal D-12\n",
            "Error signal B-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 0.6208767890930176 signal G-6\n",
            "prediction_time 0.0017113685607910156 signal G-6\n",
            "Error signal G-6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 1.0722429370880127 signal G-7\n",
            "prediction_time 0.0035628318786621095 signal G-7\n",
            "Test RMSE: 0.013 signal G-7\n",
            "fit_time 0.8981855487823487 signal P-7\n",
            "prediction_time 0.0030879974365234375 signal P-7\n",
            "Test RMSE: 0.067 signal P-7\n",
            "Error signal R-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 0.39312106132507324 signal A-5\n",
            "prediction_time 0.0017525959014892578 signal A-5\n",
            "Test RMSE: 0.000 signal A-5\n",
            "fit_time 0.8048231506347656 signal A-6\n",
            "prediction_time 0.0017430496215820313 signal A-6\n",
            "Test RMSE: 0.198 signal A-6\n",
            "Error signal A-7\n",
            "Error signal D-13\n",
            "fit_time 1.2838919258117676 signal P-2\n",
            "prediction_time 0.001996622085571289 signal P-2\n",
            "Test RMSE: 0.026 signal P-2\n",
            "Error signal A-8\n",
            "Error signal A-9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 0.5120196342468262 signal F-3\n",
            "prediction_time 0.0024671554565429688 signal F-3\n",
            "Error signal F-3\n",
            "MSE_final 0.5426334643017061\n"
          ]
        }
      ],
      "source": [
        "import pdb\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "import statistics\n",
        "pipeline = 'arima'\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "logging.getLogger().setLevel(level=logging.ERROR)\n",
        "warnings.simplefilter(\"ignore\")\n",
        "SIGNALS = [\n",
        "    'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11', 'D-12', 'B-1', 'G-6', 'G-7', 'P-7',\n",
        "    'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3', 'M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8'\n",
        "]\n",
        "SMAP=[  'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
        "    'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
        "    'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
        "    'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
        "    'F-2', 'G-4', 'T-3', 'D-11', 'D-12', 'B-1', 'G-6', 'G-7', 'P-7',\n",
        "    'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3']\n",
        "\n",
        "\n",
        "\n",
        "MSL=['M-6',\n",
        "    'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4',\n",
        "    'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14',\n",
        "    'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8']\n",
        "\n",
        "append_train='-train'\n",
        "append_test='-test'\n",
        "append_new='-new'\n",
        "training = [sub+append_train for sub in SMAP]\n",
        "\n",
        "\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "#from fitter import Fitter, get_common_distributions, get_distributions\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#SMAP=pd.Series(SMAP)\n",
        "#MSL=pd.Series(MSL)\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "avg=[]\n",
        "train_signals=SMAP\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "MSE=[]\n",
        "df_label=df_label[df_label['chan_id'].isin(SMAP)]\n",
        "\n",
        "df_label=df_label.reset_index(drop=True)\n",
        "TrainingTime=[]\n",
        "TestingTime=[]\n",
        "signal='S-1'\n",
        "NumberOfParameters=[]\n",
        "RMSE=[]\n",
        "#import autopep8\n",
        "\n",
        "Train_t=[]\n",
        "Predict_t=[]\n",
        "counter=0\n",
        "for signal in SMAP:\n",
        "  train_np = np.load('data/train/' + signal + '.npy')\n",
        "  test_np = np.load('data/test/' + signal + '.npy')\n",
        "  train =train_np[:,0]\n",
        "  test  = test_np[:,0]\n",
        "  # order = (p=1, d=1, q=1)\n",
        "  history = [x for x in train]\n",
        "  predictions = list()\n",
        "  # walk-forward validation\n",
        "  T_fit=[]\n",
        "  T_pred=[]\n",
        "\n",
        "  for t in range(25):\n",
        "    try:\n",
        "     model = ARIMA(history, order=(2,1,2))\n",
        "\n",
        "     start = time.time()\n",
        "     model_fit = model.fit()\n",
        "     end=time.time()\n",
        "     T_fit.append(end-start)\n",
        "\n",
        "    \n",
        "     start=time.time()\n",
        "     output = model_fit.forecast()\n",
        "     end=time.time()\n",
        "     T_pred.append(end-start)\n",
        "     yhat = output[0].item()\n",
        "     predictions.append(yhat)\n",
        "     obs = test[t]\n",
        "    \n",
        "    \n",
        "     history.append(obs)\n",
        "    except:\n",
        "      counter=counter+1\n",
        "      pass\n",
        "\n",
        "  try:    \n",
        "   T11=mean(T_fit)\n",
        "   T12=mean(T_pred)\n",
        " \n",
        "   print(\"fit_time\",T11,'signal',signal)\n",
        "   print(\"prediction_time\",T12,'signal',signal)\n",
        "\n",
        "  #print('predicted=%f, expected=%f' % (yhat, obs))\n",
        "  #print(model_fit.maparams)\n",
        "  #pdb.set_trace()\n",
        "   rmse = sqrt(mean_squared_error(test[0:25], predictions))\n",
        "   print('Test RMSE: %.3f' % rmse,'signal',signal)\n",
        "   RMSE.append(sqrt(rmse))\n",
        "   \n",
        "   Train_t.append( T11)\n",
        "   Predict_t.append(T12)\n",
        "  except:\n",
        "   rmse = 1\n",
        "   print('Error signal',signal)\n",
        "   RMSE.append(sqrt(rmse))\n",
        "  # plot forecasts against actual outcomes\n",
        "  #pyplot.plot(test)\n",
        "#pyplot.plot(predictions, color='red')\n",
        "#pyplot.show()\n",
        "#end=time.time()\n",
        "# Make as pandas series\n",
        "#result = model.get_forecast()\n",
        "df_SMAP=pd.DataFrame()\n",
        "df_SMAP['fit_time']=Train_t\n",
        "df_SMAP['Prediction_time']=Predict_t\n",
        "df_SMAP['pipline']='Arima'\n",
        "from math import sqrt\n",
        "MSE_final=mean(RMSE)\n",
        "print('MSE_final', MSE_final)\n",
        "import os   \n",
        "df_SMAP.to_csv('ARIMA_SMAP.csv')  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean(df_SMAP.fit_time))\n",
        "print(mean(df_SMAP.Prediction_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5R0na2ftlOD",
        "outputId": "d5cbedf8-60c6-4f30-86cf-84a61691bec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2868510804456823\n",
            "0.003014413609224207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(SMAP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZupi6NvFuc",
        "outputId": "5ecf77f7-8350-4e33-9366-227e756cd0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "#from fitter import Fitter, get_common_distributions, get_distributions\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#SMAP=pd.Series(SMAP)\n",
        "#MSL=pd.Series(MSL)\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "avg=[]\n",
        "train_signals=MSL\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "MSE=[]\n",
        "df_label=df_label[df_label['chan_id'].isin(MSL)]\n",
        "\n",
        "df_label=df_label.reset_index(drop=True)\n",
        "TrainingTime=[]\n",
        "TestingTime=[]\n",
        "signal='S-1'\n",
        "NumberOfParameters=[]\n",
        "RMSE=[]\n",
        "#import autopep8\n",
        "\n",
        "Train_t=[]\n",
        "Predict_t=[]\n",
        "counter=0\n",
        "for signal in MSL:\n",
        "  train_np = np.load('data/train/' + signal + '.npy')\n",
        "  test_np = np.load('data/test/' + signal + '.npy')\n",
        "  train =train_np[:,0]\n",
        "  test  = test_np[:,0]\n",
        "  # order = (p=1, d=1, q=1)\n",
        "  history = [x for x in train]\n",
        "  predictions = list()\n",
        "  # walk-forward validation\n",
        "  T_fit=[]\n",
        "  T_pred=[]\n",
        "\n",
        "  for t in range(25):\n",
        "    try:\n",
        "     model = ARIMA(history, order=(3,1,8))\n",
        "\n",
        "     start = time.time()\n",
        "     model_fit = model.fit()\n",
        "     end=time.time()\n",
        "     T_fit.append(end-start)\n",
        "\n",
        "    \n",
        "     start=time.time()\n",
        "     output = model_fit.forecast()\n",
        "     end=time.time()\n",
        "     T_pred.append(end-start)\n",
        "     yhat = output[0].item()\n",
        "     predictions.append(yhat)\n",
        "     obs = test[t]\n",
        "    \n",
        "    \n",
        "     history.append(obs)\n",
        "    except:\n",
        "      counter=counter+1\n",
        "      pass\n",
        "\n",
        "  try:    \n",
        "   T11=mean(T_fit)\n",
        "   T12=mean(T_pred)\n",
        " \n",
        "   print(\"fit_time\",T11,'signal',signal)\n",
        "   print(\"prediction_time\",T12,'signal',signal)\n",
        "\n",
        "  #print('predicted=%f, expected=%f' % (yhat, obs))\n",
        "  #print(model_fit.maparams)\n",
        "  #pdb.set_trace()\n",
        "   rmse = sqrt(mean_squared_error(test[0:25], predictions))\n",
        "   print('Test RMSE: %.3f' % rmse,'signal',signal)\n",
        "   RMSE.append(sqrt(rmse))\n",
        "   \n",
        "   Train_t.append( T11)\n",
        "   Predict_t.append(T12)\n",
        "  except:\n",
        "   rmse = 1\n",
        "   print('Error signal',signal)\n",
        "   RMSE.append(sqrt(rmse))\n",
        "  # plot forecasts against actual outcomes\n",
        "  #pyplot.plot(test)\n",
        "#pyplot.plot(predictions, color='red')\n",
        "#pyplot.show()\n",
        "#end=time.time()\n",
        "# Make as pandas series\n",
        "#result = model.get_forecast()\n",
        "df_MSL=pd.DataFrame()\n",
        "df_MSL['fit_time']=Train_t\n",
        "df_MSL['Prediction_time']=Predict_t\n",
        "df_MSL['pipline']='Arima'\n",
        "from math import sqrt\n",
        "MSE_final=mean(RMSE)\n",
        "print('MSE_final', MSE_final)\n",
        "import os   \n",
        "df_MSL.to_csv('ARIMA_MSL.csv')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvqJeR1qpxcX",
        "outputId": "0780fc80-c948-40e0-ca06-d50bae8e6573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error signal M-6\n",
            "Error signal M-1\n",
            "Error signal M-2\n",
            "Error signal S-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 17.743872079849243 signal P-10\n",
            "prediction_time 0.021655302047729492 signal P-10\n",
            "Test RMSE: 0.001 signal P-10\n",
            "fit_time 15.793594274520874 signal T-4\n",
            "prediction_time 0.00856522560119629 signal T-4\n",
            "Test RMSE: 0.390 signal T-4\n",
            "Error signal T-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 77.06782509803772 signal F-7\n",
            "prediction_time 0.014726800918579102 signal F-7\n",
            "Test RMSE: 0.220 signal F-7\n",
            "Error signal M-3\n",
            "fit_time 8.584167985916137 signal M-4\n",
            "prediction_time 0.006396150588989258 signal M-4\n",
            "Test RMSE: 0.288 signal M-4\n",
            "fit_time 42.80859560012817 signal M-5\n",
            "prediction_time 0.00919708251953125 signal M-5\n",
            "Test RMSE: 0.163 signal M-5\n",
            "Error signal P-15\n",
            "Error signal C-1\n",
            "Error signal C-2\n",
            "Error signal T-12\n",
            "Error signal T-13\n",
            "Error signal F-4\n",
            "Error signal F-5\n",
            "Error signal D-14\n",
            "Error signal T-9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 12.04100227355957 signal P-14\n",
            "prediction_time 0.015610218048095703 signal P-14\n",
            "Error signal P-14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 20.604829111099242 signal T-8\n",
            "prediction_time 0.007079067230224609 signal T-8\n",
            "Test RMSE: 0.305 signal T-8\n",
            "Error signal P-11\n",
            "fit_time 24.61271692276001 signal D-15\n",
            "prediction_time 0.007011814117431641 signal D-15\n",
            "Test RMSE: 0.686 signal D-15\n",
            "Error signal D-16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
            "  'available', HessianInversionWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time 56.9299391746521 signal M-7\n",
            "prediction_time 0.010828866958618164 signal M-7\n",
            "Test RMSE: 0.004 signal M-7\n",
            "Error signal F-8\n",
            "MSE_final 0.8334442615922236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean(df_MSL.fit_time))\n",
        "print(mean(df_MSL.Prediction_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZhzZpWYcZw1",
        "outputId": "6f0178ca-b5fd-4fed-fbec-e2cc0f1b7492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8294272035360337\n",
            "0.004618970155715943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr3CXoEciX7n",
        "outputId": "9a92ab13-e5bb-4a6b-922b-f46991cf939f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          Results: ARIMA\n",
            "===================================================================\n",
            "Model:              ARIMA            BIC:                 3752.9220\n",
            "Dependent Variable: D2.y             Log-Likelihood:      -1844.7  \n",
            "Date:               2022-05-30 21:42 Scale:               1.0000   \n",
            "No. Observations:   2817             Method:              css-mle  \n",
            "Df Model:           7                Sample:              2        \n",
            "Df Residuals:       2810                                  9        \n",
            "Converged:          1.0000           S.D. of innovations: 0.465    \n",
            "No. Iterations:     46.0000          HQIC:                3722.532 \n",
            "AIC:                3705.3745                                      \n",
            "--------------------------------------------------------------------\n",
            "              Coef.   Std.Err.      t       P>|t|    [0.025   0.975]\n",
            "--------------------------------------------------------------------\n",
            "const         0.0000    0.0000      0.0625  0.9502  -0.0000   0.0000\n",
            "ar.L1.D2.y   -0.9446    0.0188    -50.2449  0.0000  -0.9815  -0.9078\n",
            "ar.L2.D2.y   -0.6884    0.0251    -27.4667  0.0000  -0.7375  -0.6393\n",
            "ar.L3.D2.y   -0.4269    0.0270    -15.7900  0.0000  -0.4799  -0.3739\n",
            "ar.L4.D2.y   -0.3463    0.0251    -13.8130  0.0000  -0.3954  -0.2972\n",
            "ar.L5.D2.y   -0.0661    0.0188     -3.5126  0.0005  -0.1030  -0.0292\n",
            "ma.L1.D2.y   -1.0000    0.0009  -1144.4231  0.0000  -1.0017  -0.9983\n",
            "----------------------------------------------------------------------------\n",
            "                Real           Imaginary          Modulus          Frequency\n",
            "----------------------------------------------------------------------------\n",
            "AR.1           0.4734            -1.3587           1.4388            -0.1966\n",
            "AR.2           0.4734             1.3587           1.4388             0.1966\n",
            "AR.3          -1.0250            -0.8465           1.3293            -0.3901\n",
            "AR.4          -1.0250             0.8465           1.3293             0.3901\n",
            "AR.5          -4.1335            -0.0000           4.1335            -0.5000\n",
            "MA.1           1.0000             0.0000           1.0000             0.0000\n",
            "===================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model_fit.summary2())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki9doO21uRlK"
      },
      "outputs": [],
      "source": [
        "for name in MSL:\n",
        "        label_row=df_label[df_label.chan_id==name]\n",
        "        #pdb.set_trace()\n",
        "     \n",
        "        labels= label_row.anomaly_sequences[im]\n",
        "        labels=eval(labels)\n",
        "      \n",
        "        true_indices_grouped = [list(range(e[0], e[1]+1)) for e in labels]\n",
        "        true_indices_flat = set([i for group in true_indices_grouped for i in group])\n",
        "\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "    \n",
        "        labels= true_indices_flat\n",
        "       \n",
        "\n",
        "       # for i in range(len(labels)):\n",
        "        #    anom=labels[i]\n",
        "            #start=anom[0]\n",
        "            #end=anom[1]\n",
        "\n",
        "        index = list(labels)\n",
        "\n",
        "       # timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "        anomalies=pd.DataFrame({'value': 1, 'index':index})\n",
        "       #     appended_data.append(anomalies)\n",
        "\n",
        "        label_data = anomalies\n",
        "\n",
        "        #label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        #label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data ['name'] = name\n",
        "        #label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        #label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index',  'name']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "       # plot_length = 1000000\n",
        "        #plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        #plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index',  'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqfw3LO6fHvL"
      },
      "source": [
        "##Results For MSL Signals\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFYo86Hcoelc"
      },
      "source": [
        "MCD-SMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25ayEFyn5dd",
        "outputId": "faf62b69-2357-406b-8e9e-807575ca1720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.045960117131471634\n",
            "Training_time 5.097353935241699 signal P-1\n",
            "Test_time 5.503154754638672 signal P-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.04755738669805768\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.11617942154407501\n",
            "Training_time 4.097381281852722 signal S-1\n",
            "Test_time 4.574758768081665 signal S-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.002458680508127305\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.26880523562431335\n",
            "Training_time 4.227539539337158 signal E-1\n",
            "Test_time 4.750142574310303 signal E-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.11475009471178055\n",
            "Training_time 4.15932331085205 signal E-2\n",
            "Test_time 4.7802441120147705 signal E-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.025986159220337868\n",
            "Training_time 4.265942502021789 signal E-3\n",
            "Test_time 5.363836765289307 signal E-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.04916832596063614\n",
            "Training_time 4.211419486999512 signal E-4\n",
            "Test_time 4.811527490615845 signal E-4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.009348034515819751\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.26690003275871277\n",
            "Training_time 4.173446726799011 signal E-5\n",
            "Test_time 4.611812114715576 signal E-5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.1704988330602646\n",
            "Training_time 4.238335514068604 signal E-6\n",
            "Test_time 4.732482433319092 signal E-6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.10709930956363678\n",
            "Training_time 4.058345484733581 signal E-7\n",
            "Test_time 4.821646451950073 signal E-7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.06709341704845428\n",
            "Training_time 4.206775546073914 signal E-8\n",
            "Test_time 4.860092639923096 signal E-8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.08413517953532035\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.030295129865407944\n",
            "Training_time 4.171005988121033 signal E-9\n",
            "Test_time 4.761544466018677 signal E-9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.2647383511066437\n",
            "Training_time 4.190847086906433 signal E-10\n",
            "Test_time 4.854567527770996 signal E-10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.26577848196029663\n",
            "Training_time 4.2128965854644775 signal E-11\n",
            "Test_time 4.221667051315308 signal E-11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.025634995296331137\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.26932111382484436\n",
            "Training_time 4.143998908996582 signal E-12\n",
            "Test_time 4.851008892059326 signal E-12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.09049548208713531\n",
            "Training_time 4.1224346399307255 signal E-13\n",
            "Test_time 4.818917512893677 signal E-13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0030127462340672076\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  1.6343280151431827e-07\n",
            "Training_time 4.155686450004578 signal A-1\n",
            "Test_time 4.850998878479004 signal A-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.3089223638470452\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.04428974911570549\n",
            "Training_time 4.1082051515579225 signal D-1\n",
            "Test_time 4.734432220458984 signal D-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.06847864454641722\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0563574880361557\n",
            "Training_time 4.05130627155304 signal P-2\n",
            "Test_time 4.5890960693359375 signal P-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.028174167581412366\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.013917886652052402\n",
            "Training_time 4.106791424751282 signal P-3\n",
            "Test_time 4.669802665710449 signal P-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.6445832842154898\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  2.1581664100267517e-07\n",
            "Training_time 4.1842361211776735 signal D-2\n",
            "Test_time 4.750524997711182 signal D-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.48107163657542223\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.19668026268482208\n",
            "Training_time 4.177355718612671 signal D-3\n",
            "Test_time 4.774301290512085 signal D-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.00011587485515643106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.28576722741127014\n",
            "Training_time 4.109991598129272 signal D-4\n",
            "Test_time 4.688608884811401 signal D-4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.07601357996463776\n",
            "Training_time 3.873866653442383 signal A-2\n",
            "Test_time 4.593359470367432 signal A-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.13575404858299595\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.04510154947638512\n",
            "Training_time 3.993619990348816 signal A-3\n",
            "Test_time 4.636345148086548 signal A-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.25210494203782796\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.02600671537220478\n",
            "Training_time 3.9249138593673707 signal A-4\n",
            "Test_time 4.697329521179199 signal A-4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.2174721189591078\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.07939881086349487\n",
            "Training_time 4.0729857921600345 signal G-1\n",
            "Test_time 4.739946603775024 signal G-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.021515545572762737\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  4.4920241748513945e-07\n",
            "Training_time 3.609273171424866 signal G-2\n",
            "Test_time 4.490632057189941 signal G-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8706298462794178\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.05131690204143524\n",
            "Training_time 3.712923264503479 signal D-5\n",
            "Test_time 4.645050764083862 signal D-5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.07411163300275803\n",
            "Training_time 3.774482989311218 signal D-6\n",
            "Test_time 4.58955192565918 signal D-6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  2.24454108632699e-08\n",
            "Training_time 3.709617829322815 signal D-7\n",
            "Test_time 4.553883075714111 signal D-7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5628930817610063\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.028180673718452454\n",
            "Training_time 4.099403190612793 signal F-1\n",
            "Test_time 4.731045246124268 signal F-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0013995801259622112\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  9.683350299383164e-08\n",
            "Training_time 3.7226229667663575 signal P-4\n",
            "Test_time 4.533545970916748 signal P-4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8562974398559114\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0037497414741665125\n",
            "Training_time 3.7912297010421754 signal G-3\n",
            "Test_time 4.6626105308532715 signal G-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8328479169304799\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.1555534452199936\n",
            "Training_time 4.112932300567627 signal T-1\n",
            "Test_time 4.773932456970215 signal T-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.3890955591722855\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0476975180208683\n",
            "Training_time 4.130943608283997 signal T-2\n",
            "Test_time 4.774713039398193 signal T-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.40928612884503773\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  1.5451131218924274e-07\n",
            "Training_time 3.758453941345215 signal D-8\n",
            "Test_time 4.546384334564209 signal D-8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8786876907426246\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  2.7659328338813793e-07\n",
            "Training_time 3.7239542245864867 signal D-9\n",
            "Test_time 4.374814748764038 signal D-9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7436452136289886\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.04045698046684265\n",
            "Training_time 4.11254916191101 signal F-2\n",
            "Test_time 4.764830589294434 signal F-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.02007892293407614\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.32019656896591187\n",
            "Training_time 3.678326201438904 signal G-4\n",
            "Test_time 4.545106649398804 signal G-4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.049855680923642086\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.07925418764352798\n",
            "Training_time 4.125994491577148 signal T-3\n",
            "Test_time 4.7386391162872314 signal T-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.06955304002800794\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.3625360429286957\n",
            "Training_time 5.129716181755066 signal D-11\n",
            "Test_time 6.604388236999512 signal D-11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.00011359126801835373\n",
            "Training_time 0.4472106695175171 signal D-12\n",
            "Test_time 4.543307781219482 signal D-12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5918057663125948\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  1.67407790740981e-07\n",
            "Training_time 6.817437267303466 signal B-1\n",
            "Test_time 7.6318910121917725 signal B-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5529001742593975\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.2063549906015396\n",
            "Training_time 5.584459376335144 signal G-6\n",
            "Test_time 7.334317922592163 signal G-6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:609: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  0.001638749847188592\n",
            "Training_time 3.6773515701293946 signal G-7\n",
            "Test_time 4.859942197799683 signal G-7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7919940142162364\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.005258490797132254\n",
            "Training_time 4.172244763374328 signal P-7\n",
            "Test_time 4.835636138916016 signal P-7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.33916387544969606\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  2.07596499990359e-07\n",
            "Training_time 5.5733771324157715 signal R-1\n",
            "Test_time 4.419309854507446 signal R-1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.44138789051700306\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.034586139023303986\n",
            "Training_time 1.4231541633605957 signal A-5\n",
            "Test_time 7.0201194286346436 signal A-5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.00042707666026051675\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.24571391940116882\n",
            "Training_time 1.6089715480804443 signal A-6\n",
            "Test_time 5.026083707809448 signal A-6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0009002925950934053\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.03123452141880989\n",
            "Training_time 6.180242657661438 signal A-7\n",
            "Test_time 7.418395757675171 signal A-7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.01751536944669992\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  2.6608390726323705e-06\n",
            "Training_time 2.2459834098815916 signal D-13\n",
            "Test_time 4.7139363288879395 signal D-13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5757219391088462\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.05707330256700516\n",
            "Training_time 4.486339259147644 signal P-2\n",
            "Test_time 5.561587333679199 signal P-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.024881083058909622\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.08735118061304092\n",
            "Training_time 1.0929838418960571 signal A-8\n",
            "Test_time 4.846390724182129 signal A-8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.5000597728631201\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.15432997047901154\n",
            "Training_time 1.1012699365615846 signal A-9\n",
            "Test_time 4.914627552032471 signal A-9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.2060778727445394\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.11983682215213776\n",
            "Training_time 4.100517201423645 signal F-3\n",
            "Test_time 4.86653733253479 signal F-3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.3582357159933062\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "seed=42\n",
        "torch.backends.cudnn.determinestic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "       \n",
        "  \n",
        "def build_df(data, start=0):\n",
        "#\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
        "class MCD_AE(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, output_length, batch_size):\n",
        "        super(MCD_AE, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size  # user-defined\n",
        "\n",
        "        self.hidden_size_1 = 128\n",
        "        self.hidden_size_2 = 64\n",
        "        self.hidden_size_3= 16\n",
        "        self.hidden_size_4 = 64\n",
        "        self.stacked_layers = 3\n",
        "        self.dropout_probability = 0.5  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "\n",
        "\n",
        "        self.lstm1 = nn.LSTM(n_features,\n",
        "                             self.hidden_size_1,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
        "                             self.hidden_size_2,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(self.hidden_size_2,\n",
        "                             self.hidden_size_3,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(self.hidden_size_3,\n",
        "                             self.hidden_size_4,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_size_4, output_length)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        hidden = self.init_hidden1(batch_size)\n",
        "\n",
        "        output, _ = self.lstm1(x, hidden)\n",
        "\n",
        "        #output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        state = self.init_hidden2(batch_size)\n",
        "        output, state = self.lstm2(output, state)\n",
        "        state = self.init_hidden3(batch_size)\n",
        "        output, state = self.lstm3(output, state)\n",
        "        state = self.init_hidden4(batch_size)\n",
        "        output, state = self.lstm4(output, state)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        output = output[:, -1, :]  # take the last decoder cell's outputs\n",
        "        y_pred = self.fc(output)\n",
        "        return y_pred\n",
        "\n",
        "    def init_hidden1(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        return hidden_state, cell_state\n",
        "    def init_hidden3(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_3))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_3))\n",
        "        return hidden_state, cell_state\n",
        "    def init_hidden4(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_4))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_4))\n",
        "        return hidden_state, cell_state\n",
        "    def loss(self, pred, truth):\n",
        "        return self.loss_fn(pred, truth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "SMAP=pd.Series(SMAP)\n",
        "MSL=pd.Series(MSL)\n",
        "\n",
        "#pdb.set_trace()\n",
        "avg=[]\n",
        "train_signals=SMAP\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "T=[]\n",
        "T2=[]\n",
        "for name in SMAP:\n",
        "\n",
        "        label_row = df_label[df_label.chan_id == name]\n",
        "    # pdb.set_trace()\n",
        "\n",
        "        labels = label_row.anomaly_sequences[im]\n",
        "        labels = eval(labels)\n",
        "\n",
        "        true_indices_grouped = [list(range(e[0], e[1] + 1)) for e in labels]\n",
        "        true_indices_flat = set([i for group in true_indices_grouped for i in group])\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "        labels = true_indices_flat\n",
        "\n",
        "    # for i in range(len(labels)):\n",
        "    #    anom=labels[i]\n",
        "    # start=anom[0]\n",
        "    # end=anom[1]\n",
        "\n",
        "        index = list(labels)\n",
        "\n",
        "    # timestamp = index * 86400 + 1022819200\n",
        "\n",
        "        anomalies = pd.DataFrame({'value': 1, 'index': index})\n",
        "    #     appended_data.append(anomalies)\n",
        "\n",
        "        label_data = anomalies\n",
        "\n",
        "    # label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "    # label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data['name'] = name\n",
        "    # label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "    # label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "\n",
        "\n",
        "        #label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        #label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        label_data ['name'] = name\n",
        "        #label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        #label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index', 'name']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "        plot_length = 1000000\n",
        "        plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        #plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index', 'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 10\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)\n",
        "\n",
        "        #sns.displot(data=y_test,  kind=\"hist\", bins=100, aspect=1.5)\n",
        "      #  plt.show()\n",
        "       # pdb.set_trace()\n",
        "\n",
        "        #f = Fitter(y_train,\n",
        "         #          distributions=['gamma',\n",
        "          #                        'lognorm',\n",
        "           #                       \"beta\",\n",
        "            #                      \"burr\",\n",
        "             #                     \"norm\",'cauchy', 'chi2', 'expon', 'exponpow', 'powerlaw', 'rayleigh', 'uniform'])\n",
        "        #f.fit()\n",
        "        #f.summary()\n",
        "        #pdb.set_trace()\n",
        "        n_features = scaled_array.shape[-1]\n",
        "        sequence_length = 10\n",
        "        output_length = 1\n",
        "\n",
        "        batch_size = 64\n",
        "        n_epochs = 10\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        bayesian_lstm = MCD_AE(n_features=n_features,\n",
        "                                     output_length=output_length,\n",
        "                                     batch_size=batch_size)\n",
        "        model_parameters = filter(lambda p: p.requires_grad, bayesian_lstm.parameters())\n",
        "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        print(\"total_parameters\", params)\n",
        "\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)\n",
        "        bayesian_lstm.train()\n",
        "        start=time.time()\n",
        "\n",
        "        for e in range(1, n_epochs + 1):\n",
        "            for b in range(0, len(X_train), batch_size):\n",
        "                features = X_train[b:b + batch_size, :, :]\n",
        "                target = y_train[b:b + batch_size]\n",
        "\n",
        "                X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "                y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "                # pdb.set_trace()\n",
        "              \n",
        "               \n",
        "\n",
        "                output = bayesian_lstm(X_batch)\n",
        "                loss = criterion(output.view(-1), y_batch)\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print('epoch', e, 'loss: ', loss.item())\n",
        "                offset = sequence_length\n",
        "        end=time.time()        \n",
        "        T.append((end-start)/n_epochs)\n",
        "        print('Training_time',(end-start)/n_epochs,'signal', name)\n",
        "\n",
        "\n",
        "        training_df = pd.DataFrame()\n",
        "       # training_df['date'] = resample_df['date'].iloc[offset:n_train + offset:1]\n",
        "        training_df['index'] = resample_df['index'].iloc[offset:n_train + offset:1]\n",
        "        training_predictions = bayesian_lstm.predict(X_train)\n",
        "\n",
        "\n",
        "        training_df['value'] = inverse_transform(training_predictions)\n",
        "        training_df['source'] = 'Training Prediction'\n",
        "\n",
        "\n",
        "        #training_truth_df['date'] = training_df['date']\n",
        "        training_truth_df['index'] = training_df['index']\n",
        "        training_truth_df['value'] = resample_df['value'].iloc[\n",
        "                                     offset:n_train + offset:1]\n",
        "        training_truth_df['source'] = 'True Values'\n",
        "\n",
        "        testing_df = pd.DataFrame()\n",
        "        #testing_df['date'] = resample_df_test['date'].iloc[offset:n_test + offset:1]\n",
        "        testing_df['index'] = resample_df_test['index'].iloc[offset:n_test + offset:1]\n",
        "        start=time.time()\n",
        "\n",
        "        testing_predictions = bayesian_lstm.predict(X_test)\n",
        "        end=time.time()\n",
        "        T2.append((end-start))\n",
        "        print('Test_time',(end-start),'signal', name)\n",
        "\n",
        "        testing_df['value'] = inverse_transform(testing_predictions)\n",
        "        testing_df['source'] = 'Test Prediction'\n",
        "\n",
        "        testing_truth_df = pd.DataFrame()\n",
        "        #testing_truth_df['date'] = testing_df['date']\n",
        "        testing_truth_df['index'] = testing_df['index']\n",
        "\n",
        "        testing_truth_df['value'] = resample_df_test['value'].iloc[offset:n_test + offset:1]\n",
        "        testing_truth_df['source'] = 'True Values'\n",
        "\n",
        "\n",
        "        evaluation = pd.concat([training_df,\n",
        "                                testing_df,\n",
        "                                training_truth_df,\n",
        "                                testing_truth_df\n",
        "                                ], axis=0)\n",
        "\n",
        "        fig = px.line(evaluation,\n",
        "                             x=\"index\",\n",
        "                              y=\"value\",\n",
        "                              color=\"source\")\n",
        "        #fig.show()\n",
        "\n",
        "        n_experiments = 2\n",
        "        test_uncertainty_df = pd.DataFrame()\n",
        "        #test_uncertainty_df['date'] = testing_df['date']\n",
        "        test_uncertainty_df['index'] = testing_df['index']\n",
        "\n",
        "        for i in range(n_experiments):\n",
        "            experiment_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "            test_uncertainty_df['value_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
        "\n",
        "        log_energy_consumption_df = test_uncertainty_df.filter(like='value', axis=1)\n",
        "        test_uncertainty_df['value_mean'] = log_energy_consumption_df.mean(axis=1)\n",
        "        test_uncertainty_df['value_std'] = log_energy_consumption_df.std(axis=1)\n",
        "\n",
        "\n",
        "        test_uncertainty1 = test_uncertainty_df['value_mean']\n",
        "\n",
        "        #########################Adaptive Smoothing\n",
        "\n",
        "        #   pdb.set_trace()\n",
        "        Threshold = 10\n",
        "        gamma = 0.1\n",
        "        betta = 0.1\n",
        "        test_uncertainty2 = []\n",
        "        ###########\n",
        "        for jj in range(len(test_uncertainty1) - 2):\n",
        "            test_uncertaintyy = (1 / (1 + gamma + betta)) * (\n",
        "                        test_uncertainty1.iloc[jj] + gamma * test_uncertainty1.iloc[jj + 1] + betta *\n",
        "                        test_uncertainty1.iloc[jj + 2])\n",
        "            test_uncertainty2.append(test_uncertaintyy)\n",
        "        test_uncertainty2 = pd.DataFrame(test_uncertainty2)\n",
        "\n",
        "        test_uncertainty2.columns = [\"value_mean\"]\n",
        "\n",
        "\n",
        "        test_uncertainty_df[\"value_mean\"] = test_uncertainty2[\"value_mean\"]\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "\n",
        "        test_uncertainty_df = test_uncertainty_df[['index',  'value_mean', 'value_std']]\n",
        "        test_uncertainty_df['lower_bound'] = test_uncertainty_df['value_mean'] - 3* test_uncertainty_df['value_std']\n",
        "        test_uncertainty_df['upper_bound'] = test_uncertainty_df['value_mean'] + 3 * test_uncertainty_df['value_std']\n",
        "        import plotly.graph_objects as go\n",
        "\n",
        "        test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
        "        # test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
        "        # truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_truth_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "\n",
        "        upper_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['upper_bound'],\n",
        "          mode='lines',\n",
        "         fill=None,\n",
        "         name='99% Upper Confidence Bound'\n",
        "         )\n",
        "        lower_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['lower_bound'],\n",
        "          mode='lines',\n",
        "          fill='tonexty',\n",
        "         name= '99% Lower Confidence Bound',\n",
        "         fillcolor='rgba(255, 211, 0, 0.1)',\n",
        "         )\n",
        "        real_trace = go.Scatter(\n",
        "            x=truth_uncertainty_plot_df['index'],\n",
        "            y=truth_uncertainty_plot_df['value'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='Real Values'\n",
        "        )\n",
        "\n",
        "        labels = go.Scatter(\n",
        "           x=label_data['index'],\n",
        "          y=label_data['value'],\n",
        "         mode='lines',\n",
        "         fill='tonexty' ,\n",
        "         name='labels'\n",
        "         )\n",
        "        data = [upper_trace, lower_trace, real_trace]\n",
        "\n",
        "        fig = go.Figure(data=data)\n",
        "        fig.update_layout(title='Uncertainty MCDropout Test Data',\n",
        "                            xaxis_title='index',\n",
        "                            yaxis_title='value',\n",
        "         legend_font_size=14,\n",
        "                          )\n",
        "        #fig.show()\n",
        "        bounds_df = pd.DataFrame()\n",
        "\n",
        "        # Using 99% confidence bounds\n",
        "        bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
        "        bounds_df['prediction'] = test_uncertainty_plot_df['value_mean']\n",
        "        bounds_df['real_value'] = truth_uncertainty_plot_df['value']\n",
        "        bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
        "\n",
        "        bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
        "                                  (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
        "\n",
        "        print(\"Proportion of points contained within 99% confidence interval:\",\n",
        "              bounds_df['contained'].mean())\n",
        "        predictedanomaly = bounds_df.index[~bounds_df['contained']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        realanomaly = label_data['index']\n",
        "\n",
        "        predicter=list(range(len(test_uncertainty2)))\n",
        "\n",
        "        a1 = pd.DataFrame(index=range(len(test_uncertainty2)),columns=range(2))\n",
        "        a1.columns=['index','value']\n",
        "\n",
        "        a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "        a2.columns = ['index','value']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in predictedanomaly:\n",
        "                a1.iloc[i,1]=1\n",
        "            else:\n",
        "                a1.iloc[i,1]=0\n",
        "\n",
        "        for i in range(len(predicter)):\n",
        "            if i in realanomaly:\n",
        "                a2.iloc[i,1] = 1\n",
        "            else:\n",
        "                a2.iloc[i, 1] = 0\n",
        "\n",
        "        y_real=a2.value\n",
        "        y_real=y_real.astype(int)\n",
        "        y_predi=a1.value\n",
        "        y_predi=y_predi.astype(int)\n",
        "\n",
        "\n",
        "        cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "        cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "        #fp = len(predicteddanomaly) - tp\n",
        "        #fn = 0\n",
        "        #tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "        tp=cm[0][0]\n",
        "        fp=cm[0][1]\n",
        "        fn=cm[1][0]\n",
        "        tn=cm[1][1]\n",
        "\n",
        "        precision1 = tp / (tp + fp)\n",
        "        recall1 = tp / (tp + fn)\n",
        "        Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "        F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "      \n",
        "        precision.append(precision1)\n",
        "        F1.append(F11)\n",
        "        Accuracy.append(Accuracy1)\n",
        "        recall.append(recall1)\n",
        "\n",
        "        im=im+1\n",
        "\n",
        "        #matched_indices = list(i_anom_predicted & true_indices_flat)\n",
        "\n",
        "\n",
        "recall_final=mean(recall)\n",
        "precision_final=mean(precision)\n",
        "F1_final=mean(F1)\n",
        "Accuracy_final=mean(Accuracy)\n",
        "#cm = confusion_matrix(y_true=test_labels, y_pred=predicteddanomaly)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# %%\n",
        "\n",
        "## New Test Bayesian LSTM AE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import datetime\n",
        "import pdb\n",
        "import holidays\n",
        "import json\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "DATA_URL = 'https://s3-us-west-2.amazonaws.com/telemanom/data.zip'\n",
        "from statistics import mean\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "seed=42\n",
        "torch.backends.cudnn.determinestic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import matplotlib.pyplot as plt\n",
        "if not os.path.exists('data'):\n",
        "    response = urllib.request.urlopen(DATA_URL)\n",
        "    bytes_io = io.BytesIO(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(bytes_io) as zf:\n",
        "        zf.extractall()\n",
        "#from data import load_signal\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "train_signals = os.listdir('data/train')\n",
        "test_signals = os.listdir('data/test')\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "       \n",
        "  \n",
        "def build_df(data, start=0):\n",
        "#\n",
        "    index = np.array(range(start, start + len(data)))\n",
        "    timestamp = index * 86400 + 1022819200\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame({'timestamp': timestamp.astype(int), 'value': data[:, 0], 'index': index.astype(int)})\n",
        "\n",
        "\n",
        "def create_sliding_window(data, sequence_length, stride=1):\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(len(data)):\n",
        "      if (i + sequence_length) < len(data):\n",
        "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
        "        y_list.append(data.iloc[i+sequence_length, -1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def inverse_transform(y):\n",
        "    return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
        "class MCD_AE(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, output_length, batch_size):\n",
        "        super(MCD_AE, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size  # user-defined\n",
        "\n",
        "        self.hidden_size_1 = 128\n",
        "        self.hidden_size_2 = 64\n",
        "        self.hidden_size_3= 16\n",
        "        self.hidden_size_4 = 64\n",
        "        self.stacked_layers = 3\n",
        "        self.dropout_probability = 0.5  # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
        "\n",
        "\n",
        "        self.lstm1 = nn.LSTM(n_features,\n",
        "                             self.hidden_size_1,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
        "                             self.hidden_size_2,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(self.hidden_size_2,\n",
        "                             self.hidden_size_3,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(self.hidden_size_3,\n",
        "                             self.hidden_size_4,\n",
        "                             num_layers=self.stacked_layers,\n",
        "                             batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_size_4, output_length)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        hidden = self.init_hidden1(batch_size)\n",
        "\n",
        "        output, _ = self.lstm1(x, hidden)\n",
        "\n",
        "        #output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        state = self.init_hidden2(batch_size)\n",
        "        output, state = self.lstm2(output, state)\n",
        "        state = self.init_hidden3(batch_size)\n",
        "        output, state = self.lstm3(output, state)\n",
        "        state = self.init_hidden4(batch_size)\n",
        "        output, state = self.lstm4(output, state)\n",
        "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
        "        output = output[:, -1, :]  # take the last decoder cell's outputs\n",
        "        y_pred = self.fc(output)\n",
        "        return y_pred\n",
        "\n",
        "    def init_hidden1(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
        "        return hidden_state, cell_state\n",
        "    def init_hidden3(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_3))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_3))\n",
        "        return hidden_state, cell_state\n",
        "    def init_hidden4(self, batch_size):\n",
        "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_4))\n",
        "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_4))\n",
        "        return hidden_state, cell_state\n",
        "    def loss(self, pred, truth):\n",
        "        return self.loss_fn(pred, truth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n",
        "###Prepare Labels\n",
        "CSV_URL = 'https://github.com/khundman/telemanom/raw/master/labeled_anomalies.csv'\n",
        "\n",
        "# %%\n",
        "os.makedirs('csv', exist_ok=True)\n",
        "\n",
        "# %%\n",
        "selected_columns = ['index', 'name',  'value']\n",
        "\n",
        "\n",
        "\n",
        "df_label = pd.read_csv(CSV_URL)\n",
        "\n",
        "#name='F-7'\n",
        "MSL=df_label[df_label.spacecraft=='MSL']['chan_id']\n",
        "SMAP=df_label[df_label.spacecraft=='SMAP']['chan_id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "SMAP=pd.Series(SMAP)\n",
        "MSL=pd.Series(MSL)\n",
        "\n",
        "#pdb.set_trace()\n",
        "avg=[]\n",
        "train_signals=MSL\n",
        "precision=[]\n",
        "recall=[]\n",
        "Accuracy=[]\n",
        "F1=[]\n",
        "im=0\n",
        "training_truth_df=pd.DataFrame()\n",
        "T=[]\n",
        "T2=[]\n",
        "for name in MSL:\n",
        "\n",
        "        label_row = df_label[df_label.chan_id == name]\n",
        "    # pdb.set_trace()\n",
        "\n",
        "      #  labels = label_row.anomaly_sequences[im]\n",
        "       # labels = eval(labels)\n",
        "\n",
        "        #true_indices_grouped = [list(range(e[0], e[1] + 1)) for e in labels]\n",
        "        #true_indices_flat = set([i for group in true_indices_grouped for i in group])\n",
        "\n",
        "        appended_data = []\n",
        "\n",
        "        #labels = true_indices_flat\n",
        "\n",
        "    # for i in range(len(labels)):\n",
        "    #    anom=labels[i]\n",
        "    # start=anom[0]\n",
        "    # end=anom[1]\n",
        "\n",
        "        #index = list(labels)\n",
        "\n",
        "    # timestamp = index * 86400 + 1022819200\n",
        "\n",
        "        #anomalies = pd.DataFrame({'value': 1, 'index': index})\n",
        "    #     appended_data.append(anomalies)\n",
        "\n",
        "        #label_data = anomalies\n",
        "\n",
        "    # label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "    # label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        #label_data['name'] = name\n",
        "    # label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "    # label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "\n",
        "\n",
        "        #label_data ['date'] = pd.to_datetime(label_data ['timestamp'], unit='s')\n",
        "        #label_data ['month'] = label_data ['date'].dt.month.astype(int)\n",
        "        #label_data ['name'] = name\n",
        "        #label_data ['day_of_week'] = label_data ['date'].dt.dayofweek.astype(int)\n",
        "        #label_data ['hour_of_day'] = label_data ['date'].dt.hour.astype(int)\n",
        "        #label_data  = label_data [selected_columns]\n",
        "        #label_data .to_csv('csv/' + name + '.csv', index=False)\n",
        "\n",
        "\n",
        "        signal=name\n",
        "        train_np = np.load('data/train/' + signal + '.npy')\n",
        "        test_np = np.load('data/test/' + signal + '.npy')\n",
        "\n",
        "\n",
        "        data = build_df(np.concatenate([train_np, test_np]))\n",
        "        data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
        "        data['month'] = data['date'].dt.month.astype(int)\n",
        "        data['name'] = name\n",
        "        data['index'] = data['index'].astype(int)\n",
        "        data['day_of_week'] = data['date'].dt.dayofweek.astype(int)\n",
        "        data['hour_of_day'] = data['date'].dt.hour.astype(int)\n",
        "        data = data[selected_columns]\n",
        "        _ , validation = train_test_split(\n",
        "            data,\n",
        "            test_size=0.15\n",
        "        )\n",
        "\n",
        "        val_dataset=validation\n",
        "\n",
        "        val=val_dataset\n",
        "\n",
        "\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val['date'] = pd.to_datetime(val['timestamp'], unit='s')\n",
        "        #val['month'] = val['date'].dt.month.astype(int)\n",
        "        #val['day_of_month'] = val['date'].dt.day.astype(int)\n",
        "        #val['name'] = name\n",
        "        #val['day_of_week'] = val['date'].dt.dayofweek.astype(int)\n",
        "        #val['hour_of_day'] = val['date'].dt.hour.astype(int)\n",
        "        #val['index'] = val['index'].astype(int)\n",
        "        #val = val[selected_columns]\n",
        "\n",
        "        train = build_df(train_np)\n",
        "        train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
        "        train['month'] = train['date'].dt.month.astype(int)\n",
        "        train['day_of_month'] = train['date'].dt.day.astype(int)\n",
        "        train['name'] = name\n",
        "        train['day_of_week'] = train['date'].dt.dayofweek.astype(int)\n",
        "        train['hour_of_day'] = train['date'].dt.hour.astype(int)\n",
        "        train['index'] = train['index'].astype(int)\n",
        "        train = train[selected_columns]\n",
        "        # train.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # train.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "\n",
        "\n",
        "        test = build_df(test_np, start=len(train))\n",
        "        test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
        "        test['month'] = test['date'].dt.month.astype(int)\n",
        "        test['name'] = name\n",
        "        test['day_of_week'] = test['date'].dt.dayofweek.astype(int)\n",
        "        test['hour_of_day'] = test['date'].dt.hour.astype(int)\n",
        "        test['index'] = test['index'].astype(int)\n",
        "        test = test[selected_columns]\n",
        "        # test.to_csv('csv/' + name + '.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-train.csv', index=False)\n",
        "        # test.to_csv('csv/' + name + '-test.csv', index=False)\n",
        "\n",
        "        datetime_columns = ['index', 'name']\n",
        "        target_column = 'value'\n",
        "\n",
        "        feature_columns = datetime_columns + ['value']\n",
        "\n",
        "        resample_df = train[feature_columns]\n",
        "        resample_df_test = test[feature_columns]\n",
        "        resample_df_val=val[feature_columns]\n",
        "        #print(resample_df)\n",
        "\n",
        "        plot_length = 1000000\n",
        "        plot_df = resample_df.copy(deep=True).iloc[:plot_length]\n",
        "        #plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
        "\n",
        "        n_train = len(train_np)\n",
        "        n_test = len(test_np)\n",
        "\n",
        "        features = ['index', 'value']\n",
        "        feature_array = resample_df[features].values\n",
        "        feature_array_test = resample_df_test[features].values\n",
        "        feature_array_val = resample_df_val[features].values\n",
        "        # Fit Scaler only on Training features\n",
        "        feature_scaler = MinMaxScaler()\n",
        "        feature_scaler.fit(feature_array[:n_train])\n",
        "        # Fit Scaler only on Training target values\n",
        "        #feature_scaler.fit(feature_array_test[:n_test])\n",
        "\n",
        "        target_scaler = MinMaxScaler()\n",
        "        target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
        "\n",
        "        # Transfom on both Training and Test data\n",
        "        scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
        "                                    columns=features)\n",
        "\n",
        "        scaled_array_test = pd.DataFrame(feature_scaler.transform(feature_array_test),\n",
        "                                         columns=features)\n",
        "        scaled_array_val = pd.DataFrame(feature_scaler.transform(feature_array_val),\n",
        "                                         columns=features)\n",
        "\n",
        "        sequence_length = 25\n",
        "\n",
        "        X_train, y_train = create_sliding_window(scaled_array,\n",
        "                                                 sequence_length)\n",
        "\n",
        "        X_test, y_test = create_sliding_window(scaled_array_test,\n",
        "                                               sequence_length)\n",
        "        X_val, y_val = create_sliding_window(scaled_array_val,\n",
        "                                               sequence_length)\n",
        "\n",
        "        #sns.displot(data=y_test,  kind=\"hist\", bins=100, aspect=1.5)\n",
        "      #  plt.show()\n",
        "       # pdb.set_trace()\n",
        "\n",
        "        #f = Fitter(y_train,\n",
        "         #          distributions=['gamma',\n",
        "          #                        'lognorm',\n",
        "           #                       \"beta\",\n",
        "            #                      \"burr\",\n",
        "             #                     \"norm\",'cauchy', 'chi2', 'expon', 'exponpow', 'powerlaw', 'rayleigh', 'uniform'])\n",
        "        #f.fit()\n",
        "        #f.summary()\n",
        "        #pdb.set_trace()\n",
        "        n_features = scaled_array.shape[-1]\n",
        "        sequence_length = 25\n",
        "        output_length = 1\n",
        "\n",
        "        batch_size = 64\n",
        "        n_epochs = 10\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        bayesian_lstm = MCD_AE(n_features=n_features,\n",
        "                                     output_length=output_length,\n",
        "                                     batch_size=batch_size)\n",
        "        model_parameters = filter(lambda p: p.requires_grad, bayesian_lstm.parameters())\n",
        "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        print(\"total_parameters\", params)\n",
        "\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)\n",
        "        bayesian_lstm.train()\n",
        "        start=time.time()\n",
        "\n",
        "        for e in range(1, n_epochs + 1):\n",
        "            for b in range(0, len(X_train), batch_size):\n",
        "                features = X_train[b:b + batch_size, :, :]\n",
        "                target = y_train[b:b + batch_size]\n",
        "\n",
        "                X_batch = torch.tensor(features, dtype=torch.float32)\n",
        "                y_batch = torch.tensor(target, dtype=torch.float32)\n",
        "                # pdb.set_trace()\n",
        "              \n",
        "               \n",
        "\n",
        "                output = bayesian_lstm(X_batch)\n",
        "                loss = criterion(output.view(-1), y_batch)\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print('epoch', e, 'loss: ', loss.item())\n",
        "                offset = sequence_length\n",
        "        end=time.time()        \n",
        "        T.append((end-start)/n_epochs)\n",
        "        print('Training_time',(end-start)/n_epochs,'signal', name)\n",
        "\n",
        "\n",
        "        training_df = pd.DataFrame()\n",
        "       # training_df['date'] = resample_df['date'].iloc[offset:n_train + offset:1]\n",
        "        training_df['index'] = resample_df['index'].iloc[offset:n_train + offset:1]\n",
        "        training_predictions = bayesian_lstm.predict(X_train)\n",
        "\n",
        "\n",
        "        training_df['value'] = inverse_transform(training_predictions)\n",
        "        training_df['source'] = 'Training Prediction'\n",
        "\n",
        "\n",
        "        #training_truth_df['date'] = training_df['date']\n",
        "        training_truth_df['index'] = training_df['index']\n",
        "        training_truth_df['value'] = resample_df['value'].iloc[\n",
        "                                     offset:n_train + offset:1]\n",
        "        training_truth_df['source'] = 'True Values'\n",
        "\n",
        "        testing_df = pd.DataFrame()\n",
        "        #testing_df['date'] = resample_df_test['date'].iloc[offset:n_test + offset:1]\n",
        "        testing_df['index'] = resample_df_test['index'].iloc[offset:n_test + offset:1]\n",
        "        start=time.time()\n",
        "\n",
        "        testing_predictions = bayesian_lstm.predict(X_test)\n",
        "        end=time.time()\n",
        "        T2.append((end-start))\n",
        "        print('Test_time',(end-start),'signal', name)\n",
        "\n",
        "        testing_df['value'] = inverse_transform(testing_predictions)\n",
        "        testing_df['source'] = 'Test Prediction'\n",
        "\n",
        "        testing_truth_df = pd.DataFrame()\n",
        "        #testing_truth_df['date'] = testing_df['date']\n",
        "        testing_truth_df['index'] = testing_df['index']\n",
        "\n",
        "        testing_truth_df['value'] = resample_df_test['value'].iloc[offset:n_test + offset:1]\n",
        "        testing_truth_df['source'] = 'True Values'\n",
        "\n",
        "\n",
        "        evaluation = pd.concat([training_df,\n",
        "                                testing_df,\n",
        "                                training_truth_df,\n",
        "                                testing_truth_df\n",
        "                                ], axis=0)\n",
        "\n",
        "        fig = px.line(evaluation,\n",
        "                             x=\"index\",\n",
        "                              y=\"value\",\n",
        "                              color=\"source\")\n",
        "        #fig.show()\n",
        "\n",
        "        n_experiments = 2\n",
        "        test_uncertainty_df = pd.DataFrame()\n",
        "        #test_uncertainty_df['date'] = testing_df['date']\n",
        "        test_uncertainty_df['index'] = testing_df['index']\n",
        "\n",
        "        for i in range(n_experiments):\n",
        "            experiment_predictions = bayesian_lstm.predict(X_test)\n",
        "\n",
        "            test_uncertainty_df['value_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
        "\n",
        "        log_energy_consumption_df = test_uncertainty_df.filter(like='value', axis=1)\n",
        "        test_uncertainty_df['value_mean'] = log_energy_consumption_df.mean(axis=1)\n",
        "        test_uncertainty_df['value_std'] = log_energy_consumption_df.std(axis=1)\n",
        "\n",
        "\n",
        "        test_uncertainty1 = test_uncertainty_df['value_mean']\n",
        "\n",
        "        #########################Adaptive Smoothing\n",
        "\n",
        "        #   pdb.set_trace()\n",
        "        Threshold = 10\n",
        "        gamma = 0.1\n",
        "        betta = 0.1\n",
        "        test_uncertainty2 = []\n",
        "        ###########\n",
        "        for jj in range(len(test_uncertainty1) - 2):\n",
        "            test_uncertaintyy = (1 / (1 + gamma + betta)) * (\n",
        "                        test_uncertainty1.iloc[jj] + gamma * test_uncertainty1.iloc[jj + 1] + betta *\n",
        "                        test_uncertainty1.iloc[jj + 2])\n",
        "            test_uncertainty2.append(test_uncertaintyy)\n",
        "        test_uncertainty2 = pd.DataFrame(test_uncertainty2)\n",
        "\n",
        "        test_uncertainty2.columns = [\"value_mean\"]\n",
        "\n",
        "\n",
        "        test_uncertainty_df[\"value_mean\"] = test_uncertainty2[\"value_mean\"]\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "\n",
        "        test_uncertainty_df = test_uncertainty_df[['index',  'value_mean', 'value_std']]\n",
        "        test_uncertainty_df['lower_bound'] = test_uncertainty_df['value_mean'] - 3* test_uncertainty_df['value_std']\n",
        "        test_uncertainty_df['upper_bound'] = test_uncertainty_df['value_mean'] + 3 * test_uncertainty_df['value_std']\n",
        "        import plotly.graph_objects as go\n",
        "\n",
        "        test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
        "        # test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "        truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
        "        # truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_truth_df['date'].between('2016-05-01', '2016-05-09')]\n",
        "\n",
        "        upper_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['upper_bound'],\n",
        "          mode='lines',\n",
        "         fill=None,\n",
        "         name='99% Upper Confidence Bound'\n",
        "         )\n",
        "        lower_trace = go.Scatter(\n",
        "            x=test_uncertainty_plot_df['index'],\n",
        "           y=test_uncertainty_plot_df['lower_bound'],\n",
        "          mode='lines',\n",
        "          fill='tonexty',\n",
        "         name= '99% Lower Confidence Bound',\n",
        "         fillcolor='rgba(255, 211, 0, 0.1)',\n",
        "         )\n",
        "        real_trace = go.Scatter(\n",
        "            x=truth_uncertainty_plot_df['index'],\n",
        "            y=truth_uncertainty_plot_df['value'],\n",
        "            mode='lines',\n",
        "            fill=None,\n",
        "            name='Real Values'\n",
        "        )\n",
        "\n",
        "       # labels = go.Scatter(\n",
        "        #   x=label_data['index'],\n",
        "         # y=label_data['value'],\n",
        "         #mode='lines',\n",
        "         #fill='tonexty' ,\n",
        "         #name='labels'\n",
        "         #)\n",
        "        data = [upper_trace, lower_trace, real_trace]\n",
        "\n",
        "        fig = go.Figure(data=data)\n",
        "        fig.update_layout(title='Uncertainty MCDropout Test Data',\n",
        "                            xaxis_title='index',\n",
        "                            yaxis_title='value',\n",
        "         legend_font_size=14,\n",
        "                          )\n",
        "        #fig.show()\n",
        "        bounds_df = pd.DataFrame()\n",
        "\n",
        "        # Using 99% confidence bounds\n",
        "        bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
        "        bounds_df['prediction'] = test_uncertainty_plot_df['value_mean']\n",
        "        bounds_df['real_value'] = truth_uncertainty_plot_df['value']\n",
        "        bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
        "\n",
        "        bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
        "                                  (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
        "\n",
        "        print(\"Proportion of points contained within 99% confidence interval:\",\n",
        "              bounds_df['contained'].mean())\n",
        "        predictedanomaly = bounds_df.index[~bounds_df['contained']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       # realanomaly = label_data['index']\n",
        "\n",
        "        #predicter=list(range(len(test_uncertainty2)))\n",
        "\n",
        "        a1 = pd.DataFrame(index=range(len(test_uncertainty2)),columns=range(2))\n",
        "        a1.columns=['index','value']\n",
        "\n",
        "        a2 = pd.DataFrame(index=range(len(test_uncertainty2)), columns=range(2))\n",
        "        a2.columns = ['index','value']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#        for i in range(len(predicter)):\n",
        " #           if i in predictedanomaly:\n",
        "  #              a1.iloc[i,1]=1\n",
        "   #         else:\n",
        "    #            a1.iloc[i,1]=0\n",
        "\n",
        "        #for i in range(len(predicter)):\n",
        "         #   if i in realanomaly:\n",
        "          #      a2.iloc[i,1] = 1\n",
        "           # else:\n",
        "            #    a2.iloc[i, 1] = 0\n",
        "\n",
        "        #y_real=a2.value\n",
        "       # y_real=y_real.astype(int)\n",
        "       # y_predi=a1.value\n",
        "       # y_predi=y_predi.astype(int)\n",
        "\n",
        "\n",
        "        #cm = confusion_matrix(y_true=y_real, y_pred=y_predi)\n",
        "        #cm_plot_labels = ['no_anomaly', 'had_anomaly']\n",
        "        #plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "        # tp = len([np.where(predicteddanomaly == x)[0] for x in realanomaly])\n",
        "        #fp = len(predicteddanomaly) - tp\n",
        "        #fn = 0\n",
        "        #tn = len(truth_uncertainty_plot_df) - tp - fp - fn\n",
        "\n",
        "        #tp=cm[0][0]\n",
        "        #fp=cm[0][1]\n",
        "        #fn=cm[1][0]\n",
        "        #tn=cm[1][1]\n",
        "\n",
        "        #precision1 = tp / (tp + fp)\n",
        "        #recall1 = tp / (tp + fn)\n",
        "        #Accuracy1 = (tp + tn) / len(truth_uncertainty_plot_df)\n",
        "        #F11 = 2 / ((1 / precision1) + (1 / recall1))\n",
        "      \n",
        "        #precision.append(precision1)\n",
        "        #F1.append(F11)\n",
        "        #Accuracy.append(Accuracy1)\n",
        "        #recall.append(recall1)\n",
        "\n",
        "        #im=im+1\n",
        "\n",
        "        #matched_indices = list(i_anom_predicted & true_indices_flat)\n",
        "\n",
        "\n",
        "#recall_final=mean(recall)\n",
        "#precision_final=mean(precision)\n",
        "#F1_final=mean(F1)\n",
        "#Accuracy_final=mean(Accuracy)\n",
        "#cm = confusion_matrix(y_true=test_labels, y_pred=predicteddanomaly)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# %%\n",
        "\n",
        "## New Test Bayesian LSTM AE\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTJ16OQF5_-e",
        "outputId": "52162a5d-a68e-47a8-9e6a-9d2a24a4cf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_parameters 545217\n",
            "epoch 10 loss:  1.4802489545218123e-07\n",
            "Training_time 6.244893336296082 signal M-6\n",
            "Test_time 2.8344850540161133 signal M-6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.41650197628458496\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0447407141327858\n",
            "Training_time 7.323600721359253 signal M-1\n",
            "Test_time 2.8106515407562256 signal M-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.010657193605683837\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.002773695858195424\n",
            "Training_time 7.324299049377442 signal M-2\n",
            "Test_time 2.7761430740356445 signal M-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.006216696269982238\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  3.384477167855948e-06\n",
            "Training_time 3.0706828832626343 signal S-2\n",
            "Test_time 2.262962818145752 signal S-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.7980022197558269\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.00801699236035347\n",
            "Training_time 14.503446745872498 signal P-10\n",
            "Test_time 17.08965301513672 signal P-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.06041152263374486\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.2951049506664276\n",
            "Training_time 7.667843294143677 signal T-4\n",
            "Test_time 7.246553659439087 signal T-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  3.1453893711841374e-07\n",
            "Training_time 7.719637322425842 signal T-5\n",
            "Test_time 7.2475481033325195 signal T-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8627450980392157\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.048106200993061066\n",
            "Training_time 8.489115262031556 signal F-7\n",
            "Test_time 12.163040161132812 signal F-7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.005965400676078743\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.06351989507675171\n",
            "Training_time 6.834141325950623 signal M-3\n",
            "Test_time 5.472331762313843 signal M-3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.30589914367269266\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.06661955267190933\n",
            "Training_time 6.957887792587281 signal M-4\n",
            "Test_time 4.564511060714722 signal M-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.28415300546448086\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.08519432693719864\n",
            "Training_time 7.176884508132934 signal M-5\n",
            "Test_time 7.692261219024658 signal M-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.08516242317822652\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0074136448092758656\n",
            "Training_time 12.492927861213683 signal P-15\n",
            "Test_time 4.215481281280518 signal P-15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.11550688802543271\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.007061430253088474\n",
            "Training_time 7.1454216003417965 signal C-1\n",
            "Test_time 2.7693026065826416 signal C-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.00044662795891022776\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  7.116949518604088e-07\n",
            "Training_time 2.491142463684082 signal C-2\n",
            "Test_time 2.3969149589538574 signal C-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.18262586377097728\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.20739872753620148\n",
            "Training_time 3.738759756088257 signal T-12\n",
            "Test_time 3.1677889823913574 signal T-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.39542619542619545\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.15572287142276764\n",
            "Training_time 3.8165022850036623 signal T-13\n",
            "Test_time 3.2432963848114014 signal T-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.1758835758835759\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.002582184737548232\n",
            "Training_time 7.517366933822632 signal F-4\n",
            "Test_time 7.235451698303223 signal F-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.28201354136002355\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  8.675501885591075e-05\n",
            "Training_time 8.671861577033997 signal F-5\n",
            "Test_time 9.222166776657104 signal F-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.07980497818835001\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  6.878358504991411e-08\n",
            "Training_time 12.25404679775238 signal D-14\n",
            "Test_time 3.196993112564087 signal D-14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.8103846153846154\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.011598828248679638\n",
            "Training_time 1.6350671291351317 signal T-9\n",
            "Test_time 1.6054222583770752 signal T-9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.45751633986928103\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.00837191753089428\n",
            "Training_time 9.9240558385849 signal P-14\n",
            "Test_time 12.366273403167725 signal P-14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.00011335456656524912\n",
            "Training_time 2.488267517089844 signal T-8\n",
            "Test_time 1.7417397499084473 signal T-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.6331994645247657\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.0036926954053342342\n",
            "Training_time 13.352583885192871 signal P-11\n",
            "Test_time 6.7916834354400635 signal P-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.33618233618233617\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.00671941926702857\n",
            "Training_time 6.897517132759094 signal D-15\n",
            "Test_time 2.4350926876068115 signal D-15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.41303328645100795\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.042903535068035126\n",
            "Training_time 5.151470518112182 signal D-16\n",
            "Test_time 2.5470142364501953 signal D-16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.0641735918744229\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  3.087450750172138e-05\n",
            "Training_time 5.276236510276794 signal M-7\n",
            "Test_time 2.504493236541748 signal M-7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of points contained within 99% confidence interval: 0.08493664946034725\n",
            "total_parameters 545217\n",
            "epoch 10 loss:  0.10591845214366913\n",
            "Training_time 11.260765790939331 signal F-8\n",
            "Test_time 2.852597236633301 signal F-8\n",
            "Proportion of points contained within 99% confidence interval: 0.015028432168968318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:493: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_MSL=pd.DataFrame()\n",
        "df_MSL['training_time']=T\n",
        "df_MSL['testing_time']=T2\n",
        "df_MSL['pipline']='MCD'\n",
        "df_MSL.to_csv('df_msl.csv',index=False)"
      ],
      "metadata": {
        "id": "QvT8cq_x5YJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXTvocug7YU_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Table4and2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}